<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://xzzz2020.github.io</id>
    <title>xzzz2020</title>
    <updated>2020-07-12T10:51:40.733Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://xzzz2020.github.io"/>
    <link rel="self" href="https://xzzz2020.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://xzzz2020.github.io/images/avatar.png</logo>
    <icon>https://xzzz2020.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, xzzz2020</rights>
    <entry>
        <title type="html"><![CDATA[【面试题】ThreadLocal]]></title>
        <id>https://xzzz2020.github.io/post/aX_Ohmt2H/</id>
        <link href="https://xzzz2020.github.io/post/aX_Ohmt2H/">
        </link>
        <updated>2020-07-12T10:46:31.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E7%AE%80%E4%BB%8B">简介</a></li>
<li><a href="#%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98">内存泄漏问题</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="简介">简介</h2>
<ul>
<li>
<p>threadlocal在线程间是隔离的，不共享，用于存储线程的变量</p>
</li>
<li>
<p>即使多个线程使用同一个ThreadLocal，也只能访问自己的属性</p>
</li>
</ul>
<p>ThreadLocal是使用的Key/Value的结构实现，内部有一个ThreadLocalMap</p>
<h2 id="内存泄漏问题">内存泄漏问题</h2>
<p>ThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。</p>
<p>在一些场景尤其是使用线程池)下，线程不会关闭，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal中key可以被回收，但是这些key为null的Entry的value就会一直存在一条强引用链，会造成内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】JUC并发包]]></title>
        <id>https://xzzz2020.github.io/post/2imuXDnFS/</id>
        <link href="https://xzzz2020.github.io/post/2imuXDnFS/">
        </link>
        <updated>2020-07-12T10:45:03.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>该文章为面试精华版，如果是初学者，建议学习专栏：<a href="https://blog.csdn.net/qq_43040688/category_9910156.html">Java并发专栏</a></p>
</blockquote>
<blockquote>
<p>Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：<a href="https://blog.csdn.net/qq_43040688/category_9819683.html">JVM专栏</a> 和 <a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#1-countdownlatch">1. CountDownLatch</a></li>
<li><a href="#2-cyclicbarrier">2. CyclicBarrier</a></li>
<li><a href="#3-semaphore">3. Semaphore</a></li>
<li><a href="#4-futuretask">4. FutureTask</a></li>
<li><a href="#5-forkjoin">5. ForkJoin</a>
<ul>
<li><a href="#forkjoinpool">ForkJoinPool</a></li>
<li><a href="#forkjointask">ForkJoinTask</a></li>
</ul>
</li>
<li><a href="#6-exchange">6. Exchange</a></li>
<li><a href="#7-condition">7. Condition</a></li>
<li><a href="#8-stampedlock">8. StampedLock</a></li>
<li><a href="#9-reentrantreadwritelock%E8%AF%BB%E5%86%99%E9%94%81">9. ReentrantReadWriteLock读写锁</a></li>
<li><a href="#10-%E9%94%81%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8E%A8%E8%8D%90">10. 锁的使用推荐</a>
<ul>
<li><a href="#%E6%AF%94%E8%BE%83">比较</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</p>
<h2 id="1-countdownlatch">1. CountDownLatch</h2>
<ul>
<li>
<p>用来控制一个线程等待多个线程。</p>
</li>
<li>
<p>维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒</p>
</li>
<li>
<p>计数器的初始值是<strong>线程的数量或者任务的数量</strong></p>
</li>
<li>
<p>每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。</p>
</li>
<li>
<p>通过CAS成功置为0的那个线程将会同时承担起唤醒队列中第一个节点线程的任务</p>
</li>
</ul>
<p><strong>不足</strong>：CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。</p>
<figure data-type="image" tabindex="1"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzExMTUzNDI3NjQ2LnBuZw?x-oss-process=image/format,png" alt="image-20200711153427646" loading="lazy"></figure>
<p><strong>文章地址</strong>：<a href="https://blog.csdn.net/qq_43040688/article/details/105935307">https://blog.csdn.net/qq_43040688/article/details/105935307</a></p>
<h2 id="2-cyclicbarrier">2. CyclicBarrier</h2>
<ul>
<li>
<p>用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。</p>
</li>
<li>
<p>和 CountdownLatch 相似，都是通过维护计数器来实现的。线程执行 await() 方法之后计数器会减 1，并进行等待，直到计数器为 0，所有调用 await() 方法而在等待的线程才能继续执行。</p>
</li>
<li></li>
<li>
<p>CyclicBarrier 有两个构造函数，其中 parties 指示计数器的初始值，barrierAction 在所有线程都到达屏障的时候会执行一次。</p>
</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzExMTUzNDQ0NDMwLnBuZw?x-oss-process=image/format,png" alt="image-20200711153444430" loading="lazy"></figure>
<p><strong>CyclicBarrier 和 CountdownLatch 的区别？</strong></p>
<ul>
<li>CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障，而CountdownLatch 是一次性的。</li>
<li>CountdownLatch 用于一个线程等待一组线程执行完任务  ，CyclicBarrier 用于一组线程互相等待</li>
</ul>
<h2 id="3-semaphore">3. Semaphore</h2>
<p>Semaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。</p>
<p>以下代码模拟了对某个服务的并发请求，每次只能有 3 个客户端同时访问，请求总数为 10。</p>
<pre><code class="language-java">public class SemaphoreExample {
    public static void main(String[] args) {
        final int clientCount = 3;
        final int totalRequestCount = 10;
        Semaphore semaphore = new Semaphore(clientCount);
        ExecutorService executorService = Executors.newCachedThreadPool();
        for (int i = 0; i &lt; totalRequestCount; i++) {
            executorService.execute(()-&gt;{
                try {
                    semaphore.acquire();
                    System.out.print(semaphore.availablePermits() + &quot; &quot;);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    semaphore.release();
                }
            });
        } 
        executorService.shutdown();
    }
}
</code></pre>
<p><strong>实现循环打印？</strong></p>
<p>下面的例子有ABC三个线程。A负责输出1 4 7 B负责输出2 5 8 C负责3 6 9。要求通过信号量机制 控制这三个线程按照顺序输出。</p>
<p><strong>思路就是考虑前驱图，利用信号量实现</strong>：</p>
<pre><code class="language-java">public class Test {
    public static void main(String[] args) {
        new SemaphoreTest().print();
    }
}


class SemaphoreTest {
    private int i = 1;
    private Semaphore s1 = new Semaphore(1);
    private Semaphore s2 = new Semaphore(0);
    private Semaphore s3 = new Semaphore(0);
    private ExecutorService es = Executors.newFixedThreadPool(3);
    public void print(){
        es.execute(()-&gt;{
            while (i&lt;7){
                try {
                    s1.acquire();
                    System.out.println(i);
                    i++;
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }finally {
                    s2.release();
                }
            }
        });
        es.execute(()-&gt;{
            while (i&lt;8){
                try {
                    s2.acquire();
                    System.out.println(i);
                    i++;
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }finally {
                    s3.release();
                }
            }
        });
        es.execute(()-&gt;{
            while (i&lt;9){
                try {
                    s3.acquire();
                    System.out.println(i);
                    i++;
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }finally {
                    s1.release();
                }
            }
        });
        es.shutdown();
    }
}
</code></pre>
<p>或者利用两个线程通过加锁，输出完就唤醒，自己等待，来实现循环打印</p>
<h2 id="4-futuretask">4. FutureTask</h2>
<p>在介绍 Callable 时我们知道它可以有返回值，返回值通过 Future 进行封装。FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，<strong>这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。</strong></p>
<pre><code class="language-java">public class FutureTaskExample {
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() {
            @Override
            public Integer call() throws Exception {
                int result = 0;for (int i = 0; i &lt; 100; i++) {
                    Thread.sleep(10);
                    result += i;
                } 
                return result;
            }
        });
        Thread computeThread = new Thread(futureTask);
        computeThread.start();
        Thread otherThread = new Thread(() -&gt; {
            System.out.println(&quot;other task is running...&quot;);
            try {
                Thread.sleep(1000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        otherThread.start();
        System.out.println(futureTask.get());//获取返回值
    }
}
</code></pre>
<h2 id="5-forkjoin">5. ForkJoin</h2>
<p>一个用于并行执行任务的框架， 是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架，主要用于并行计算中</p>
<p><strong>思想</strong>：分治，fork分解任务，join收集数据</p>
<p>Java标准库提供的<code>java.util.Arrays.parallelSort(array)</code>可以进行并行排序，它的原理就是内部通过Fork/Join对大数组分拆进行并行排序，在多核CPU上就可以大大提高排序的速度。</p>
<h3 id="forkjoinpool">ForkJoinPool</h3>
<p>ForkJoin 使用 ForkJoinPool 来启动，它是一个特殊的线程池，线程数量取决于 CPU 核数</p>
<p>ForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2 从 Thread1 的队列中拿出最晚的 Task1 任务，Thread1 会拿出Task2 来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。</p>
<figure data-type="image" tabindex="3"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzExMTYyNzUyMjE4LnBuZw?x-oss-process=image/format,png" alt="image-20200711162752218" loading="lazy"></figure>
<h3 id="forkjointask">ForkJoinTask</h3>
<p>ForkJoinTask就是ForkJoinPool里面的每一个任务。他主要有两个子类：<code>RecursiveAction</code>和<code>RecursiveTask</code>。然后通过fork()方法去分配任务执行任务，通过join()方法汇总任务结果，</p>
<h2 id="6-exchange">6. Exchange</h2>
<ul>
<li>用于两个工作线程之间交换数据的封装工具类</li>
<li>简单说就是一个线程在完成一定的事务后想与另一个线程交换数据，则<strong>第一个先拿出数据的线程会一直等待第二个线程，直到第二个线程拿着数据到来时才能彼此交换对应数据</strong></li>
<li><strong>如果交换的是引用类型，发送的对象和接收的对象是同一个对象，可能会用严重的线程安全问题</strong></li>
</ul>
<h2 id="7-condition">7. Condition</h2>
<ul>
<li>提供了类似Object的监视器方法，<strong>与Lock配合可以实现等待/通知模式</strong>，但是这两者在使用方式以及功能特性上还是有差别的，等待是用await，通知是signal或者signalAll。</li>
<li>await和Object.wait()类似，都会自动的释放锁，并且在唤起后需要重新获得锁</li>
<li>想要await操作必须需要获得到锁</li>
</ul>
<p><strong>wait和await的区别？</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">wait</th>
<th style="text-align:center">await</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">是配合synchronized关键字的</td>
<td style="text-align:center">是配合Lock锁的</td>
</tr>
<tr>
<td style="text-align:center">等待队列的唤醒受到JVM的影响，是随机的唤醒</td>
<td style="text-align:center">等待队列FIFO的，先阻塞先唤醒</td>
</tr>
<tr>
<td style="text-align:center">不可以被打断</td>
<td style="text-align:center">可以被打断</td>
</tr>
<tr>
<td style="text-align:center">等待队列只有一个</td>
<td style="text-align:center">每一个Condition都具有一个等待队列，可以创建多个Condition</td>
</tr>
</tbody>
</table>
<h2 id="8-stampedlock">8. StampedLock</h2>
<p>如果我们深入分析ReadWriteLock，会发现它有个潜在的问题：<font color="red">如果有线程正在读，写线程需要等待读线程释放锁后才能获取写锁，即读的过程中不允许写，这是一种悲观的读锁。</p>
<p>要进一步提升并发执行效率，Java 8引入了新的读写锁：StampedLock。</p>
<p><strong>出现的问题</strong>：如果有999个需要读锁，1个需要写锁，此时，写的线程，很难得到执行。</p>
<p>StampedLock和ReadWriteLock相比，改进之处在于：<code>读的过程中也允许获取写锁后写入</code>！这样一来，我们读的数据就可能不一致，所以，<strong>需要一点额外的代码来判断读的过程中是否有写入，这种读锁是一种乐观锁</strong>。</p>
<p><strong>乐观锁的意思就是乐观地估计读的过程中大概率不会有写入，因此被称为乐观锁。反过来，悲观锁则是读的过程中拒绝有写入，也就是写入必须等待。</strong></p>
<p>显然乐观锁的并发效率更高，但一旦有小概率的写入导致读取的数据不一致，需要能检测出来，再读一遍就行。</p>
<blockquote>
<p>这是个不可重入锁。</p>
</blockquote>
<pre><code class="language-java">public class Point {


    private final StampedLock stampedLock = new StampedLock();

    private double x;
    private double y;

    public void move(double deltaX, double deltaY) {
        long stamp = stampedLock.writeLock(); // 获取写锁
        try {
            x += deltaX;
            y += deltaY;
        } finally {
            stampedLock.unlockWrite(stamp); // 释放写锁
        }
    }

    public double distanceFromOrigin() {
        long stamp = stampedLock.tryOptimisticRead(); // 获得一个乐观读锁
        // 注意下面两行代码不是原子操作
        // 假设x,y = (100,200)
        double currentX = x;
        // 此处已读取到x=100，但x,y可能被写线程修改为(300,400)
        double currentY = y;
        // 此处已读取到y，如果没有写入，读取是正确的(100,200)
        // 如果有写入，读取是错误的(100,400)
        if (!stampedLock.validate(stamp)) { // 检查乐观读锁后是否有其他写锁发生
            stamp = stampedLock.readLock(); // 获取一个悲观读锁
            try {
                currentX = x;
                currentY = y;
            } finally {
                stampedLock.unlockRead(stamp); // 释放悲观读锁
            }
        }
        return Math.sqrt(currentX * currentX + currentY * currentY);
    }
}
</code></pre>
<h2 id="9-reentrantreadwritelock读写锁">9. ReentrantReadWriteLock读写锁</h2>
<blockquote>
<p>一般情况下都不会使用</p>
</blockquote>
<ul>
<li>读锁和写锁是分离的</li>
<li>一个线程读的时候允许其他线程也可以读</li>
<li>一个线程写的时候不允许其他线程写</li>
<li>读和写也不允许同时进行</li>
</ul>
<p><strong>出现的问题是</strong>：可能会造成饥饿现象，写的线程迟迟无法执行任务</p>
<h2 id="10-锁的使用推荐">10. 锁的使用推荐</h2>
<blockquote>
<p>原文：<a href="https://blog.csdn.net/qq_43040688/article/details/106032189">https://blog.csdn.net/qq_43040688/article/details/106032189</a></p>
</blockquote>
<h3 id="比较">比较</h3>
<table>
<thead>
<tr>
<th>synchronized</th>
<th>StampedLock</th>
<th>Lock</th>
</tr>
</thead>
<tbody>
<tr>
<td>是JVM的的内置锁，每个JDK版本都会优化</td>
<td>是一个Java类，可以更好的扩展</td>
<td>是一个Java类，可以更好的扩展</td>
</tr>
<tr>
<td>都是悲观锁</td>
<td>提供了写的乐观锁</td>
<td>都是悲观锁，但是提供了自旋锁，或者不阻塞的获取锁</td>
</tr>
<tr>
<td>性能一般，因为有一个从用户态到内核态的过程</td>
<td>性能最好，可以代替读写锁</td>
<td>性能十分不稳定，在复杂的读写环境下，性能十分差</td>
</tr>
<tr>
<td>不具有公平锁</td>
<td>不具有公平锁</td>
<td>具有公平锁</td>
</tr>
<tr>
<td>锁会自动释放</td>
<td>锁需要手动释放</td>
<td>锁需要手动释放</td>
</tr>
</tbody>
</table>
<h3 id="总结">总结</h3>
<ul>
<li><code>StampedLock</code>是性能最好的，可以<font color="gold">胜任复杂的读写多线程环境</li>
<li>令人惊奇的是<code>synchronized</code> ，<font color="gold">由于是内置锁，每个JDK版本都会优化，尤其在复杂的读写多线程情况下，表现依然很优秀。</li>
<li><code>Lock</code>虽然提供了读写锁，<font color="gold">但是性能特别差；而<code>ReentrantLock</code>性能十分好，同时功能丰富</li>
</ul>
<p><strong>个人推荐</strong>：如果时读写环境，推荐使用<code>StampedLock</code>；如果是正常的加锁，推荐使用<code>synchronized</code>；如果需要对锁有更多的控制，推荐使用<code>ReentrantLock</code></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】Java内存模型]]></title>
        <id>https://xzzz2020.github.io/post/vKnc9DHsO/</id>
        <link href="https://xzzz2020.github.io/post/vKnc9DHsO/">
        </link>
        <updated>2020-07-12T10:43:53.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>该文章为面试精华版，如果是初学者，建议学习专栏：<a href="https://blog.csdn.net/qq_43040688/category_9910156.html">Java并发专栏</a></p>
</blockquote>
<blockquote>
<p>Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：<a href="https://blog.csdn.net/qq_43040688/category_9819683.html">JVM专栏</a> 和 <a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E4%B8%80-java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8Bjmm">一、Java内存模型JMM</a></li>
<li><a href="#%E4%BA%8C-%E5%86%85%E5%AD%98%E9%97%B4%E4%BA%A4%E4%BA%92%E6%93%8D%E4%BD%9C">二、内存间交互操作</a></li>
<li><a href="#%E4%B8%89-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7">三、内存模型三大特性</a>
<ul>
<li><a href="#%E5%8E%9F%E5%AD%90%E6%80%A7">原子性</a></li>
<li><a href="#%E5%8F%AF%E8%A7%81%E6%80%A7">可见性</a></li>
<li><a href="#%E6%9C%89%E5%BA%8F%E6%80%A7">有序性</a></li>
</ul>
</li>
<li><a href="#%E5%9B%9B-%E9%87%8D%E6%8E%92%E5%BA%8F">四、重排序</a></li>
<li><a href="#%E4%BA%94-happens-before%E5%8E%9F%E5%88%99">五、happens-before原则</a></li>
<li><a href="#%E5%85%AD-volatitle">六、volatitle</a>
<ul>
<li><a href="#1-volatitle%E5%8F%98%E9%87%8F%E4%B8%BA%E4%BD%95%E7%AB%8B%E5%8D%B3%E5%8F%AF%E8%A7%81">1. volatitle变量为何立即可见？</a></li>
<li><a href="#2-%E5%A6%82%E4%BD%95%E7%A6%81%E6%AD%A2%E9%87%8D%E6%8E%92%E5%BA%8F%E4%BC%98%E5%8C%96">2. 如何禁止重排序优化？</a></li>
<li><a href="#3-%E5%92%8Csynchronized%E7%9A%84%E5%8C%BA%E5%88%AB">3. 和synchronized的区别？</a></li>
</ul>
</li>
<li><a href="#%E4%B8%83-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F">七、单例模式</a>
<ul>
<li><a href="#1-%E9%A5%BF%E6%B1%89%E5%BC%8F">1. 饿汉式</a></li>
<li><a href="#2-%E6%99%AE%E9%80%9A%E7%9A%84%E6%87%92%E6%B1%89%E5%BC%8F">2. <strong>普通的懒汉式</strong></a></li>
<li><a href="#3-%E5%90%8C%E6%AD%A5%E6%96%B9%E6%B3%95%E7%9A%84%E6%87%92%E6%B1%89%E5%BC%8F">3. 同步方法的懒汉式</a></li>
<li><a href="#4-%E4%BA%8C%E6%AC%A1%E6%A3%80%E6%9F%A5">4. 二次检查</a></li>
<li><a href="#5-holder%E6%96%B9%E5%BC%8F">5. Holder方式</a></li>
<li><a href="#6-%E6%9E%9A%E4%B8%BE">6. 枚举</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</p>
<h2 id="一-java内存模型jmm">一、Java内存模型JMM</h2>
<p>处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。</p>
<p>加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。</p>
<img src="https://img-1302474103.cos.ap-nanjing.myqcloud.com/img/image-20200711163213039.png" alt="image-20200711163213039" style="zoom:50%;" />
<p>所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。</p>
<p>线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。</p>
<img src="https://img-1302474103.cos.ap-nanjing.myqcloud.com/img/image-20200711163313895.png" alt="image-20200711163313895" style="zoom:50%;" />
<h2 id="二-内存间交互操作">二、内存间交互操作</h2>
<figure data-type="image" tabindex="1"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzExMTYzNDA4ODI2LnBuZw?x-oss-process=image/format,png" alt="image-20200711163408826" loading="lazy"></figure>
<pre><code class="language-go">1. lock（锁定）：作用于`主内存`的变量，它把一个变量标识为一条线程独占的状态。
2. unlock（解锁）：作用于`主内存`的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。

// 读入工作内存
3. read（读取）：主内存 ---&gt; 工作内存。
4. load（载入）：把read操作从主内存中得到的`变量值` ---&gt; `工作内存的变量副本`。

// 中间步骤
5. use（使用）：工作内存中一个`变量的值`---&gt;`执行引擎`，每当虚拟机遇到一个需要`使用到变量的值`的字节码指令时将会执行这个操作。
6. assign（赋值）：把一个`从执行引擎`接收到的值---赋给---&gt;`工作内存的变量`，每当虚拟机遇到一个给变量`赋值`的字节码指令时执行这个操作。

// 写入主内存
7. store（存储）：把工作内存中一个`变量的值`---&gt;`主内存`。
8. write（写入）：把store操作从工作内存中得到的变量的值---&gt;主内存的变量。
</code></pre>
<h2 id="三-内存模型三大特性">三、内存模型三大特性</h2>
<h3 id="原子性">原子性</h3>
<p>Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。</p>
<p><strong>int 等原子性的类型在多线程环境中不会出现线程安全问题？</strong></p>
<p>有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，1000 个线程对它进行自增操作之后，得到的值为 997 而不是 1000。<br>
为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。</p>
<p>下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此<strong>对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。</strong></p>
<figure data-type="image" tabindex="2"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzExMTYzOTU5NDg2LnBuZw?x-oss-process=image/format,png" alt="image-20200711163959486" loading="lazy"></figure>
<p><strong>如何保证原子性呢？</strong></p>
<ul>
<li>Atomic原子类可以利用CAS的方式，在不加锁的情况下保证原子性</li>
<li>synchronized 互斥锁来保证操作的原子性，它对应的内存间交互操作为：lock 和unlock</li>
</ul>
<h3 id="可见性">可见性</h3>
<p>可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。</p>
<p><strong>主要有三种实现可见性的方式</strong>：</p>
<ul>
<li>volatile关键字，是工作内存失效</li>
<li>synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存 。</li>
<li><strong>final</strong>，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。</li>
</ul>
<pre><code class="language-java">public class FinalTest{
    final int i;
    static FinalTest obj;

    public FinalTest(){
        i  =1;
        /**
         *这里会使正在被构造的对象逸出，如果和上一句做了重排序，那么其他线程就可以通过obj访问到还为被初始化的final域。
         **/
        obj = this;
    }
}
</code></pre>
<p>类的 final 域在编译器层面会保证在类的构造器运行结束之前一定要初始化完成，同时 Java 内存模型会保证对象实例化后它的 final 域对其他线程是可见的，然而非 final 域并没有这种待遇。例如如下代码：</p>
<pre><code class="language-java">public class FinalFiled {
    final int x;
    int y;
    static FinalFiled f;

    public FinalFiled() {
        x = 100;
        y = 100;
    }

    static void writer() {
        f = new FinalFiled();
    }

    static void reader() {
        if (f != null) {
            int i = f.x;  // 保证此时一定是 100
            int j = f.y;  // 有可能此时还是 0
        }
    }
}
</code></pre>
<h3 id="有序性">有序性</h3>
<p>有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。</p>
<p><strong>如何保证有序性？</strong></p>
<ul>
<li>volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。</li>
<li>通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。</li>
</ul>
<h2 id="四-重排序">四、重排序</h2>
<p>执行任务的时候，为了提高编译器和处理器的执行性能，编译器和处理器(包括内存系统，内存在行为没有重排但是存储的时候是有变化的)会对指令重排序。编译器优化的重排序是在编译时期完成的，指令重排序和内存重排序是处理器重排序</p>
<ol>
<li>编译器优化的重排序，在不改变单线程语义的情况下重新安排语句的执行顺序</li>
<li>指指令级并行重排序，处理器的指令级并行技术将多条指令重叠执行，如果不存在数据的依赖性将会改变语句对应机器指令的执行顺序</li>
<li>内存系统的重排序，因为使用了读写缓存区，使得看起来并不是顺序执行的</li>
</ol>
<h2 id="五-happens-before原则">五、happens-before原则</h2>
<ol>
<li>程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</li>
<li>监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。</li>
<li>volatile规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。</li>
<li>传递性：如果Ahappens-before B，并且B happens-before C，那么A happens-before C。</li>
<li>start()规则：如果线程A执行操作ThreadB.start()，那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。</li>
<li>join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B的任意操作happens-before于线程A从ThreadB.join()操作成功返回。</li>
</ol>
<p><strong>含义</strong>：两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。所以只要能够满足<strong>A的操作结果一定要对B可见</strong></p>
<h2 id="六-volatitle">六、volatitle</h2>
<h3 id="1-volatitle变量为何立即可见">1. volatitle变量为何立即可见？</h3>
<p>在对有volatile修饰符修饰的共享变量进行写操作时，汇编代码会多一条lock前缀的指令。该指令有如下两个作用：</p>
<ol>
<li>将当前缓存行的数据回写到内存中</li>
<li>使其他cpu里缓存了该内存地址的数据无效(缓存一致性机制)</li>
</ol>
<h3 id="2-如何禁止重排序优化">2. 如何禁止重排序优化？</h3>
<p>通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化</p>
<h3 id="3-和synchronized的区别">3. 和synchronized的区别？</h3>
<ul>
<li>volatile本质是在告诉JVM当前变量在寄存器(工作内存)中的值是不确定的,需要从主存中读取; synchronized则是锁定当前变量， 只有当前线程可以访问该变量,其他线程被阻塞住直到该线程完成变量操作为止</li>
<li>volatile仅能使用在变量级别; synchronized则可以使用在变量、方法和类级别</li>
<li>volatile仅能实现变量的修改可见性,不能保证原子性;而synchronized则可以保证变量修改的可见性和原子性</li>
<li>volatile不会造成线程的阻塞; synchronized可能会造成线程的阻塞</li>
<li>volatile标记的变量不会被编译器优化; synchronized标记的变量可以被编译器优化</li>
</ul>
<h2 id="七-单例模式">七、单例模式</h2>
<h3 id="1-饿汉式">1. 饿汉式</h3>
<pre><code>public class Singleton {

    private final static Singleton INSTANCE = new Singleton();
    
    private Singleton(){}

    public static Singleton getInstance(){
        return INSTANCE;
    }

}
</code></pre>
<h3 id="2-普通的懒汉式">2. <strong>普通的懒汉式</strong></h3>
<pre><code class="language-java">public class Singleton {  
    private static Singleton instance;  
    private Singleton (){}  
  
    public static Singleton getInstance() {  
    if (instance == null) {  
        instance = new Singleton();  
    }  
    return instance;  
    }  
}
</code></pre>
<ul>
<li>线程不安全，不支持多线程</li>
</ul>
<h3 id="3-同步方法的懒汉式">3. 同步方法的懒汉式</h3>
<pre><code class="language-java">class Singleton{
    private static Singleton singleton;
    
    private Singleton(){}
    
    public static synchronized Singleton getSingleton(){
        if (singleton==null){
            singleton = new Singleton();
        }
        return singleton;
    }
}
</code></pre>
<ul>
<li>线程安全，但是性能差</li>
</ul>
<h3 id="4-二次检查">4. 二次检查</h3>
<pre><code class="language-java">class Singleton{
    private static volatile Singleton singleton;

    private Singleton(){}

    public static  Singleton getSingleton(){
        if (singleton==null){
            synchronized (Singleton.class){
                if (singleton==null){
                    singleton = new Singleton();
                }
            }
        }
        return singleton;
    }
}
</code></pre>
<ul>
<li>需要加一个volatile关键字，避免指令重排序如果不加volatile关键字，可能会出现空指针异常，因为在构造singleton的时候，可能也会构造其他的对象，如果出现了指令重排序，会导致singleton构造完成时，其他对象没有构造完成</li>
</ul>
<h3 id="5-holder方式">5. Holder方式</h3>
<pre><code class="language-java">class Singleton{
    
    private Singleton(){}

    private static class instanceHolder {
        private static Singleton singleton = new Singleton();
    }

    public static  Singleton getSingleton(){
        return instanceHolder.singleton;
    }
}
</code></pre>
<ul>
<li>
<p>静态内部类方式在Singleton类被装载时并不会立即实例化，而是在需要实例化时，调用getInstance方法，才会装载SingletonInstance类，从而完成对象的实例化。</p>
</li>
<li>
<p>同时，因为类的静态属性只会在第一次加载类的时候初始化，也就保证了SingletonInstance中的对象只会被实例化一次，并且这个过程也是线程安全的。</p>
</li>
</ul>
<h3 id="6-枚举">6. 枚举</h3>
<pre><code class="language-java">class Singleton{
    private Singleton(){}

    private enum enmuSingleton{
        INSTANCE;

        private Singleton singleton;
        enmuSingleton(){
            singleton = new Singleton();
        }

        public Singleton getSingleton() {
            return singleton;
        }
    }


    public static  Singleton getSingleton(){
        return enmuSingleton.INSTANCE.getSingleton();
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】Java并发实现原理]]></title>
        <id>https://xzzz2020.github.io/post/7zdoEh6sT/</id>
        <link href="https://xzzz2020.github.io/post/7zdoEh6sT/">
        </link>
        <updated>2020-07-12T10:42:22.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>该文章为面试精华版，如果是初学者，建议学习专栏：<a href="https://blog.csdn.net/qq_43040688/category_9910156.html">Java并发专栏</a></p>
</blockquote>
<blockquote>
<p>Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：<a href="https://blog.csdn.net/qq_43040688/category_9819683.html">JVM专栏</a> 和 <a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#1-%E7%B1%BB%E9%94%81%E5%92%8C%E5%AF%B9%E8%B1%A1%E9%94%81%E7%9A%84%E5%8C%BA%E5%88%AB">1. 类锁和对象锁的区别</a></li>
<li><a href="#2-synchronize%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86">2. synchronize底层实现原理</a></li>
<li><a href="#3-%E4%BB%80%E4%B9%88%E6%98%AF%E9%94%81%E9%87%8D%E5%85%A5">3. 什么是锁重入？</a></li>
<li><a href="#4-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E5%AF%B9synchronized%E5%97%A4%E4%B9%8B%E4%BB%A5%E9%BC%BB">4. 为什么会对synchronized嗤之以鼻</a></li>
<li><a href="#4-%E9%94%81%E4%BC%98%E5%8C%96">4. 锁优化</a></li>
<li><a href="#5-%E8%87%AA%E6%97%8B%E9%94%81%E5%92%8C%E8%87%AA%E9%80%82%E5%BA%94%E8%87%AA%E6%97%8B%E9%94%81">5. 自旋锁和自适应自旋锁</a></li>
<li><a href="#6-%E9%94%81%E6%B6%88%E9%99%A4">6. 锁消除</a></li>
<li><a href="#7-%E9%94%81%E7%B2%97%E5%8C%96">7. 锁粗化</a></li>
<li><a href="#8-%E9%94%81%E8%86%A8%E8%83%80%E5%92%8C%E9%94%81%E9%99%8D%E7%BA%A7">8. 锁膨胀和锁降级</a></li>
<li><a href="#9-%E5%81%8F%E5%90%91%E9%94%81">9. 偏向锁</a></li>
<li><a href="#10-%E8%BD%BB%E9%87%8F%E7%BA%A7%E9%94%81">10. 轻量级锁</a></li>
<li><a href="#10-%E9%87%8D%E9%87%8F%E7%BA%A7%E9%94%81">10. 重量级锁</a></li>
<li><a href="#11-reentrantlock">11. ReentrantLock</a></li>
<li><a href="#12-synchronize%E5%92%8Creentrantlock">12. synchronize和ReentrantLock</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="1-类锁和对象锁的区别">1. 类锁和对象锁的区别</h2>
<p><strong>对象锁</strong></p>
<ul>
<li>对象锁有两种，第一种是在普通方法上加synchronize关键字，一种是使用synchronize同步代码块同步一个对象</li>
</ul>
<pre><code class="language-java">//同步代码块
public void func() {
    synchronized (this) {
    // ...
    }
}

//同步一个方法
public synchronized void func () {
	// ...
}
</code></pre>
<p>作用都是同一个对象，如果不同线程去争抢同一个对象的头，就会陷入阻塞，如果是争抢不同对象的头，则不会阻塞</p>
<p><strong>类锁</strong></p>
<ul>
<li>类锁有两种，第一种是在静态方法上加synchronize关键字，一种是使用synchronize同步代码块同步类</li>
</ul>
<pre><code class="language-java">//同步一个类
public void func() {
    synchronized (SynchronizedExample.class) {
    // ...
    }
}
public synchronized static void fun() {
	// ...
}
</code></pre>
<p>作用于整个类，如果是一个类不同的对象，调用这些方法的时候，会陷入阻塞</p>
<p><strong>类锁是一种特殊的对象锁，类锁和对象锁互不干扰，也就是说一个线程访问同步静态方法，另一个线程访问同步普通方法，是不会阻塞的</strong></p>
<pre><code class="language-java">public class Test {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(2);
        Solution solution = new Solution();
        executor.execute(new Runnable() {
            @Override
            public void run() {
                solution.fun2();
            }
        });
        executor.execute(new Runnable() {
            @Override
            public void run() {
                Solution.fun1();
            }
        });
        executor.shutdown();
    }

}


class Solution {

    public  synchronized static void fun1(){
        System.out.println(&quot;fun1...&quot;);
        try {
            TimeUnit.SECONDS.sleep(5);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    public  synchronized void fun2(){
        System.out.println(&quot;fun2...&quot;);
        try {
            TimeUnit.SECONDS.sleep(5);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>
<h2 id="2-synchronize底层实现原理">2. synchronize底层实现原理</h2>
<p>每个对象出生就有一个对象头，而Mark Word的中会包含锁信息和hashcode信息</p>
<p>synchronize获取锁的过程其实是在Mark Word加入线程信息的过程</p>
<figure data-type="image" tabindex="1"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzA4MTYwMjQ2NDE2LnBuZw?x-oss-process=image/format,png" alt="image-20200708160246416" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzA4MTYwMzQyMjk2LnBuZw?x-oss-process=image/format,png" alt="image-20200708160342296" loading="lazy"></figure>
<p><strong>Monitor :每个Java对象天生自带了一把看不见的锁</strong></p>
<h2 id="3-什么是锁重入">3. 什么是锁重入？</h2>
<p>就是如果一个线程获取了一个对象的锁，如果在这个时候，又尝试获取这个对象的锁，会直接进入：</p>
<pre><code class="language-java">class Solution {
    private void test(){
        synchronized (this){
            synchronized (this){
                //执行代码
            }
        }
    }
}
</code></pre>
<p>synchronize和ReentrantLock都是支持可重入的</p>
<h2 id="4-为什么会对synchronized嗤之以鼻">4. 为什么会对synchronized嗤之以鼻</h2>
<ul>
<li>早期版本中, synchronized属于重量级锁,依赖于Mutex Lock实现</li>
<li>线程之间的切换需要从用户态转换到核心态,开销较大</li>
</ul>
<h2 id="4-锁优化">4. 锁优化</h2>
<ul>
<li>synchronized有四种状态无锁、偏向锁、轻量级锁、重量级锁</li>
<li>偏向锁不会使用CAS操作获取锁，直接让第一次获取对象头mark word线程访问，当有其他线程争用对象头时，会结束偏向，膨胀成轻量级锁</li>
<li>轻量级锁会使用CAS操作来获取锁，当获取锁失败的时候，会采用自旋的方式，如果多次失败，会锁升级为重量级锁</li>
<li>同时优化了自旋使用自适应自旋，自旋的次数不固定，会根据上次自旋的次数来决定这次自旋的次数来决定这次自旋的次数</li>
<li>重量级锁和轻量级锁的差异在于，线程获取不到锁，就会陷入阻塞，切换锁的性能十分差，频繁的切换锁就会造成大量的性能优化</li>
<li>锁升级策略主要应对一系列操作频繁的获取锁和释放锁，将扩大加锁的范围，一次加锁就可以完成操作</li>
<li>锁消除会根据逃逸分析，当共享变量并不会被其他线程访问，则可以消除加锁的过程</li>
</ul>
<h2 id="5-自旋锁和自适应自旋锁">5. 自旋锁和自适应自旋锁</h2>
<p>互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，<strong>它只适用于共享数据的锁定状态很短的场景。</strong></p>
<p>在 JDK 1.6 中引入了自适应的自旋锁。<strong>自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。</strong></p>
<h2 id="6-锁消除">6. 锁消除</h2>
<p>锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。</p>
<p>锁消除主要是通过<strong>逃逸分析</strong>来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。</p>
<p>对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁</p>
<pre><code class="language-java">public static String concatString(String s1, String s2, String s3) {
    return s1 + s2 + s3;
}
</code></pre>
<p>String 是一个不可变的类，编译器会对 String 的拼接自动优化。在 JDK 1.5 之前，会转化为 StringBuffer 对象的连续 append() 操作（JDK1.6之后变成StringBuider）：</p>
<pre><code class="language-java">public static String concatString(String s1, String s2, String s3) {
    StringBuffer sb = new StringBuffer();
    sb.append(s1);
    sb.append(s2);
    sb.append(s3);
    return sb.toString();
}
</code></pre>
<p>每个 append() 方法中都有一个同步块。虚拟机观察变量 sb，很快就会发现它的动态作用域被限制在 concatString()方法内部。也就是说，sb 的<strong>所有引用永远不会逃逸到 concatString() 方法之外</strong>，其他线程无法访问到它，因此可以进行消除。</p>
<p>​</p>
<h2 id="7-锁粗化">7. 锁粗化</h2>
<p>如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。</p>
<p>上一节的示例代码中连续的 append() 方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个append() 操作之前直至最后一个 append() 操作之后，这样只需要加锁一次就可以了。</p>
<h2 id="8-锁膨胀和锁降级">8. 锁膨胀和锁降级</h2>
<p><strong>所谓锁的升级、降级，就是 JVM 优化 synchronized 运行的机制，当 JVM 检测到不同的竞争状况时，会自动切换到适合的锁实现，这种切换就是锁的升级、降级。</strong></p>
<h2 id="9-偏向锁">9. 偏向锁</h2>
<p>偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS操作也不再需要。</p>
<p>当锁对象第一次被线程获得的时候，进入偏向状态，标记为 1 01。同时使用 CAS 操作将线程 ID 记录到 Mark Word中，如果 CAS 操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。</p>
<p>当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（Revoke Bias）后恢复到未锁定状态或者轻量级锁状态</p>
<h2 id="10-轻量级锁">10. 轻量级锁</h2>
<p>轻量级锁是相对于传统的重量级锁而言，它使用 CAS 操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。</p>
<p>当尝试获取一个锁对象时，如果锁对象标记为001，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建 Lock Record，然后使用 CAS 操作将对象的 Mark Word 更新为 Lock Record 指针。如果 CAS操作成功了，那么线程就获取了该对象上的锁，并且对象的 Mark Word 的锁标记变为 00，表示该对象处于轻量级锁状态。</p>
<figure data-type="image" tabindex="3"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzExMTkyMzAzNTU5LnBuZw?x-oss-process=image/format,png" alt="image-20200711192303559" loading="lazy"></figure>
<p>如果 CAS 操作失败了，虚拟机首先会检查对象的 Mark Word 是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。</p>
<p>当竞争线程尝试占用轻量级锁失败多次之后（使用自旋）轻量级锁就会膨胀为重量级锁，重量级线程指针指向竞争线程，竞争线程也会阻塞，等待轻量级线程释放锁后唤醒他。</p>
<h2 id="10-重量级锁">10. 重量级锁</h2>
<p>重量级锁的加锁、解锁过程和轻量级锁差不多，区别是：<strong>竞争失败后，线程阻塞，释放锁后，唤醒阻塞的线程，不使用自旋锁，不会那么消耗CPU，所以重量级锁适合用在同步块执行时间长的情况下。</strong></p>
<figure data-type="image" tabindex="4"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzA4MTYyOTA0NjU2LnBuZw?x-oss-process=image/format,png" alt="image-20200708162904656" loading="lazy"></figure>
<h2 id="11-reentrantlock">11. ReentrantLock</h2>
<ul>
<li>ReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。</li>
<li>ReenTrantLock的实现是一种自旋锁， 通过循环调用CAS操作来实现加锁。</li>
<li>它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。</li>
<li>支持公平锁，但是只是相对公平，并不能一定的保证公平，可以避免线程的饥饿现象，即长时间获取不到CPU的执行权，但是如果没有业务需求，不建议使用，因为其会降低性能</li>
<li>必须手动的释放锁，一般使用try...catch..finally释放锁</li>
<li>支持可重入</li>
</ul>
<h2 id="12-synchronize和reentrantlock">12. synchronize和ReentrantLock</h2>
<ul>
<li>Lock基于<code>AQS</code>实现，通过<code>int类型状态</code>和<code>CAS机制</code>来维护锁的获取与释放</li>
<li>synchronized需要通过<code>monitor</code>，经历一个从用户态到内核态的转变过程，更加耗时</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">比较</th>
<th style="text-align:center">synchronized</th>
<th style="text-align:center">Lock</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">锁的实现</td>
<td style="text-align:center">是java内置关键字，在jvm层面</td>
<td style="text-align:center">是个java类</td>
</tr>
<tr>
<td style="text-align:center">能否判断状态</td>
<td style="text-align:center">无法判断是否获取锁的状态</td>
<td style="text-align:center">可以判断是否获取到锁</td>
</tr>
<tr>
<td style="text-align:center">释放锁的方式</td>
<td style="text-align:center">会自动释放锁</td>
<td style="text-align:center">需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁</td>
</tr>
<tr>
<td style="text-align:center">等待可中断</td>
<td style="text-align:center">线程会一直等待下去</td>
<td style="text-align:center">如果尝试获取不到锁，线程可以不用一直等待就结束</td>
</tr>
<tr>
<td style="text-align:center">公平锁</td>
<td style="text-align:center">不支持</td>
<td style="text-align:center">支持公平锁</td>
</tr>
<tr>
<td style="text-align:center">性能</td>
<td style="text-align:center">新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等</td>
<td style="text-align:center">基于<code>AQS</code>实现，性能和synchronize差不多</td>
</tr>
</tbody>
</table>
<p><strong>使用建议</strong>：</p>
<p>除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】Java并发基础]]></title>
        <id>https://xzzz2020.github.io/post/k2Dw6UqvL/</id>
        <link href="https://xzzz2020.github.io/post/k2Dw6UqvL/">
        </link>
        <updated>2020-07-12T10:40:57.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>该文章为面试精华版，如果是初学者，建议学习专栏：<a href="https://blog.csdn.net/qq_43040688/category_9910156.html">Java并发专栏</a></p>
</blockquote>
<blockquote>
<p>Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：<a href="https://blog.csdn.net/qq_43040688/category_9819683.html">JVM专栏</a> 和 <a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#1-%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB">1. 进程和线程的区别</a></li>
<li><a href="#2-start-%E6%96%B9%E6%B3%95%E5%92%8Crun%E6%96%B9%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB">2. start() 方法和run()方法的区别</a></li>
<li><a href="#3-java-%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0%E5%88%9B%E5%BB%BA%E6%96%B9%E5%BC%8F">3. JAVA 线程实现/创建方式</a></li>
<li><a href="#4-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%A4%84%E7%90%86%E7%BA%BF%E7%A8%8B%E7%9A%84%E8%BF%94%E5%9B%9E%E5%80%BC">4. 如何实现处理线程的返回值</a></li>
<li><a href="#5-%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81">5. 线程的状态</a></li>
<li><a href="#6sleep%E5%92%8Cwait%E6%96%B9%E6%B3%95%E7%9A%84%E5%B7%AE%E5%BC%82">6.sleep和wait方法的差异</a></li>
<li><a href="#7-notify-%E5%92%8C-notifyall%E7%9A%84%E5%8C%BA%E5%88%AB">7. notify 和 notifyAll的区别</a></li>
<li><a href="#8-%E5%AE%88%E6%8A%A4%E7%BA%BF%E7%A8%8B%E6%9C%BA%E5%88%B6">8. 守护线程机制</a></li>
<li><a href="#9-%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6">9. 中断机制</a>
<ul>
<li><a href="#interruptedexception">InterruptedException</a></li>
<li><a href="#interrupted">interrupted()</a></li>
</ul>
</li>
<li><a href="#10-%E4%BF%9D%E8%AF%81%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E6%96%B9%E5%BC%8F">10. 保证线程安全的方式</a>
<ul>
<li><a href="#%E4%B8%8D%E5%8F%AF%E5%8F%98%E5%AF%B9%E8%B1%A1">不可变对象</a></li>
<li><a href="#%E4%BA%92%E6%96%A5%E5%90%8C%E6%AD%A5">互斥同步</a></li>
<li><a href="#%E9%9D%9E%E9%98%BB%E5%A1%9E%E5%90%8C%E6%AD%A5-cas">非阻塞同步--CAS</a></li>
<li><a href="#%E6%97%A0%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88">无同步方案</a></li>
</ul>
</li>
<li><a href="#11-java-%E4%B8%AD%E7%94%A8%E5%88%B0%E7%9A%84%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6">11. Java 中用到的线程调度</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="1-进程和线程的区别">1. 进程和线程的区别</h2>
<blockquote>
<p>初期计算机采用串行方式执行任务，需要等待用户输入指令，效率很低；接着计算机采用批处理批量执行用户指令，但是如果有一条指令需要读取大量的数据，此时CPU仍然处于停滞状态，此时就出现了进程。</p>
<p>进程有自己的内存空间，互相之间不干扰，可以保存自己的运行状态可以互相切换，虽然一个CPU依然只能运行一个进程，但当时间片比较小的时候，看起来就像是运行多个程序一样</p>
<p>而线程是为了更进一步的粒度控制，是进程的一个子任务，共享进程的资源，相互切换更加迅速</p>
</blockquote>
<p><strong>进程和线程的区别？</strong></p>
<ol>
<li><strong>拥有资源</strong>：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源</li>
<li><strong>调度</strong>：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换</li>
<li><strong>系统开销</strong>：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小</li>
<li><strong>通信方面</strong>：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。</li>
</ol>
<p><strong>Java与进程和线程的关系</strong>：</p>
<ul>
<li>Java对操作系统提供的功能进行封装,包括进程和线程</li>
<li>运行一个程序会产生一个进程,进程包含至少一个线程</li>
<li>每个进程对应一个JVM实例,多个线程共享JVM里的堆</li>
<li>Java采用单线程编程模型,程序会自动创建主线程</li>
<li>主线程可以创建子线程,原则上要后于子线程完成执行</li>
</ul>
<h2 id="2-start-方法和run方法的区别">2. start() 方法和run()方法的区别</h2>
<ul>
<li>
<p>Thread中调用start方法默认调用的start0方法，会创建一个子线程并执行run方法。</p>
</li>
<li>
<p>Thread中run方法，默认调用的是类属性中Runnable接口的run方法，这个体现了策略模式，即执行和策略分离，由用户定义执行的策略</p>
</li>
</ul>
<h2 id="3-java-线程实现创建方式">3. JAVA 线程实现/创建方式</h2>
<p><strong>有三种使用线程的方法</strong> ：</p>
<ul>
<li>实现 Runnable 接口；</li>
<li>实现 Callable 接口；</li>
<li>继承 Thread 类</li>
</ul>
<p>实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说任务是通过线程驱动从而执行的 。</p>
<p><strong>实现接口比继承 Thread  要好，因为</strong>：</p>
<ul>
<li>Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口；</li>
<li>类可能只要求可执行就行，继承整个 Thread 类开销过大。</li>
</ul>
<h2 id="4-如何实现处理线程的返回值">4. 如何实现处理线程的返回值</h2>
<ul>
<li>主线程等待法：利用循环不断的判断，控制和实现很复杂</li>
<li>使用Thread的join方法，阻塞主线程</li>
<li>使用Callable接口实现：通过FutureTask或者线程池获取</li>
</ul>
<h2 id="5-线程的状态">5. 线程的状态</h2>
<figure data-type="image" tabindex="1"><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWctMTMwMjQ3NDEwMy5jb3MuYXAtbmFuamluZy5teXFjbG91ZC5jb20vaW1nL2ltYWdlLTIwMjAwNzA4MTUxNTQ2MjM5LnBuZw?x-oss-process=image/format,png" alt="image-20200708151546239" loading="lazy"></figure>
<p><strong>新建（New）</strong></p>
<ul>
<li>创建后尚未启动。</li>
</ul>
<p><strong>可运行（Runnable）</strong></p>
<ul>
<li>可能正在运行，也可能正在等待 CPU 时间片。</li>
<li>包含了操作系统线程状态中的 Running 和 Ready。</li>
</ul>
<p><strong>阻塞（Blocked）</strong></p>
<ul>
<li>等待获取一个排它锁，如果其线程释放了锁就会结束此状态。</li>
</ul>
<p><strong>无限期等待（Waiting）</strong></p>
<ul>
<li>等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。</li>
</ul>
<table>
<thead>
<tr>
<th>进入方法</th>
<th>退出方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>没有设置 Timeout 参数的 Object.wait() 方法</td>
<td>Object.notify() / Object.notifyAll()</td>
</tr>
<tr>
<td>没有设置 Timeout 参数的 Thread.join() 方法</td>
<td>被调用的线程执行完毕</td>
</tr>
<tr>
<td>LockSupport.park() 方法</td>
<td>LockSupport.unpark(Thread)</td>
</tr>
</tbody>
</table>
<p><strong>限期等待（Timed Waiting）</strong></p>
<ul>
<li>无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。</li>
<li>调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。</li>
<li>调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。</li>
<li>睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。</li>
<li>阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和Object.wait() 等方法进入</li>
</ul>
<table>
<thead>
<tr>
<th>进入方法</th>
<th>退出方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>Thread.sleep() 方法</td>
<td>时间结束</td>
</tr>
<tr>
<td>设置了 Timeout 参数的 Object.wait() 方法</td>
<td>时间结束 / Object.notify() / Object.notifyAll()</td>
</tr>
<tr>
<td>设置了 Timeout 参数的 Thread.join() 方法</td>
<td>时间结束 / 被调用的线程执行完毕</td>
</tr>
<tr>
<td>LockSupport.parkNanos() 方法</td>
<td>LockSupport.unpark(Thread)</td>
</tr>
<tr>
<td>LockSupport.parkUntil() 方法</td>
<td>LockSupport.unpark(Thread)</td>
</tr>
</tbody>
</table>
<p><strong>死亡（Terminated）</strong></p>
<ul>
<li>可以是线程结束任务之后自己结束，或者产生了异常而结束</li>
</ul>
<h2 id="6sleep和wait方法的差异">6.sleep和wait方法的差异</h2>
<p><strong>最主要的本质区别</strong>：</p>
<ul>
<li>Thread.sleep只会让出CPU ,<code>不会导致锁行为的改变</code></li>
<li>Object.wait不仅让出CPU ,<code>还会释放已经占有的同步资源锁</code></li>
</ul>
<h2 id="7-notify-和-notifyall的区别">7. notify 和 notifyAll的区别</h2>
<p><strong>锁池</strong>：</p>
<p>假设线程A已经拥有了某个对象(不是类)的锁，而其它线程B、C想要调用这个对象的某个synchronized方法(或者块)，由于B、C线程在进入对象的synchronized方法(或者块)之前必须先获得该对象锁的拥有权，而恰巧该对象的锁目前正被线程A所占用，此时B、C线程就会被阻塞，进入一个地方去等待锁的释放，这个地方便是该对象的锁池</p>
<p><strong>等待池</strong>：</p>
<p>假设线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁，同时线程A就进入到了该对象的等待池中，进入到等待池中的线程不会去竞争该对象的锁。</p>
<p><strong>notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会</strong></p>
<p><strong>notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会。</strong></p>
<h2 id="8-守护线程机制">8. 守护线程机制</h2>
<ul>
<li>
<p>守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。</p>
</li>
<li>
<p>当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。</p>
</li>
<li>
<p>main() 属于非守护线程。</p>
</li>
<li>
<p>可以使用 setDaemon() 方法将一个线程设置为守护线程</p>
</li>
</ul>
<pre><code class="language-java">public static void main(String[] args) {
    Thread thread = new Thread(new MyRunnable());
    thread.setDaemon(true);
}
</code></pre>
<h2 id="9-中断机制">9. 中断机制</h2>
<h3 id="interruptedexception">InterruptedException</h3>
<p>通过调用一个线程的 interrupt() 来中断该线程，<code>如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。</code><br>
对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个InterruptedException，从而提前结束线程，不执行之后的语句。</p>
<pre><code class="language-java">public class InterruptExample {
    private static class MyThread1 extends Thread {
        @Override
        public void run() {
            try {
                Thread.sleep(2000);
                System.out.println(&quot;Thread run&quot;);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
    public static void main(String[] args) throws InterruptedException {
        Thread thread1 = new MyThread1();
        thread1.start();
        thread1.interrupt();
        System.out.println(&quot;Main run&quot;);
    }
}
</code></pre>
<h3 id="interrupted">interrupted()</h3>
<p>如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。</p>
<p>但是调用 interrupt() 方法会<code>设置线程的中断标记</code>，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。</p>
<pre><code class="language-java">public class InterruptExample {
    private static class MyThread2 extends Thread {
        @Override
        public void run() {
            while (!interrupted()) {
                // ..
            } 
            System.out.println(&quot;Thread end&quot;);
        }
    }
    public static void main(String[] args) throws InterruptedException {
        Thread thread2 = new MyThread2();
        thread2.start();
        thread2.interrupt();
    }
}
</code></pre>
<h2 id="10-保证线程安全的方式">10. 保证线程安全的方式</h2>
<h3 id="不可变对象">不可变对象</h3>
<p>这是一种<code>无锁</code>的设计模式，因为<code>对于不可变对象没有任何机会去修改这个对象的属性或者引用类型</code></p>
<ul>
<li>final 关键字修饰的基本数据类型</li>
<li>String</li>
<li>枚举类型</li>
<li>Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。</li>
<li>对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合，先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常</li>
</ul>
<h3 id="互斥同步">互斥同步</h3>
<p>synchronize和ReentrantLock</p>
<h3 id="非阻塞同步-cas">非阻塞同步--CAS</h3>
<p>是一种乐观锁，先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。</p>
<p>乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。</p>
<h3 id="无同步方案">无同步方案</h3>
<p>要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。</p>
<ol>
<li>
<p><strong>栈封闭</strong><br>
多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。</p>
<pre><code class="language-java">public class StackClosedExample {
    public void add100() {
        int cnt = 0;
        for (int i = 0; i &lt; 100; i++) {
            cnt++;
        } 
        
        System.out.println(cnt);
    }

    public static void main(String[] args) {
        StackClosedExample example = new StackClosedExample();
        ExecutorService executorService = Executors.newCachedThreadPool();
        executorService.execute(() -&gt; example.add100());
        executorService.execute(() -&gt; example.add100());
        executorService.shutdown();
    }
}
</code></pre>
</li>
<li>
<p><strong>线程本地存储</strong></p>
<p>可以使用<strong>ThreadLocal</strong>，实现线程本地存储功能，这样不同线程访问数据时，只能访问属于本线程的数据，不会干扰到其他点线程</p>
</li>
<li>
<p><strong>可重入代码</strong></p>
<p>最简单的理解就是任何变量都是局部变量，保证在被任何一个函数调用时都以同样的方式运行美，也就是说多个线程执行这个代码，只要赋予方法参数相同，方法结果则都一样</p>
</li>
</ol>
<h2 id="11-java-中用到的线程调度">11. Java 中用到的线程调度</h2>
<p><strong>抢占式调度</strong>：</p>
<p>抢占式调度指的是每条线程执行的时间、线程的切换都由系统控制，系统控制指的是在系统某种运行机制下，可能每条线程都分同样的执行时间片，也可能是某些线程执行的时间片较长，甚至某些线程得不到执行的时间片。在这种机制下，一个线程的堵塞不会导致整个进程堵塞。</p>
<p>Java 中线程会按优先级分配 CPU 时间片运行， 且优先级越高越优先执行，但优先级高并不代表能独自占用执行时间片，可能是优先级高得到越多的执行时间片，反之，优先级低的分到的执行时间少但不会分配不到执行时间</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】CAS]]></title>
        <id>https://xzzz2020.github.io/post/DjYrJcxKl/</id>
        <link href="https://xzzz2020.github.io/post/DjYrJcxKl/">
        </link>
        <updated>2020-07-12T10:39:31.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>该文章为面试精华版，如果是初学者，建议学习专栏：<a href="https://blog.csdn.net/qq_43040688/category_9910156.html">Java并发专栏</a></p>
</blockquote>
<blockquote>
<p>Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：<a href="https://blog.csdn.net/qq_43040688/category_9819683.html">JVM专栏</a> 和 <a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E4%B8%80-cas%E5%8E%9F%E7%90%86%E5%8F%8A%E7%BC%BA%E9%99%B7">一、CAS原理及缺陷</a></li>
<li><a href="#%E4%BA%8C-aba%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3">二、ABA问题及解决</a></li>
<li><a href="#%E4%B8%89-atomic%E7%B1%BB">三、atomic类</a></li>
<li><a href="#%E5%9B%9B-unsafe%E7%B1%BB">四、Unsafe类</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="一-cas原理及缺陷">一、CAS原理及缺陷</h2>
<p><strong>原理</strong>：</p>
<ul>
<li>
<p>CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。</p>
</li>
<li>
<p>更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。</p>
</li>
<li>
<p>从思想上来说，Synchronized属于悲观锁，悲观地认为程序中的并发情况严重，所以严防死守。</p>
</li>
<li>
<p>CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。</p>
</li>
</ul>
<p><strong>缺点</strong>：</p>
<ol>
<li><strong>在竞争激烈的时候，CPU开销较大</strong></li>
</ol>
<p>在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。</p>
<ol start="2">
<li><strong>不能保证代码块的原子性</strong></li>
</ol>
<p>CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证多个变量共同进行原子性的更新，就不得不使用Synchronized了</p>
<h2 id="二-aba问题及解决">二、ABA问题及解决</h2>
<p><strong>什么是ABA？</strong></p>
<p>CAS的机制是在赋值的时候进行比较，如果此时的数值没有修改，则可以完成修改</p>
<p>但是，如果一个对象或者变量出现了：<code>A =&gt; B =&gt; ...... =&gt; A</code>，此时CAS算法进行比较，会没有任何问题，进行修改。但是此时可能已经被修改过了无数次，其他线程的修改就丢失了，在复杂的数据结构比如链表，队列，栈、树等都可能出现不可预知的问题</p>
<p><strong>解决方式–AtomicStampedReference</strong></p>
<ul>
<li>加一个版本号，除了比较对象值，还需要比较状态戳，类似于时间戳</li>
<li>每次修改成功也会同时修改状态戳</li>
</ul>
<h2 id="三-atomic类">三、atomic类</h2>
<p>在高并发条件下，如果都需要对一些基本类型进行修改，就会破坏其原子性</p>
<p>Java并发包提供了一个原子类，基于的是用了 Unsafe 类的 CAS 操作</p>
<p><strong>主要分为基本类型 、数组类型、引用类型和对象的属性子四类</strong></p>
<h2 id="四-unsafe类">四、Unsafe类</h2>
<p>很多Java的基础类库，包括一些被广泛使用的高性能开发库都是基于Unsafe类开发的，比如Netty、Cassandra、Hadoop、Kafka等。Unsafe类在提升Java运行效率，增强Java语言底层操作能力方面起了很大的作用。</p>
<p>Java和C++语言的一个重要区别就是Java中我们无法直接操作一块内存区域，不能像C++中那样可以自己申请内存和释放内存。Java中的Unsafe类为我们提供了类似C++手动管理内存的能力，同时也有了指针的问题。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】阻塞队列]]></title>
        <id>https://xzzz2020.github.io/post/YWCL9C2A8/</id>
        <link href="https://xzzz2020.github.io/post/YWCL9C2A8/">
        </link>
        <updated>2020-07-12T10:38:05.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>该文章为面试精华版，如果是初学者，建议学习专栏：<a href="https://blog.csdn.net/qq_43040688/category_9910156.html">Java并发专栏</a></p>
</blockquote>
<blockquote>
<p>Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：<a href="https://blog.csdn.net/qq_43040688/category_9819683.html">JVM专栏</a> 和 <a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E4%B8%80-arrayblockingqueue">一、ArrayBlockingQueue</a></li>
<li><a href="#%E4%BA%8C-linkedblockingqueue">二、LinkedBlockingQueue</a></li>
<li><a href="#%E4%B8%89-priorityblockingqueue">三、PriorityBlockingQueue</a></li>
<li><a href="#%E5%9B%9B-delayqueue">四、DelayQueue</a></li>
<li><a href="#%E4%BA%94-synchronousqueue">五、SynchronousQueue</a></li>
<li><a href="#%E5%85%AD-linkedtransferqueue">六、LinkedTransferQueue</a></li>
<li><a href="#%E4%B8%83-linkedblockingdeque">七、LinkedBlockingDeque</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="一-arrayblockingqueue">一、ArrayBlockingQueue</h2>
<ul>
<li>
<p><strong>用数组实现的有界阻塞队列</strong>。</p>
</li>
<li>
<p>此队列按照先进先出（FIFO）的原则对元素进行排序。</p>
</li>
<li>
<p><strong>默认情况下不保证访问者公平的访问队列</strong>，所谓公平访问队列是指先阻塞的线程先访问，通常情况下为了保证公平性会降低吞吐量。</p>
</li>
</ul>
<h2 id="二-linkedblockingqueue">二、LinkedBlockingQueue</h2>
<ul>
<li>
<p>基于链表的无界阻塞队列，默认创建一个类似无限大小的容量</p>
</li>
<li>
<p>同 ArrayListBlockingQueue 类似，此队列按照先进先出（FIFO）的原则对元素进行排序。而</p>
</li>
<li>
<p>LinkedBlockingQueue 之所以能够高效的处理并发数据，还因为其<strong>对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。</strong></p>
</li>
</ul>
<h2 id="三-priorityblockingqueue">三、PriorityBlockingQueue</h2>
<ul>
<li>
<p>是一个支持优先级的无界队列。</p>
</li>
<li>
<p>默认情况下元素采取自然顺序升序排列。 可以自定义实现compareTo()方法来指定元素进行排序规则，或者初始化 PriorityBlockingQueue 时，指定构造参数 Comparator 来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。</p>
</li>
</ul>
<h2 id="四-delayqueue">四、DelayQueue</h2>
<ul>
<li>
<p>是一个支持延时获取元素的无界阻塞队列。</p>
</li>
<li>
<p>队列使用 PriorityQueue 来实现。队列中的元素必须实现 Delayed 接口，<strong>在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。</strong></p>
</li>
<li>
<p>可以用于：<strong>缓存系统设计</strong>，当可以取出任务时，代表缓存期到了；定时任务调度 ，保 存 当 天 将 会 执 行 的任务和执行时间 ，一旦从DelayQueue 中获取到任务就开始执行</p>
</li>
</ul>
<h2 id="五-synchronousqueue">五、SynchronousQueue</h2>
<ul>
<li>是一个不存储元素的阻塞队列。</li>
<li>每一个put 操作必须等待一个 take 操作，否则不能继续添加元素。</li>
<li>负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给另外一个线程使用</li>
<li>SynchronousQueue 的 吞 吐 量 高 于 LinkedBlockingQueue 和ArrayBlockingQueue</li>
</ul>
<h2 id="六-linkedtransferqueue">六、LinkedTransferQueue</h2>
<p>是 一 个 由 链 表 结 构 组 成 的无界阻塞 TransferQueue 队 列 。 相对于其他阻塞队列 ，LinkedTransferQueue 多了 tryTransfer 和 transfer 方法，<strong>是一种预占的模式，判断有没有线程空闲，有就直接让其拿走，没有就占着这个位置直到任务被拿到或者超时或者中断</strong>：</p>
<ol>
<li><strong>transfer 方法</strong>： 如果当前有消费者正在等待接收元素（消费者使用 take()方法或带时间限制的poll()方法时）， transfer 方法可以把生产者传入的元素立刻 transfer（传输）给消费者。如果没有消费者在等待接收元素， transfer 方法会将元素存放在队列的 tail 节点，并等到该元素被消费者消费了才返回。</li>
<li><strong>tryTransfer 方法</strong>。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回 false。和 transfer 方法的区别是 tryTransfer 方法无论消费者是否接收，方法立即返回。而 transfer 方法是必须等到消费者消费了才返回。</li>
</ol>
<p>对于带有时间限制的 tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回 false，如果在超时时间内消费了元素，则返回 true。</p>
<h2 id="七-linkedblockingdeque">七、LinkedBlockingDeque</h2>
<p>是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。</p>
<p>在初始化 LinkedBlockingDeque 时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在<br>
“工作窃取”模式中，Fork/Join框架会窃取其他线程队尾的任务。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】线程池]]></title>
        <id>https://xzzz2020.github.io/post/oJRLv7myX/</id>
        <link href="https://xzzz2020.github.io/post/oJRLv7myX/">
        </link>
        <updated>2020-07-12T10:36:31.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>该文章为面试精华版，如果是初学者，建议学习专栏：<a href="https://blog.csdn.net/qq_43040688/category_9910156.html">Java并发专栏</a></p>
</blockquote>
<blockquote>
<p>Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：<a href="https://blog.csdn.net/qq_43040688/category_9819683.html">JVM专栏</a> 和 <a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E4%B8%80-threadpoolexecutor%E5%8F%82%E6%95%B0%E5%90%AB%E4%B9%89">一、ThreadPoolExecutor参数含义</a>
<ul>
<li><a href="#1-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E5%88%9B%E5%BB%BA%E6%96%B0%E7%9A%84%E7%BA%BF%E7%A8%8B">1. 什么时候创建新的线程？</a></li>
<li><a href="#2-%E5%A6%82%E4%BD%95%E5%85%B3%E9%97%AD%E7%BA%BF%E7%A8%8B%E6%B1%A0">2. 如何关闭线程池？</a></li>
</ul>
</li>
<li><a href="#%E4%BA%8C-%E6%8B%92%E7%BB%9D%E7%AD%96%E7%95%A5">二、拒绝策略</a></li>
<li><a href="#%E4%B8%89-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E7%8A%B6%E6%80%81">三、线程池的状态</a></li>
<li><a href="#%E5%9B%9B-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%86%E7%B1%BB">四、线程池分类</a>
<ul>
<li><a href="#newcachedthreadpool">newCachedThreadPool</a></li>
<li><a href="#newfixedthreadpool">newFixedThreadPool</a></li>
<li><a href="#newsinglethreadexecutor">newSingleThreadExecutor</a></li>
<li><a href="#newscheduledthreadpool">newScheduledThreadPool</a></li>
<li><a href="#newworkstealingpool">newWorkStealingPool</a></li>
</ul>
</li>
<li><a href="#%E4%BA%94-%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E5%A5%BD%E5%A4%84">五、使用线程池的好处</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="一-threadpoolexecutor参数含义">一、ThreadPoolExecutor参数含义</h2>
<pre><code class="language-java">public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue&lt;Runnable&gt; workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler)
</code></pre>
<ul>
<li><strong>corePoolSize</strong>：线程池始终线程数，即使有些是空闲的。设置<code>allowCoreThreadTimeOut</code>参数为true，才会进行回收。</li>
<li><strong>maximumPoolSize</strong>：线程池最大线程数，表示在线程池中最多能创建多少个线程。如果当线程池中的数量到达这个数字时，新来的任务会抛出异常。</li>
<li><strong>keepAliveTime</strong>：表示线程没有任务执行时最多能保持多少时间会回收，然后线程池的数目维持在corePoolSize。</li>
<li><strong>unit</strong>：参数keepAliveTime的时间单位</li>
<li><strong>workQueue</strong>：一个阻塞队列，所有的任务都会先放在这里，务；如果对当前对线程的需求超过了corePoolSize大小，会用来存储等待执行的任。</li>
<li><strong>threadFactory</strong>：线程工厂，主要用来创建线程，比如指定线程的名字。</li>
<li><strong>handler</strong>：如果线程池已满，新的任务处理方式。</li>
</ul>
<p><strong>注意一点</strong>：<mark>初始化线程池时，线程数为0</mark></p>
<h3 id="1-什么时候创建新的线程">1. 什么时候创建新的线程？</h3>
<ul>
<li>线程初始化时线程数为0</li>
<li>当前线程数小于corePoolSize时，提交任务会直接创建新的线程</li>
<li>当前线程数大于等于为corePoolSize时，提交任务会放到阻塞队列中，当阻塞队列满时会创建线程</li>
</ul>
<h3 id="2-如何关闭线程池">2. 如何关闭线程池？</h3>
<p><strong>shutdown（高安全低响应）</strong></p>
<ul>
<li>
<p>本质上执行的是<code>interrupt</code>方法</p>
</li>
<li>
<p>阻止新来的任务提交，会将线程池的状态改成SHUTDOWN，当再将执行execute提交任务时，如果测试到状态不为RUNNING，则执行拒绝策略，从而达到阻止新任务提交的目的。</p>
</li>
<li>
<p>对已经提交了的任务不会产生任何影响，当已经提交的任务执行完后，它会将那些闲置的线程进行中断，这个过程是异步的，也就是说只会打断空闲线程，如果当前还有任务队列还有任务未执行，线程将继续把任务执行完。</p>
</li>
</ul>
<p><strong>shutdownNow（低安全高响应）</strong></p>
<ul>
<li>
<p>阻止新来的任务提交，将线程池的状态改成STOP，当再将执行execute提交任务时，如果测试到状态不为RUNNING，则抛出rejectedExecution，从而达到阻止新任务提交的目的.</p>
</li>
<li>
<p>会中断空闲进程，同时也会中断当前正在运行的线程，即workers中的线程。</p>
</li>
<li>
<p>另外它还将workQueue中的任务给移除，并将这些任务添加到列表中进行返回。</p>
</li>
<li>
<p>如遇已经激活的任务，并且处于阻塞状态时，shutdownNow()会执行1次中断阻塞的操作，此时对应的线程报InterruptedException，如果后续还要等待某个资源，则按正常逻辑等待某个资源的到达。例如，一个线程正在sleep状态中，此时执行shutdownNow()，它向该线程发起interrupt()请求，而sleep()方法遇到有interrupt()请求时，会抛出InterruptedException()，并继续往下执行。在这里要提醒注意的是，在激活的任务中，如果有多个sleep(),该方法只会中断第一个sleep()，而后面的仍然按照正常的执行逻辑进行。</p>
</li>
</ul>
<p>高安全低响应体现在shutdown等待任务执行完成再关闭，可以保证任务一定被执行，但是关闭线程池需要等待较长的时间</p>
<p>低安全高响应体现在shutdownNow会关闭正在执行任务的线程，任务可能并没有执行完毕，也不会回退到任务队列中，将会消失，但是关闭线程池不需要等待较长的时间</p>
<p><strong>如果一个任务执行时间很长，导致线程池长时间关闭不了，可以在创建线程的时候将其设置为守护线程，此时被守护的线程是主线程，只要主线程执行完成，线程池就会强制关闭，可以配合awaitTermination使用</strong>：</p>
<pre><code class="language-java">ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(1,2,
        30, TimeUnit.SECONDS,new ArrayBlockingQueue&lt;&gt;(5), r -&gt; {
    Thread t = new Thread(r);
    t.setDaemon(true);
    return t;
},new ThreadPoolExecutor.AbortPolicy());

public static void main(String[] args) throws InterruptedException {
    ThreadPoolExecutor threadPoolExecutor = bulidThreadPoolExecutor();
    threadPoolExecutor.shutdown();
    threadPoolExecutor.awaitTermination(5,TimeUnit.SECONDS);
    System.out.println(&quot;强制关闭&quot;);
}
</code></pre>
<h2 id="二-拒绝策略">二、拒绝策略</h2>
<p>线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也<br>
塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。<br>
<strong>JDK 内置的拒绝策略如下</strong>：</p>
<ol>
<li><strong>AbortPolicy</strong> ： 直接抛出异常，阻止系统正常运行。</li>
<li><strong>CallerRunsPolicy</strong> ： 导致该方法直接在调用者的主线程中执行，而不是在线程池中执行。从而导致主线程在该任务执行结束之前不能提交任何任务。从而有效的阻止了任务的提交。</li>
<li><strong>DiscardOldestPolicy</strong> ： 丢弃最老的一个请求，也就是即将被执行的一个任务，会直接出队，并尝试再<br>
次提交当前任务。</li>
<li><strong>DiscardPolicy</strong> ：默认情况下它将丢弃被拒绝的任务</li>
</ol>
<p>以上内置拒绝策略均实现了 RejectedExecutionHandler 接口，若以上策略仍无法满足实际<br>
需要，完全可以自己扩展 RejectedExecutionHandler 接口。</p>
<h2 id="三-线程池的状态">三、线程池的状态</h2>
<ul>
<li><strong>RUNNING</strong>：能够接收新任务，以及对已添加的任务进行处理。</li>
<li><strong>SHUTDOWN</strong>：不接收新任务，但能处理已添加的任务。</li>
<li><strong>STOP</strong>：程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。</li>
<li><strong>TIDYING</strong>：当所有的任务已终止</li>
<li><strong>TERMINATED</strong>：线程池彻底终止，就变成TERMINATED状态。</li>
</ul>
<h2 id="四-线程池分类">四、线程池分类</h2>
<p>Java 里面线程池的顶级接口是 Executor，但是严格意义上讲 Executor 并不是一个线程池，而<br>
只是一个执行线程的工具。真正的线程池接口是 ExecutorService</p>
<blockquote>
<p><strong>摘自阿里巴巴开发手册</strong>:</p>
<p>【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样 的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors 返回的线程池对象的弊端如下：</p>
<p>1）FixedThreadPool 和 SingleThreadPool: 允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。</p>
<p>2）CachedThreadPool 和 ScheduledThreadPool: 允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。</p>
</blockquote>
<h3 id="newcachedthreadpool">newCachedThreadPool</h3>
<ul>
<li><strong>线程池的参数</strong>：coreSize线程数0，最大线程数无限制，线程的允许空闲时间是60s，阻塞队列是SynchronousQueue</li>
<li>这个线程池适用情况是<code>短任务</code>情况。</li>
<li>采用SynchronousQueue，每当提交一个任务，都会超过阻塞队列的长度，导致创建线程，所以说：每当提交一个任务，都会创建一个线程，可能造成OOM。</li>
<li>当线程空闲1分钟就会，销毁，所以该线程池会频繁的创建和销毁线程，最终会线程池会自己销毁</li>
</ul>
<h3 id="newfixedthreadpool">newFixedThreadPool</h3>
<ul>
<li>coreSize和最大线程数都是用户输入的，阻塞队列用的LinkedBlockingQueue，线程的允许空闲时间是0s</li>
<li>该线程池的线程数是用户自定义的，不会增加，不会减少，线程池不会自己销毁，但是并不是刚开始就会直接创建coreSize的线程</li>
<li>阻塞队列是无限大的，不会执行拒绝策略。</li>
<li>可能会堆集无限的请求，导致OOM</li>
</ul>
<h3 id="newsinglethreadexecutor">newSingleThreadExecutor</h3>
<ul>
<li>相当于线程数为1的newFixedThreadPool，缺点和newFixedThreadPool一样</li>
</ul>
<p><strong>和一个线程的区别？</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">newSingleThreadExecutor</th>
<th style="text-align:center">Thread</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">任务执行完成后，不会自动销毁，可以复用</td>
<td style="text-align:center">任务执行完成后，会自动销毁</td>
</tr>
<tr>
<td style="text-align:center">可以将任务存储在阻塞队列中，逐个执行</td>
<td style="text-align:center">无法存储任务，只能执行一个任务</td>
</tr>
</tbody>
</table>
<h3 id="newscheduledthreadpool">newScheduledThreadPool</h3>
<ul>
<li>可以创建定时的任务，以固定周期执行或者固定的延迟时间执行</li>
<li><strong>如果任务时间超过了定时时长，就无法按照预定的时间执行</strong></li>
<li>而Linux<code>crontab</code>定时处理器<strong>为了确保时间的正确性，会重新启一个线程</strong></li>
</ul>
<h3 id="newworkstealingpool">newWorkStealingPool</h3>
<ul>
<li>采用的ForkJoin框架，可以将任务进行分割，同时线程之间会互相帮助</li>
<li>阻塞队列采用的LinkedBlockingDeque，可以进行任务窃取</li>
</ul>
<h2 id="五-使用线程池的好处">五、使用线程池的好处</h2>
<ul>
<li><strong>线程重用</strong>：线程的创建和销毁的开销是巨大的，而通过线程池的重用大大减少了这些不必要的开销，当然既然少了这么多消费内存的开销，其线程执行速度也是突飞猛进的提升。</li>
<li><strong>控制线程池的并发数</strong>：线程不是并发的越多，性能越高，反而在线程并发太多时，线程的切换会消耗系统大量的资源，可以通过的设置线程池最大并发线程数目，维持系统高性能</li>
<li><strong>线程池可以对线程进行管理</strong>：虽然线程提供了线程组操控线程，但是线程池拥有更多管理线程的API</li>
<li><strong>可以储存需要执行的任务</strong>：当任务提交过多时，可以将任务储存起来，等待线程处理</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】虚拟内存]]></title>
        <id>https://xzzz2020.github.io/post/IAw823Nme/</id>
        <link href="https://xzzz2020.github.io/post/IAw823Nme/">
        </link>
        <updated>2020-07-06T07:35:49.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>本文档为面试精华版，如果是初学者，建议从专栏学习：<a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#1-%E4%BB%80%E4%B9%88%E6%98%AF%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98virtual-memory">1. 什么是虚拟内存(Virtual Memory)?</a></li>
<li><a href="#2-%E5%B1%80%E9%83%A8%E6%80%A7%E5%8E%9F%E7%90%86">2. 局部性原理</a></li>
<li><a href="#3-%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8">3. 虚拟存储器</a></li>
<li><a href="#4-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%9A%84%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0">4. 虚拟内存的技术实现</a></li>
<li><a href="#5-%E8%AF%B7%E6%B1%82%E5%88%86%E9%A1%B5%E4%B8%8E%E5%88%86%E9%A1%B5%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E7%9A%84%E4%B8%8D%E5%90%8C">5. 请求分页与分页存储管理的不同？</a></li>
<li><a href="#6-%E5%B8%B8%E8%A7%81%E7%9A%84%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%E6%9C%89%E5%93%AA%E4%BA%9B">6. 常见的页面置换算法有哪些？</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="1-什么是虚拟内存virtual-memory">1. 什么是虚拟内存(Virtual Memory)?</h2>
<p>这个在我们平时使用电脑特别是Windows 系统的时候太常见了。很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。为什么可以这样呢?正是因为虚拟内存的存在，<strong>通过虚拟内存可以让程序可以拥有超过系统物理内存大小的可用内存空间。</strong></p>
<p>另外，<strong>虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉(每个进程拥有一片连续完整的内存空间)。 这样会更加有效地管理内存并减少出错。</strong></p>
<p><strong>总结而言就是</strong>：</p>
<ul>
<li>可以将内存扩展到外部磁盘存储器上，使得程序可以拥有超过物理内存的的空间大小</li>
<li>让程序有一种错觉，认为自己获得了连续的可⽤的内存，而实际上这些内存分散在物理内存上甚至存放在外部磁盘上</li>
</ul>
<h2 id="2-局部性原理">2. 局部性原理</h2>
<p>局部性原理是虚拟内存技术的基础，正是因为程序运⾏具有局部性原理，才可以只装⼊部分程序到内存就开始运行。</p>
<p><strong>局部性原理表现在以下两个方面</strong>：</p>
<ol>
<li><strong>时间局部性</strong> ：如果程序中的某条指令⼀旦执⾏，不久以后该指令可能再次执⾏；如果某数据被访问过，不久以后该数据可能再次被访问。产⽣时间局部性的典型原因，是由于在程序中存在着⼤量的循环操作。</li>
<li><strong>空间局部性</strong> ：⼀旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在⼀段时间内所访问的地址，可能集中在⼀定的范围之内，这是因为指令通常是顺序存放、顺序执⾏的，数据也⼀般是以向量、数组、表等形式簇聚存储的。</li>
</ol>
<p>时间局部性是通过将近来使⽤的指令和数据保存到⾼速缓存存储器中，并使⽤⾼速缓存的层次结构实现。空间局部性通常是使⽤较⼤的⾼速缓存，并将预取机制集成到⾼速缓存控制逻辑中实现。虚拟内存技术实际上就是建⽴了 “内存⼀外存”的两级存储器的结构，</p>
<h2 id="3-虚拟存储器">3. 虚拟存储器</h2>
<p>基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，<strong>计算机好像为用户提供了一个比实际内存大的多的存储器一虚拟存储器。</strong></p>
<p>实际上，我觉得虚拟内存同样<strong>是一种时间换空间的策略</strong>，你用CPU 的计算时间，页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。</p>
<h2 id="4-虚拟内存的技术实现">4. 虚拟内存的技术实现</h2>
<p><strong>虚拟内存的实现需要建立在离散分配的内存管理方式的基础上，虚拟内存的实现有以下三种方式</strong>:</p>
<ol>
<li><strong>请求分页存储管理</strong>:建立在分页管理之上，<code>为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。</code>请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。</li>
<li><strong>请求分段存储管理</strong>:建立在分段存储管理之.上，<code>增加了请求调段功能、分段置换功能。</code>请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行;在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段;当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。</li>
<li><strong>请求段页式存储管理</strong></li>
</ol>
<h2 id="5-请求分页与分页存储管理的不同">5. 请求分页与分页存储管理的不同？</h2>
<p>根本区别在于，是否要求将程序所需全部的地址空间都装入内存，分页存储是这样要求的，所以无法提供虚拟内存</p>
<h2 id="6-常见的页面置换算法有哪些">6. 常见的页面置换算法有哪些？</h2>
<p>在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。</p>
<p>页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。</p>
<p>页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。</p>
<ul>
<li>
<p><strong>最佳置换算法（OPT）</strong>：理论上最好的算法，每次置换选择的将是最久不会被访问的页面</p>
</li>
<li>
<p><strong>最近最久未使用（LRU）</strong>:  记录的是页面上次的访问时间，实现方式有栈或者寄存器两种，对于栈每次置换栈顶元素，每次访问都会将页面置于栈底；寄存器保存的是访问时间，每次置换掉访问时间离现在最晚的的</p>
</li>
<li>
<p><strong>最少使用（LFU）</strong>：该置换算法选择在之前时期使⽤最少的⻚⾯作为淘汰页，记录的是一段时间内的使用频率。</p>
</li>
<li>
<p><strong>先进先出（FIFO）</strong>：每次置换的将是最先进来的页面</p>
</li>
<li>
<p><strong>第二次机会算法</strong> ：由于先进先出可能会将经常使用的页面置换出去，所以增加了一个访问位，当页面被访问时，将该位置成1，当发生缺页中断时，会将该位置成0，会给该页面一次机会。</p>
</li>
<li>
<p><strong>最近未使用（NRU）</strong>：每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。当发生缺页中断时，最先置换00，最后置换11的页面，至于中间的两个分类，NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[【面试题】操作系统内存管理]]></title>
        <id>https://xzzz2020.github.io/post/NnnE8vgmP/</id>
        <link href="https://xzzz2020.github.io/post/NnnE8vgmP/">
        </link>
        <updated>2020-07-06T07:33:30.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>本文档为面试精华版，如果是初学者，建议从专栏学习：<a href="https://xzzz2020.gitee.io/tag/operating_system/">操作系统专栏</a></p>
</blockquote>
<p><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#1-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B8%BB%E8%A6%81%E6%98%AF%E5%81%9A%E4%BB%80%E4%B9%88">1. 操作系统的内存管理主要是做什么？</a></li>
<li><a href="#2-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E5%90%97%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F">2. 操作系统的内存管理机制了解吗？内存管理有哪几种方式?</a></li>
<li><a href="#3-%E5%BF%AB%E8%A1%A8%E5%92%8C%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8">3. 快表和多级页表</a>
<ul>
<li><a href="#%E5%BF%AB%E8%A1%A8">快表</a></li>
<li><a href="#%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8">多级页表</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
</ul>
</li>
<li><a href="#4-%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%E5%92%8C%E5%88%86%E6%AE%B5%E6%9C%BA%E5%88%B6%E6%9C%89%E5%93%AA%E4%BA%9B%E5%85%B1%E5%90%8C%E7%82%B9%E5%92%8C%E5%8C%BA%E5%88%AB%E5%91%A2">4. 分页机制和分段机制有哪些共同点和区别呢?</a></li>
<li><a href="#5-%E8%A7%A3%E9%87%8A%E4%B8%80%E4%B8%8B%E9%80%BB%E8%BE%91%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E5%92%8C%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80">5. 解释一下逻辑(虚拟)地址和物理地址</a></li>
<li><a href="#6-cpu%E5%AF%BB%E5%9D%80%E4%BA%86%E8%A7%A3%E5%90%97%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4">6. CPU寻址了解吗?为什么需要虚拟地址空间?</a></li>
</ul>
</li>
</ul>
</p>
<h2 id="1-操作系统的内存管理主要是做什么">1. 操作系统的内存管理主要是做什么？</h2>
<p>操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存， free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。</p>
<h2 id="2-操作系统的内存管理机制了解吗内存管理有哪几种方式">2. 操作系统的内存管理机制了解吗？内存管理有哪几种方式?</h2>
<p>**简单分为连续分配管理⽅式和⾮连续分配管理⽅式这两种。**连续分配管理⽅式是指为⼀个⽤户程序分配⼀个连续的内存空间，常⻅的如块式管理 。同样地，⾮连续分配管理⽅式允许⼀个程序使⽤的内存分布在离散或者说不相邻的内存中，常⻅的如⻚式管理 和 段式管理：</p>
<ol>
<li><strong>块式管理</strong> ： 远古时代的计算机操系统的内存管理⽅式。将内存分为⼏个固定⼤⼩的块，每个块中只包含⼀个进程。如果程序运⾏需要内存的话，操作系统就分配给它⼀块，如果程序运⾏只需要很⼩的空间话，分配的这块内存很⼤⼀部分⼏乎被浪费了。这些在每个块中未被利⽤的空间，我们称之为碎⽚。</li>
<li><strong>页式管理</strong> ：把主存分为⼤⼩相等且固定的⼀⻚⼀⻚的形式，⻚较⼩，相对相⽐于块式管理的划分⼒度更⼤，提⾼了内存利⽤率，减少了碎⽚。⻚式管理通过⻚表对应逻辑地址和物理地址。</li>
<li><strong>段式管理</strong> ： ⻚式管理虽然提⾼了内存利⽤率，但是⻚式管理其中的⻚实际并⽆任何实际意义。段式管理把主存分为⼀段段的，每⼀段的空间⼜要⽐⼀⻚的空间⼩很多 。但是，最重要的是段是有实际意义的，每个段定义了⼀组逻辑信息，例如,有主程序段 MAIN、⼦程序段 X、数据段 D及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。</li>
</ol>
<p><strong>最后还有一个很重要的段页式管理</strong>：段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若⼲段，每个段⼜分成若⼲⻚，也就是说 段⻚式管理机制 中段与段之间以及段的内部的都是离散的。</p>
<h2 id="3-快表和多级页表">3. 快表和多级页表</h2>
<h3 id="快表">快表</h3>
<p>**为了解决虚拟地址到物理地址的转换速度，操作系统在页表方案基础之上引入了快表来加速虚拟地址到物理地址的转换。**我们可以把快表理解为一种特殊的高速缓冲存储器(Cache) ，其中的内容是页表的一部分或者全部内容。作为页表的Cache， 它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时CPU要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存,这样可加速查找并提高指令执行速度。</p>
<p><strong>使用快表之后的地址转换流程是这样的</strong>:</p>
<ol>
<li>根据虚拟地址中的页号查快表;</li>
<li>如果该页在快表中，直接从快表中读取相应的物理地址;</li>
<li>如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中;</li>
<li>当快表填满后， 又要登记新页时，就按照一-定的淘汰策略淘汰掉快表中的一个页。</li>
</ol>
<p>看完了之后你会发现快表和我们平时经常在我们开发的系统使用的缓存(比如Redis) 很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。</p>
<h3 id="多级页表">多级页表</h3>
<p>引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需<br>
要的页表就不需要保留在内存中，多级页表属于时间换空间的典型场景。</p>
<h3 id="总结">总结</h3>
<p>为了提高内存的空间性能，提出了多级页表的概念;但是提到空间性能是以浪费时间性能为基础的，因<br>
此为了补充损失的时间性能，提出了快表(即TLB) 的概念。不论是快表还是多级页表实际上都利用到了程序的局部性原理。</p>
<h2 id="4-分页机制和分段机制有哪些共同点和区别呢">4. 分页机制和分段机制有哪些共同点和区别呢?</h2>
<ol>
<li><strong>共同点</strong>:
<ul>
<li>分页机制和分段机制都是为了提高内存利用率，较少内存碎片。</li>
<li>页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。</li>
</ul>
</li>
<li><strong>区别</strong>:
<ul>
<li>页的大小是固定的，由操作系统决定;而段的大小不固定，取决于我们当前运行的程序。</li>
<li>分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。</li>
<li>分页是一维地址空间，分段是二维的。</li>
</ul>
</li>
</ol>
<h2 id="5-解释一下逻辑虚拟地址和物理地址">5. 解释一下逻辑(虚拟)地址和物理地址</h2>
<p>我们编程一般只有 可能和逻辑地址打交道， 比如在C语言中， 指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。</p>
<h2 id="6-cpu寻址了解吗为什么需要虚拟地址空间">6. CPU寻址了解吗?为什么需要虚拟地址空间?</h2>
<p>现代处理器使用的是- -种称为虚拟寻址(Virtual Addressing) 的寻址方式。使用虚拟寻址，CPU 需要<br>
将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。实际 上完成虚拟地址转换为物理地址<br>
转换的硬件是CPU中含有一个被称为内存管理单元(Memory Management Unit, MMU) 的硬件。</p>
<p><strong>为什么要有虚拟地址空间呢？</strong></p>
<ul>
<li>没有虚拟地址空间的时候， 程序都是直接访问和操作的都是物理内存 。</li>
<li>如果直接把物理地址暴露出来的话会带来严重问题，⽐如可能对操作系统造成伤害以及给同时运⾏多个程序造成困难。</li>
</ul>
<p><strong>通过虚拟地址访问内存有以下优势</strong>：</p>
<ul>
<li>程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。</li>
<li>程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页(通常大小为4 KB) 保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。</li>
<li>不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。</li>
</ul>
]]></content>
    </entry>
</feed>