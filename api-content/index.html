{"posts":[{"title":"【总结】RocketMq高级特性","content":"一、消息存储1.为什么要存储到文件系统？如何保证性能？2.加入持久化后RocketMq的架构是什么样的？3.存储结构是什么样的？4.刷盘机制有哪些？5.如何保证消息不丢失？二、高可用机制1.消息消费的高可用（主从）2.消息发送高可用（配置多个主节点）3.主从复制三、负载均衡1.Producer负载均衡2.Consumer负载均衡四、消息重试机制1.顺序消息的重试2.无序消息的重试五、死信队列六、消费幂等1.什么时候产生重复消息？2.处理方式一、消息存储分布式队列因为有高可靠性，保证消息不会丢失的要求，所以数据要进行持久化存储。.1.为什么要存储到文件系统？如何保证性能？持久化方式可以分成两大类关系型数据库：ActiveMQ默认采用的KahaDB做消息存储，由于，普通关系型数据库（如Mysql）在单表数据量达到千万级别的情况下，其IO读写性能往往会出现瓶颈。文件系统：RocketMQ/Kafka/RabbitMQ）均采用的是消息刷盘至所部署虚拟机/物理机的文件系统来做持久化，刷盘一般可以分为异步刷盘和同步刷盘两种模式一般来讲性能对比上：文件系统&gt;关系型数据库DBRocketMq的文件存储系统有两点优化以保证性能：消息存储（顺序写）：RocketMQ的消息用顺序写,保证了消息存储的速度。目前的高性能磁盘，顺序写速度可以达到600MB/s，超过了一般网卡的传输速度，但是磁盘随机写的速度只有大概100KB/s消息发送（零拷贝）：将本机磁盘文件的内容发送到客户端需要进行多次复制，比如从磁盘复制数据到内核态内存；从内核态内存复制到用户态内存；从用户态内存复制到网络驱动，最后从网络驱动复制到网卡中。RocketMq采用Java中零拷贝的技术，让从内核态内存复制到用户态内存这一步省略，直接赋值到网络驱动中零拷贝技术有个限制是不能超过2G，所以RocketMQ默认设置单个CommitLog日志数据文件为1G2.加入持久化后RocketMq的架构是什么样的？消息生成者发送消息MQ收到消息，将消息进行持久化，在存储中新增一条记录返回ACK给生产者MQpush消息给对应的消费者，然后等待消费者返回ACK如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push消息,重复执行4、5、6步骤MQ删除消息3.存储结构是什么样的？RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成的CommitLog：消息真正的物理存储文件是CommitLog，默认一个文件一个G，存储的是Topic，QueueId和Message，一个存储满了会自动创建一个新的。ConsumeQueue：是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址，为了加快消息的读取速度。消费者消费某条消息时，先查询索引获取CommitLog的对应的物理地址。每个Topic下的每个MessageQueue都有一个对应的ConsumeQueue文件，文件很小，通常会加载到内存中。如果该文件丢失或者损坏，可以通过CommitLog恢复IndexFile：也是个索引文件，为了消息查询提供了一种通过key或时间区间来查询消息的方法，这种通过IndexFile来查找消息的方法不影响发送与消费消息的主流程4.刷盘机制有哪些？同步刷盘（数据一定保存成功，但是速度慢）：在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘，然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态。异步刷盘（速度快，数据不一定保存成功）：在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入。5.如何保证消息不丢失？RocketMq提供消息持久化机制，消息的刷盘策略分为同步刷盘和异步刷盘。同步刷盘即刷盘成功后再返回一个成功信息，能够保证数据一定保存成功，但是会降低系统吞吐量，异步刷盘与同步刷盘相反，我一般会采用同步刷盘的策略来保证消息不会丢失。RocketMq采用的文件系统存储而不是关系型数据库存储，因为在一般情况下文件系统的性能是比数据库性能高的而RocketMq为了提高文件系统的读写的高性能，做了两点优化。第一点是采用顺序写的方式，这样可以大大提高磁盘写的性能。第二点采用了零拷贝，原来的文件读取流程是：从磁盘复制数据到内核态内存；从内核态内存复制到用户态内存；从用户态内存复制到网络驱动，最后从网络驱动复制到网卡中发送，零拷贝则省去了从内核态内存复制到用户态内存的这一过程，提高了读取的性能，但是零拷贝对文件大小有要求，所以RocketMq的持久化文件commitlog默认为1G。commitlog是存储了RocketMq的消息等核心信息，除此之外，还提供可一个ConsumeQueue作为持久化文件的索引，提高查询的效率，一般文件比较小，都是加载在内存中。除了ConsumeQueue之外，还会存储一个IndexFile文件，用来提供针对某一个key或者时间区间的查询。二、高可用机制RocketMq是天生支持分布式的，可以配置主从以及水平扩展Master角色的Broker支持读和写，Slave角色的Broker仅支持读，也就是Producer只能和Master角色的Broker连接写入消息；Consumer可以连接Master角色的Broker，也可以连接Slave角色的Broker来读取消息。1.消息消费的高可用（主从）在Consumer的配置文件中，并不需要设置是从Master读还是从Slave读，当Master不可用或者繁忙的时候，Consumer会被自动切换到从Slave读。有了自动切换Consumer这种机制，当一个Master角色的机器出现故障后，Consumer仍然可以从Slave读取消息，不影响Consumer程序。这就达到了消费端的高可用性。RocketMQ目前还不支持把Slave自动转成Master，如果机器资源不足，需要把Slave转成Master，则要手动停止Slave角色的Broker，更改配置文件，用新的配置文件启动Broker。2.消息发送高可用（配置多个主节点）在创建Topic的时候，把Topic的多个MessageQueue创建在多个Broker组上（相同Broker名称，不同brokerId的机器组成一个Broker组），这样当一个Broker组的Master不可用后，其他组的Master仍然可用，Producer仍然可以发送消息。3.主从复制如果一个Broker组有Master和Slave，消息需要从Master复制到Slave上，有同步和异步两种复制方式。同步复制：同步复制方式是等Master和Slave均写成功后才反馈给客户端写成功状态。如果Master出故障，Slave上有全部的备份数据，容易恢复同步复制会增大数据写入延迟，降低系统吞吐量。异步复制：异步复制方式是只要Master写成功即可反馈给客户端写成功状态。在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果Master出了故障，有些数据因为没有被写入Slave，有可能会丢失通常情况下，应该把Master和Save配置成同步刷盘方式，主从之间配置成异步的复制方式，这样即使有一台机器出故障，仍然能保证数据不丢，是个不错的选择。三、负载均衡1.Producer负载均衡Producer端，每个实例在发消息的时候，默认会轮询所有的messagequeue发送，以达到让消息平均落在不同的queue上。而由于queue可以散落在不同的broker，所以消息就发送到不同的broker下，如下图：2.Consumer负载均衡如果consumer实例的数量比messagequeue的总数量还多的话，多出来的consumer实例将无法分到queue，也就无法消费到消息，也就无法起到分摊负载的作用了。所以需要控制让queue的总数量大于等于consumer的数量。消费者的集群模式--启动多个消费者就可以保证消费者的负载均衡（均摊队列）默认使用的是均摊队列：会按照queue的数量和实例的数量平均分配queue给每个实例，这样每个消费者可以均摊消费的队列，如下图所示6个队列和三个生产者。另外一种平均的算法环状轮流分queue的形式，每个消费者，均摊不同主节点的一个消息队列，如下图所示：对于广播模式并不是负载均衡的，要求一条消息需要投递到一个消费组下面所有的消费者实例，所以也就没有消息被分摊消费的说法。四、消息重试机制1.顺序消息的重试对于顺序消息，当消费者消费消息失败后，消息队列RocketMQ会自动不断进行消息重试（每次间隔时间为1秒），这时，应用会出现消息消费被阻塞的情况。因此，在使用顺序消息时，务必保证应用能够及时监控并处理消费失败的情况，避免阻塞现象的发生。2.无序消息的重试对于无序消息（普通、定时、延时、事务消息），当消费者消费消息失败时，您可以通过设置返回状态达到消息重试的结果。无序消息的重试只针对集群消费方式生效；广播方式不提供失败重试特性，即消费失败后，失败消息不再重试，继续消费新的消息。消息队列RocketMQ默认允许每条消息最多重试16次，将会在接下来的4小时46分钟之内进行16次重试，如果依然失败就会进入死信队列。一条消息无论重试多少次，这些重试消息的MessageID不会改变。也可以通过配置，让其不再重试，但是不建议这样publicclassMessageListenerImplimplementsMessageListener{@OverridepublicActionconsume(Messagemessage,ConsumeContextcontext){try{doConsumeMessage(message);}catch(Throwablee){//捕获消费逻辑中的所有异常，并返回Action.CommitMessage;returnAction.CommitMessage;}//消息处理正常，直接返回Action.CommitMessage;returnAction.CommitMessage;}}五、死信队列死信消息具有以下特性:不会再被消费者正常消费。有效期与正常消息相同，均为3天，3天后会被自动删除。因此，请在死信消息产生后的3天内及时处理。死信队列具有以下特性：一个死信队列对应一个GroupID，而不是对应单个消费者实例。如果一个GroupID未产生死信消息，消息队列RocketMQ不会为其创建相应的死信队列。一个死信队列包含了对应GroupID产生的所有死信消息，不论该消息属于哪个Topic。查看死信队列在控制台查询出现死信队列的主题信息在消息界面根据主题查询死信消息选择重新发送消息一条消息进入死信队列，意味着某些因素导致消费者无法正常消费该消息，因此，通常需要您对其进行特殊处理。排查可疑因素并解决问题后，可以在消息队列RocketMQ控制台重新发送该消息，让消费者重新消费一次。六、消费幂等消息队列RocketMQ消费者在接收到消息以后，有必要根据业务上的唯一Key对消息做幂等处理的必要性。1.什么时候产生重复消息？在互联网应用中，尤其在网络不稳定的情况下，消息队列RocketMQ的消息有可能会出现重复，这个重复简单可以概括为以下情况：发送时消息重复当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。如果此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且MessageID也相同的消息。消费时消息重复消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。为了保证消息至少被消费一次，消息队列RocketMQ的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且MessageID也相同的消息。负载均衡时消息重复（包括但不限于网络抖动、Broker重启以及订阅方应用重启）当消息队列RocketMQ的Broker或客户端重启、扩容或缩容时，会触发Rebalance，此时消费者可能会收到重复消息。2.处理方式因为MessageID有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以MessageID作为处理依据。最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息Key进行设置：Messagemessage=newMessage();message.setKey(&quot;ORDERID_100&quot;);SendResultsendResult=producer.send(message);订阅方收到消息时可以根据消息的Key进行幂等处理：consumer.subscribe(&quot;ons_test&quot;,&quot;*&quot;,newMessageListener(){publicActionconsume(Messagemessage,ConsumeContextcontext){Stringkey=message.getKey()//根据业务唯一标识的key做幂等处理}});","link":"https://xzzz2020.github.io/post/czb-YfH6n/"},{"title":"【总结】JVM内存机制","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：JVM专栏一、简介二、程序计数器三、虚拟机栈问题辨析四、本地方法栈五、堆六、方法区七、运行时常量池八、直接内存一、简介Java虚拟机在执⾏Java程序的过程中会把它管理的内存划分成若⼲个不同的数据区域。JDK.1.8和之前的版本略有不同jdk1.8之前：jdk1.8之后：线程私有的：程序计数器虚拟机栈本地方法栈线程共享的：堆方法区直接内存(非运行时数据区的一部分)二、程序计数器用来记住下一条指令的执行的地址，可以依次读取指令或者在多线程的时候，记录线程执行的位置，线程切换后，继续执行是线程私有的，且不会出现内存溢出程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。从上面的介绍中我们知道程序计数器主要有两个作用：字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。注意：程序计数器是唯一一个不会出现OutOfMemoryError的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。三、虚拟机栈与程序计数器一样，Java虚拟机栈也是线程私有的描述的是Java方法执行的内存模型，每次方法调用的数据都是通过栈传递的每个虚拟栈中存放的是栈帧，每个栈帧对应着一次方法的调用，即每个方法需要的内存方法执行时会入栈，所以栈顶的栈帧是正在执行的方法，方法执行结束或出现异常时，会出栈当方法出现递归的时候，可能会造成栈帧过多，导致栈溢出与程序计数器一样，Java虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是Java方法执行的内存模型，每次方法调用的数据都是通过栈传递的。Java内存可以粗糙的区分为堆内存（Heap）和栈内存(Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。（实际上，Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。）局部变量表主要存放了编译期可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）。Java虚拟机栈会出现两种错误：StackOverFlowError和OutOfMemoryError。StackOverFlowError：若Java虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度的时候，就抛出StackOverFlowError错误。OutOfMemoryError：若Java虚拟机堆中没有空闲内存，并且垃圾回收器也无法提供更多内存的话。就会抛出OutOfMemoryError错误。Java虚拟机栈也是线程私有的，每个线程都有各自的Java虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。扩展：那么方法/函数如何调用？Java栈可用类比数据结构中栈，Java栈中保存的主要内容是栈帧，每一次函数调用都会有一个对应的栈帧被压入Java栈，每一个函数调用结束后，都会有一个栈帧被弹出。Java方法有两种返回方式：return语句。抛出异常。不管哪种返回方式都会导致栈帧被弹出。问题辨析垃圾回收是否涉及栈内存？不需要每个方法执行后，都会被弹出栈，自动回收掉栈内存分配越大越好吗？不是分配的越大，因为物理内存一定，会导致线程变少分配的更多，只是帮助更多次的递归调用方法内的局部变量是否线程安全？（看这个线程对变量是私有还是共享的）如果方法内局部变量没有逃离方法的作用访问，它是线程安全的如果是局部变量引用了对象，并逃离方法的作用范围，需要考虑线程安全如果变量变成static类型，需要考虑线程安全四、本地方法栈和虚拟机栈类似，只是用来存储native方法的栈帧和虚拟机栈所发挥的作用非常相似，区别是：虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。在HotSpot虚拟机中和Java虚拟机栈合二为一。本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现StackOverFlowError和OutOfMemoryError两种错误。五、堆是线程共享的，唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存从jdk1.7开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代：再细致一点有：Eden空间、FromSurvivor、ToSurvivor空间等这个是垃圾回收器主要负责回收的区域，当对象过大或者堆存储的对象过多时，就会进行垃圾回收，如果回收失败，最终户出现堆溢出一个线程出现堆溢出，这个线程就会关闭，并且回收该线程创建的对象，此时JVM还没有关闭；如果其他线程在创建对象时，关闭线程并没有释放掉大量的堆空间，会导致其他线程也出现堆溢出，最终导致JVM关闭Java虚拟机所管理的内存中最大的一块，Java堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。Java世界中“几乎”所有的对象都在堆中分配，但是，随着JIT编译期的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。从jdk1.7开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。Java堆是垃圾收集器管理的主要区域，因此也被称作GC堆（GarbageCollectedHeap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代：再细致一点有：Eden空间、FromSurvivor、ToSurvivor空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。六、方法区⽅法区与Java堆⼀样，是各个线程共享的内存区域，它⽤于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。七、运行时常量池运⾏时常量池是⽅法区的⼀部分。Class⽂件中除了有类的版本、字段、⽅法、接口等描述信息外，还有常量池信息（⽤于存放编译期⽣成的各种字⾯量和符号引⽤）既然运行时常量池时方法区的⼀部分，自然受到⽅法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。JDK1.7之前运行时常量池逻辑包含字符串常量池存放在方法区,此时hotspot虚拟机对方法区的实现为永久代JDK1.7字符串常量池被从方法区拿到了堆中,这里没有提到运行时常量池,也就是说字符串常量池被单独拿到堆,运行时常量池剩下的东西还在方法区,也就是hotspot中的永久代。JDK1.8hotspot移除了永久代用元空间(Metaspace)取而代之,这时候字符串常量池还在堆,运行时常量池还在方法区,只不过方法区的实现从永久代变成了元空间(Metaspace)八、直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致OutOfMemoryError错误出现。JDK1.4中新加入的NIO(NewInput/Output)类，引入了一种基于通道（Channel）与缓存区（Buffer）的I/O方式，它可以直接使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在Java堆和Native堆之间来回复制数据。本机直接内存的分配不会受到Java堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。","link":"https://xzzz2020.github.io/post/YkvbP7GKA/"},{"title":"【总结】JVM垃圾回收","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：JVM专栏一、如何判断对象是否死亡？1.引用计数法2.可达性分析算法二、四种引用三、垃圾回收算法1.标记清除算法2.复制算法3.标记压缩算法4.分代收集算法四、常见的垃圾回收器有那些?1.Serial收集器2.ParNew收集器3.ParallelScavenge收集器4.SerialOld收集器5.ParallelOld收集器6.CMS收集器7.G1收集器五、其他1.方法区可以GC吗？2.哪些元素可以做GCroot？3.MinorGC、MajorGC和FullGC之间的区别？MinorGCMajorGCFullGC4.常用JVM参数5.频繁fullGC的原因？一、如何判断对象是否死亡？1.引用计数法给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。2.可达性分析算法这个算法的基本思想就是通过一系列的称为“GCRoots”的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到GCRoots没有任何引用链相连的话，则证明此对象是不可用的。不可达的对象并非“非死不可”即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一个对象死亡，至少要经历两次标记过程被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。如何判断一个常量是废弃常量？运行时常量池主要回收的是废弃的常量。假如在常量池中存在字符串&quot;abc&quot;，如果当前没有任何String对象引用该字符串常量的话，就说明常量&quot;abc&quot;就是废弃常量，如果这时发生内存回收的话而且有必要的话，&quot;abc&quot;就会被系统清理出常量池。如何判断一个类是无用的类?方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面3个条件才能算是“无用的类”：该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例。加载该类的ClassLoader已经被回收。该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。虚拟机可以对满足上述3个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。二、四种引用无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判定对象的存活都与“引用”有关。1．强引用（StrongReference）以前我们使用的大部分引用实际上都是强引用，垃圾回收器绝不会回收它。当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。2．软引用（SoftReference）如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。3．弱引用（WeakReference）弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。4．虚引用（PhantomReference）&quot;虚引用&quot;顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要用来跟踪对象被垃圾回收的活动。虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速JVM对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。.三、垃圾回收算法1.标记清除算法该算法分为“标记”和“清除”阶段：首先比较出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：效率问题，需要STW，会影响性能空间问题（标记清除后会产生大量不连续的碎片）为什么不能边运行，边标记？因为标记和清理的过程是遍历全部对象如果代码没有停止运行，就无法梳理所有的对象关系，此时的标记和清除是不准的，所以必须停止应用程序2.复制算法复制算法的核心就是，将原有的内存空间一分为二，每次只用其中的一块，在垃圾回收时，将正在使用的对象复制到另一个内存空间中，然后将该内存空间清空，交换两个内存的角色，完成垃圾的回收。如果内存中的垃圾对象较多，需要复制的对象就较少，这种情况下适合使用该方式并且效率比较高，反之，则不适合。3.标记压缩算法根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存，从而解决了碎片化的问题。不过，标记压缩算法多了一步，对象移动内存位置的步骤，其效率也有有一定的影响4.分代收集算法这样分区主要为了提高GC的效率，根据不同点分区选择不同的GC算法当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。四、常见的垃圾回收器有那些?1.Serial收集器Serial（串行）收集器收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的“单线程”的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程（&quot;StopTheWorld&quot;），直到它收集结束。新生代采用复制算法，老年代采用标记-整理算法但是Serial收集器有没有优于其他垃圾收集器的地方呢？当然有，它简单而高效（与其他收集器的单线程相比）。Serial收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。Serial收集器对于运行在Client模式下的虚拟机来说是个不错的选择。2.ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和Serial收集器完全一样。新生代采用复制算法，老年代采用标记-整理算法。它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器（真正意义上的并发收集器，后面会介绍到）配合工作3.ParallelScavenge收集器ParallelScavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。ParallelScavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在困难的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。新生代采用复制算法，老年代采用标记-整理算法。有两个很重要的参数：控制吞吐量大小控制最大垃圾收集停顿时间的4.SerialOld收集器Serial收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在JDK1.5以及以前的版本中与ParallelScavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。5.ParallelOld收集器ParallelScavenge收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及CPU资源的场合，都可以优先考虑ParallelScavenge收集器和ParallelOld收集器。6.CMS收集器CMS（ConcurrentMarkSweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。CMS（ConcurrentMarkSweep）收集器是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。从名字中的MarkSweep这两个词可以看出，CMS收集器是一种“标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：初始标记（STW）：暂停所有的其他线程，并记录下直接与root相连的对象，速度很快；并发标记：同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。重新标记（STW）：重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短并发清除：开启用户线程，同时GC线程开始对未标记的区域做清扫。从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：并发收集、低停顿。但是它有下面三个明显的缺点：对CPU资源敏感；无法处理浮动垃圾，并发清理阶段用户线程还在运行，这段时间就可能产生新的垃圾，新的垃圾在此次GC无法清除，只能等到下次清理。；它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。7.G1收集器G1(Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器.以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征.被视为JDK1.7中HotSpot虚拟机的一个重要进化特征。它具备一下特点：并行与并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。空间整合：与CMS的“标记--清除”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内。G1收集器的运作大致分为以下几个步骤：初始标记：只标记GCRoots能直接关联到的对象并发标记：进行GCRootsTracing的过程最终标记：修正并发标记期间，因程序运行导致标记发生变化的那一部分对象筛选回收：根据时间来进行价值最大化的回收G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字Garbage-First的由来)。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。五、其他1.方法区可以GC吗？方法区和堆一样，都是线程共享的内存区域，被用于存储已被虚拟机加载的类信息（字段等）、即时编译后的代码（方法字节码）、静态变量和常量等数据。根据Java虚拟机规范的规定，方法区无法满足内存分配需求时，也会抛出OutOfMemoryError异常，虽然规范规定虚拟机可以不实现垃圾收集，因为和堆的垃圾回收效率相比，方法区的回收效率实在太低，但是此部分内存区域也是可以被回收的。方法区的垃圾回收主要有两种，分别是对废弃常量的回收（常量池的回收）和对无用类的回收（类的卸载）。当一个常量对象不再任何地方被引用的时候，则被标记为废弃常量，这个常量可以被回收。方法区中的类需要同时满足以下三个条件才能被标记为无用的类：Java堆中不存在该类的任何实例对象；加载该类的类加载器已经被回收；该类对应的java.lang.Class对象不在任何地方被引用，且无法在任何地方通过反射访问该类的方法。当满足上述三个条件的类才可以被回收，但是并不是一定会被回收，需要参数进行控制，例如HotSpot虚拟机提供了-Xnoclassgc参数进行控制是否回收。2.哪些元素可以做GCroot？虚拟机栈中的引用对象。方法区中的类静态变量引用的对象。方法区中常量引用对象。本地方法栈中JNI引用对象。3.MinorGC、MajorGC和FullGC之间的区别？MinorGC清理java堆中的年轻代，一般使用复制算法触发条件:新生代空间不足时MajorGC一般使用标记-清除法，清理老年代触发条件：当老年代不足时，会触发MajorGC什么时候老年代需要申请空间新生代清理后依然出现空间不足，新生代复制到老年代年龄大于15，会复制到老年代新建一个大对象FullGCFullGC是清理整个堆空间—包括年轻代和老久代只要发生fullGC，JAVA程序就会STW触发条件：老年代空间不足方法区空间不足调用System.gc时，系统建议执行FullGC，但是不必然执行通过MinorGC后进入老年代的平均大小大于老年代的可用内存SafePoint分析过程中对象引用关系不会发生变化的点产生Safepoint的地方：方法调用、循环跳转、异常跳转等4.常用JVM参数-Xmx：堆内存最大值，默认是机器物理内存的1/4。这个值决定了最多可用的Java堆内存。分配过少就会在应用中需要大量内存作缓存或者临时对象时出现OOM（OutOfMemory）的问题。如果分配过大，那么就会因PermSize过小而引起的另外一种OutOfMemory。-Xms：设置Java堆初始化时的大小，默认情况是机器物理内存的1/64。这个主要是根据应用启动时消耗的资源决定，分配少了申请起来会降低运行速度，分配多了也浪费。-XX:PermSize：初始化永久内存区域大小。-Xmn：直接设置青年代大小。整个JVM可用内存大小=青年代大小+老年代大小+持久代大小。Sun官方推荐配置为整个堆的3/8。-XX:NewRatio：控制默认的Young代的大小，例如，设置-XX:NewRatio=3意味着Young代和老年代的比率是1:3。换句话说，Eden和Survivor空间总和是整个堆大小的1/4。-XX:SurvivorRatio：设置年轻代中Eden区与Survivor区的大小比值。设置为4，则两个Survivor区与一个Eden区的比值为2:4，一个Survivor区占整个年轻代的1/6。-Xss：设置每个线程的堆栈大小，根据应用的线程所需内存大小进行调整，在相同物理内存下，减小这个值能生成更多的线程。5.频繁fullGC的原因？可能堆空间设置的太小了可能有对象长时间得不到释放内存碎片导致所以建议先用jstack保存当前堆栈信息，然后重启系统，保证系统的高可用","link":"https://xzzz2020.github.io/post/Yuwv7VFrF/"},{"title":"【总结】类加载器","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：JVM专栏一、简介二、自定义加载器三、双亲委派模型1.双亲委派模型的好处2.双亲委派模型实现源码分析3.如果我们不想用双亲委派模型怎么办？4.ClassLoader.loadClass和Class.forName的区别一、简介JVM中内置了三个重要的ClassLoader，除了BootstrapClassLoader其他类加载器均由Java实现且全部继承自java.lang.ClassLoader：BootstrapClassLoader(启动类加载器)：最顶层的加载类，由C++实现，负责加载%JAVA_HOME%/lib目录下的jar包和类或者或被-Xbootclasspath参数指定的路径中的所有类。ExtensionClassLoader(扩展类加载器)：主要负责加载目录%JRE_HOME%/lib/ext目录下的jar包和类，或被java.ext.dirs系统变量所指定的路径下的jar包。AppClassLoader(应用程序类加载器):面向我们用户的加载器，负责加载当前应用classpath下的所有jar包和类。一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的loadClass()方法）。数组类型不通过类加载器创建，它由Java虚拟机直接创建。所有的类都由类加载器加载，加载的作用就是将.class文件加载到内存。二、自定义加载器除了BootstrapClassLoader其他类加载器均由Java实现且全部继承自java.lang.ClassLoader。如果我们要自定义自己的类加载器，很明显需要继承ClassLoader。主要的就是下面三个方法：findClass（让JVM寻找class文件）loadClass（加载class文件变成二进制数组）defineClass（将二进制数组变成最终的class）可以加载一些加密的Class文件比如说股票软件，别人写的模型，不要让别人看到，可以通过加密文件但是加密的class文件，JVM的提供的类加载器无法识别，需要一个自定义的加载器三、双亲委派模型当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，只有当父类加载器反馈自己无法完成这个请求的时候(在它的加载路径下没有找到所需加载的class），子类加载器才会尝试自己去加载。每个类加载都有一个父类加载器，我们通过下面的程序来验证。publicclassClassLoaderDemo{publicstaticvoidmain(String[]args){System.out.println(&quot;ClassLodarDemo'sClassLoaderis&quot;+ClassLoaderDemo.class.getClassLoader());System.out.println(&quot;TheParentofClassLodarDemo'sClassLoaderis&quot;+ClassLoaderDemo.class.getClassLoader().getParent());System.out.println(&quot;TheGrandParentofClassLodarDemo'sClassLoaderis&quot;+ClassLoaderDemo.class.getClassLoader().getParent().getParent());}}OutputClassLodarDemo'sClassLoaderissun.misc.Launcher$AppClassLoader@18b4aac2TheParentofClassLodarDemo'sClassLoaderissun.misc.Launcher$ExtClassLoader@1b6d3586TheGrandParentofClassLodarDemo'sClassLoaderisnullAppClassLoader的父类加载器为ExtClassLoaderExtClassLoader的父类加载器为null，null并不代表ExtClassLoader没有父类加载器，而是BootstrapClassLoader。1.双亲委派模型的好处双亲委派模型保证了Java程序的稳定运行，可以避免类的重复加载（JVM区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了Java的核心API不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为java.lang.Object类的话，那么程序运行的时候，系统就会出现多个不同的Object类。2.双亲委派模型实现源码分析双亲委派模型的实现代码非常简单，逻辑非常清晰，都集中在java.lang.ClassLoader的loadClass()中，相关代码如下所示。privatefinalClassLoaderparent;protectedClass&lt;?&gt;loadClass(Stringname,booleanresolve)throwsClassNotFoundException{synchronized(getClassLoadingLock(name)){//首先，检查请求的类是否已经被加载过，这是个native方法Class&lt;?&gt;c=findLoadedClass(name);if(c==null){longt0=System.nanoTime();try{if(parent!=null){//父加载器不为空，调用父加载器loadClass()方法处理c=parent.loadClass(name,false);}else{//父加载器为空，使用启动类加载器BootstrapClassLoader加载c=findBootstrapClassOrNull(name);}}catch(ClassNotFoundExceptione){//抛出异常说明父类加载器无法完成加载请求}if(c==null){longt1=System.nanoTime();//自己尝试加载c=findClass(name);//thisisthedefiningclassloader;recordthestatssun.misc.PerfCounter.getParentDelegationTime().addTime(t1-t0);sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);sun.misc.PerfCounter.getFindClasses().increment();}}if(resolve){resolveClass(c);}returnc;}}3.如果我们不想用双亲委派模型怎么办？为了避免双亲委托机制，我们可以自己定义一个类加载器，然后重写loadClass()即可。4.ClassLoader.loadClass和Class.forName的区别ClassLoader就是遵循双亲委派模型最终调用启动类加载器的类加载器，实现的功能是“通过一个类的全限定名来获取描述此类的二进制字节流”，获取到二进制流后放到JVM中。Class.forName()方法实际上也是调用的CLassLoader来实现的。Class.forName加载类时将类进了初始化，而ClassLoader的loadClass并没有对类进行初始化，只是把类加载到了虚拟机中。在我们熟悉的Spring框架中的IOC的实现就是使用的ClassLoader。而在我们使用JDBC时通常是使用Class.forName()方法来加载数据库连接驱动。如果用ClassLoader.loadClass(&quot;&quot;)将不会执行静态代码块，当然也不能注册驱动了。","link":"https://xzzz2020.github.io/post/jTbAiVT5N/"},{"title":"【总结】类加载过程","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：JVM专栏一、类的加载过程二、加载三、验证四、准备五、解析六、初始化七、卸载一、类的加载过程分为三大阶段加载:查找并且加载类的二进制数据链接：验证:确保被加载类的正确性准备:为类的静态变量分配内存，并将其初始化为默认值解析:把类中的符号引用转换为直接引用初始化:执行构造方法二、加载类加载过程的第一步，主要完成下面3件事情：通过全类名获取定义此类的二进制字节流将字节流所代表的静态存储结构转换为方法区的运行时数据结构在内存中生成一个代表该类的Class对象,作为方法区这些数据的访问入口一个非数组类的加载阶段（加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，这一步我们可以去完成还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的loadClass()方法）。数组类型不通过类加载器创建，它由Java虚拟机直接创建。三、验证主要目的：检查输入的字节流。为了确保当前加载的Class字节流符合虚拟机的要求，不会危害到虚拟机检验动作文件格式验证。判断当前字节流是否符合Class文件格式要求。原数据验证。语义分析，判断数据类型是否符合Java语言规范字节码验证。判断方法是否符合Java语言规范符号引用验证。判断能否找到所引用的类四、准备目的：给类中静态变量赋予初值，其他的变量随着类的初始化，跟类存放在堆中五、解析目的：将常量池中的符号引用变成直接引用六、初始化目的：初始化是类加载的最后一步，初始化阶段是执行类构造器&lt;clinit&gt;()方法的过程七、卸载卸载类即该类的Class对象被GC。卸载类需要满足3个要求:该类的所有的实例对象都已被GC，也就是说堆不存在该类的实例对象。该类没有在其他任何地方被引用该类的类加载器的实例已被GC所以，在JVM生命周期类，由jvm自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。","link":"https://xzzz2020.github.io/post/FOuttAozI/"},{"title":"【总结】Redis主从复制","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：Redis专栏1.复制的完整流程2.数据同步相关的核心机制3.全量复制4.增量复制5.heartbeat6.异步复制7.主从复制流程1.复制的完整流程slavenode启动，仅仅保存masternode的信息，包括masternode的host和ip，但是复制流程没开始masterhost和ip是在redis.conf里面的slaveof配置的slavenode内部有个定时任务，每秒检查是否有新的masternode要连接和复制，如果发现，就跟masternode建立socket网络连接slavenode发送ping命令给masternode口令认证，如果master设置了requirepass，那么salvenode必须发送masterauth的口令过去进行认证masternode第一次执行全量复制，将所有数据发给slavenodemasternode后续持续将写命令，异步复制给slavenode2.数据同步相关的核心机制指的就是第一次slave连接msater的时候，执行的全量复制，那个过程里面你的一些细节的机制（1）master和slave都会维护一个offsetmaster会在自身不断累加offset，slave也会在自身不断累加offsetslave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset这个倒不是说特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况（2）backlogmasternode有一个backlog，默认是1MB大小masternode给slavenode复制数据时，也会将数据在backlog中同步写一份backlog主要是用来做全量复制中断后的增量复制的（3）masterrunidinfoserver，可以看到masterrunid如果根据host+ip定位masternode，是不靠谱的，如果masternode重启或者数据出现了变化，那么slavenode应该根据不同的runid区分，runid不同就做全量复制如果需要不更改runid重启redis，可以使用redis-clidebugreload命令（4）psync从节点使用psync从masternode进行复制，psyncrunidoffsetmasternode会根据自身的情况返回响应信息，可能是FULLRESYNCrunidoffset触发全量复制，可能是CONTINUE触发增量复制3.全量复制master执行bgsave，在本地生成一份rdb快照文件masternode将rdb快照文件发送给salvenode，如果rdb复制时间超过60秒（repl-timeout），那么slavenode就会认为复制失败，可以适当调节大这个参数对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60smasternode在生成rdb时，会将所有新的写命令缓存在内存中，在salvenode保存了rdb之后，再将新的写命令复制给salvenodeclient-output-buffer-limitslave256MB64MB60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败slavenode接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务如果slavenode开启了AOF，那么会立即执行BGREWRITEAOF，重写AOFrdb生成、rdb通过网络拷贝、slave旧数据的清理、slaveaofrewrite，很耗费时间如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟4.增量复制如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制master直接从自己的backlog中获取部分丢失的数据，发送给slavenode，默认backlog就是1MBmsater就是根据slave发送的psync中的offset来从backlog中获取数据的5.heartbeat主从节点互相都会发送heartbeat信息master默认每隔10秒发送一次heartbeat，salvenode每隔1秒发送一个heartbeat6.异步复制master每次接收到写命令之后，现在内部写入数据，然后异步发送给slavenode7.主从复制流程主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；主服务器每执行一次写命令，就向从服务器发送相同的写命令。","link":"https://xzzz2020.github.io/post/y9Xr-Nu8H/"},{"title":"【总结】Redis哨兵","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：Redis专栏一、哨兵的介绍二、哨兵的核心知识三、为什么redis哨兵集群只有2个节点无法正常工作？四、经典的3节点哨兵集群五、两种数据丢失的情况1.异步复制导致的数据丢失2.脑裂导致的数据丢失3.解决六、sdown和odown转换机制七、哨兵集群的自动发现机制八、slave配置的自动纠正九、slave-&gt;master选举算法十、quorum和majority十一、configurationepoch十二、configuraiton传播一、哨兵的介绍sentinal，中文名是哨兵，是启动Redis后一个额外的进程，哨兵是redis集群架构中非常重要的一个组件，主要功能如下：集群监控，负责监控redismaster和slave进程是否正常工作消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员故障转移，如果masternode挂掉了，会自动转移到slavenode上配置中心，如果故障转移发生了，通知client客户端新的master地址哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作：故障转移时，判断一个masternode是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了目前采用的是sentinal2版本，sentinal2相对于sentinal1来说，重写了很多代码，主要是让故障转移的机制和算法变得更加健壮和简单二、哨兵的核心知识哨兵至少需要3个实例，来保证自己的健壮性哨兵+redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性对于哨兵+redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练三、为什么redis哨兵集群只有2个节点无法正常工作？哨兵集群必须部署2个以上节点如果哨兵集群仅仅部署了个2个哨兵实例，quorum=1+----++----+|M1|---------|R1||S1||S2|+----++----+Configuration:quorum=1master宕机，s1和s2中只要有1个哨兵认为master宕机就可以还行切换，同时s1和s2中会选举出一个哨兵来执行故障转移同时这个时候，需要majority，也就是大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority=2，3的majority=2，5的majority=3，4的majority=2），2个哨兵都运行着，就可以允许执行故障转移但是如果整个M1和S1运行的机器宕机了，那么哨兵只有1个了，此时就没有majority来允许执行故障转移，虽然另外一台机器还有一个R1，但是故障转移不会执行四、经典的3节点哨兵集群+----+|M1||S1|+----+|+----+|+----+|R2|----+----|R3||S2||S3|+----++----+Configuration:quorum=2，majority如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移五、两种数据丢失的情况主备切换的过程，可能会导致数据丢失1.异步复制导致的数据丢失因为master-&gt;slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了2.脑裂导致的数据丢失脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master这个时候，集群里就会有两个master，也就是所谓的脑裂此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据，网络分区写入的数据就会丢失3.解决配置Redis的主节点，要求只少有n台机器同步时间小于m秒，如果不满足情况，Redis会拒绝写入，这样最多丢失m秒的数据客户端通过降级和限流，控制请求，同时可以把数据写入本地磁盘或者消息队列，等待Redis重启六、sdown和odown转换机制sdown和odown两种失败状态：sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机sdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机七、哨兵集群的自动发现机制哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往_sentinel_:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在每隔两秒钟，每个哨兵都会往自己监控的某个master+slaves对应的_sentinel_:hellochannel里发送一个消息，内容是自己的host、ip和runid还有对这个master的监控配置每个哨兵也会去监听自己监控的每个master+slaves对应的_sentinel_:hellochannel，然后去感知到同样在监听这个master+slaves的其他哨兵的存在每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步八、slave配置的自动纠正哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保slave复制新master的数据;如果slave连接到了一个错误的master上，比如故障转移之后，那么哨兵会确保它们连接到正确的master上九、slave-&gt;master选举算法如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个新master来会考虑slave的一些信息：跟master断开连接的时长slave优先级复制offsetrunid如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master(down-after-milliseconds*10)+milliseconds_since_master_is_in_SDOWN_state接下来会对slave进行排序：按照slave优先级进行排序，slavepriority越低，优先级就越高如果slavepriority相同，那么看replicaoffset，哪个slave复制了越多的数据，offset越靠后，优先级就越高如果上面两个条件都相同，那么选择一个runid比较小的那个slave十、quorum和majoritymajority取值如下:n=2，majority=2n=3，majority=2n=4，majority=2n=5，majority=3每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还得得到majority哨兵的授权，才能正式执行切换如果quorum&lt;majority，比如5个哨兵，majority就是3，quorum设置为2，那么就3个哨兵授权就可以执行切换但是如果quorum&gt;=majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换十一、configurationepoch哨兵会对一套redismaster+slave进行监控，有相应的监控的配置执行切换的那个哨兵，会从要切换到的新master（salve-&gt;master）那里得到一个configurationepoch，这就是一个version号，每次切换的version号都必须是唯一的如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configurationepoch，作为新的version号十二、configuraiton传播哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制这里之前的version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的其他的哨兵都是根据版本号的大小来更新自己的master配置的","link":"https://xzzz2020.github.io/post/XQ2Qib6Xc/"},{"title":"【总结】Redis配置","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：Redis专栏一、容灾策略1.如何配置RDB持久化机制2.RDB持久化机制的工作流程3.AOF持久化的配置4.AOFrewrite5.AOF破损文件的修复6.AOF和RDB同时工作7.企业级的备份策略二、读写分离1.redisreplication主从复制过程2.主从搭建从节点主节点读写分离架构的测试3.快速压测三、哨兵配置1.解决异步复制和脑裂导致的数据丢失2.配置经典三节点哨兵3.常用命令四、Redis-cluster集群配置1.rediscluster的重要配置2.编写配置文件3.准备环境4.创建集群5.添加删除节点一、容灾策略1.如何配置RDB持久化机制redis.conf文件，也就是/etc/redis/6379.conf，去配置持久化save9001save30010save6010000每隔60s，如果有超过1000个key发生了变更，那么就生成一个新的dump.rdb文件，就是当前redis内存中完整的数据快照，这个操作也被称之为snapshotting，快照也可以手动调用save或者bgsave命令，同步或异步执行rdb快照生成save可以设置多个，就是多个snapshotting检查点，每到一个检查点，就会去check一下，是否有指定的key数量发生了变更，如果有，就生成一个新的dump.rdb文件2.RDB持久化机制的工作流程（1）redis根据配置自己尝试去生成rdb快照文件（2）fork一个子进程出来（3）子进程尝试将数据dump到临时的rdb快照文件中（4）完成rdb快照文件的生成之后，就替换之前的旧的快照文件dump.rdb，每次生成一个新的快照，都会覆盖之前的老快照3.AOF持久化的配置AOF持久化，默认是关闭的，默认是打开RDB持久化appendonlyyes，可以打开AOF持久化机制，在生产环境里面，一般来说AOF都是要打开的，除非你说随便丢个几分钟的数据也无所谓打开AOF持久化机制之后，redis每次接收到一条写命令，就会写入日志文件中，当然是先写入oscache的，然后每隔一定时间再fsync一下而且即使AOF和RDB都开启了，redis重启的时候，也是优先通过AOF进行数据恢复的，因为aof数据比较完整可以配置AOF的fsync策略，有三种策略可以选择，一种是每次写入一条数据就执行一次fsync;一种是每隔一秒执行一次fsync;一种是不主动执行fsyncalways:每次写入一条数据，立即将这个数据对应的写日志fsync到磁盘上去，性能非常非常差，吞吐量很低;确保说redis里的数据一条都不丢，那就只能这样了everysec:每秒将oscache中的数据fsync到磁盘，这个最常用的，生产环境一般都这么配置，性能很高，QPS还是可以上万的，但是可能会失去一秒的数据no:仅仅redis负责将数据写入oscache就撒手不管了，然后后面os自己会时不时有自己的策略将数据刷入磁盘，不可控了#appendfsyncalwaysappendfsynceverysec#appendfsyncno4.AOFrewriteredis中的数据其实有限的，很多数据可能会自动过期，可能会被用户删除，可能会被redis用缓存清除的算法清理掉。redis中的数据会不断淘汰掉旧的，就一部分常用的数据会被自动保留在redis内存中所以可能很多之前的已经被清理掉的数据，对应的写日志还停留在AOF中，AOF日志文件就一个，会不断的膨胀，到很大很大。所以AOF会自动在后台每隔一定时间做rewrite操作，比如日志里已经存放了针对100w数据的写日志了;redis内存只剩下10万;基于内存中当前的10万数据构建一套最新的日志，到AOF中;覆盖之前的老日志;确保AOF日志文件不会过大，保持跟redis内存数据量一致no-appendfsync-on-rewriteno当进行rewrite操作时，涉及大量磁盘操作，这样就会造成主进程在写aof文件的时候出现阻塞的情形，设置成no意思就是接受阻塞，而设置成yes则相当于将appendfsync设置为no，将可能丢失30s的数据如果应用系统无法忍受延迟，而可以容忍少量的数据丢失，则设置为yes；如果应用系统无法忍受数据丢失，则设置为no。在redis.conf中，可以配置rewrite策略auto-aof-rewrite-percentage100#增长超过100%的比例auto-aof-rewrite-min-size64mb#最小的重写大小每一次rewrite之后会记住当前文件的大小，当文件大小超过一定比例时就会进行rewrite比如说上一次AOFrewrite之后，是128mb然后就会接着128mb继续写AOF的日志，如果发现增长的比例，超过了之前的100%，256mb，就可能会去触发一次rewrite但是此时还要去跟min-size，64mb去比较，256mb&gt;64mb，才会去触发rewrite重写的过程：redisfork一个子进程子进程基于当前内存中的数据，构建日志，开始往一个新的临时的AOF文件中写入日志redis主进程，接收到client新的写操作之后，在内存中写入日志，同时新的日志也继续写入旧的AOF文件子进程写完新的日志文件之后，redis主进程将内存中的新日志再次追加到新的AOF文件中用新的日志文件替换掉旧的日志文件5.AOF破损文件的修复如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损用redis-check-aof--fix命令来修复破损的AOF文件，就是删除那些破损的命令6.AOF和RDB同时工作RDB和AOF重写同一时间只会执行一个同时有RDBsnapshot文件和AOF日志文件，那么redis重启的时候，会优先使用AOF进行数据恢复，因为其中的日志更完整7.企业级的备份策略RDB中每隔一分钟更改的数据量为多少需要根据业务需求改变博主设置的为save601000AOF一定要打开，fsync磁盘刷新策略使用everysec，重写策略采用就是超过100%，最小大小设置为16mbauto-aof-rewrite-percentage100auto-aof-rewrite-min-size16mb然后设置定时任务每天和每个小时都做一个备份，然后每天都将备份上传到云服务器上备份也可以避免上线出现的BUG，比如12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据二、读写分离单机Redis最高不超过10万QPS，一般情况下，大量的请求都是读请求1.redisreplication主从复制过程千万不能关闭主节点的持久化，否则一旦重启主节点，数据将是空，然后将全部的从节点也变成空当启动一个slavenode的时候，它会发送一个PSYNC命令给masternode如果这是slavenode重新连接masternode，那么masternode仅仅会复制给slave部分缺少的数据;否则如果是slavenode第一次连接masternode，那么会触发一次全量复制全量复制master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕之后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，slave也会同步这些数据。如果发现有多个slavenode都来重新连接，仅仅会启动一个rdbsave操作，用一份数据服务所有slavenode。异步同步当给一个主节点写一条数据的时候，会直接返回给客户端写入成功，然后在异步的把这个命令同步给从节点断点续传如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份无磁盘化同步master在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了repl-diskless-syncyes#开启无磁盘化，默认是falserepl-diskless-sync-delay5#等待一定时长再开始复制，因为要等更多slave重新连接过来，默认等待5秒过期key处理slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。2.主从搭建从节点修改绑定的IP地址bind0.0.0.0配置从节点slaveof192.168.xxx.xxx6379强制读写分离slave-read-onlyyes开启了只读的redisslavenode，会拒绝所有的写操作，这样可以强制搭建成读写分离的架构集群安全认证masterauthredis-pass#master连接口令主节点修改绑定的IP地址bind0.0.0.0集群安全认证requirepassredis-pass#master上启用安全认证读写分离架构的测试先启动主节点，eshop-cache01上的redis实例再启动从节点，eshop-cache02上的redis实例使用命令查看各个节点状态redis-cli-aredis-passinforeplication3.快速压测redis-3.2.8/src./redis-benchmark-heshop-cache01-c&lt;clients&gt;Numberofparallelconnections(default50)-n&lt;requests&gt;Totalnumberofrequests(default100000)-d&lt;size&gt;DatasizeofSET/GETvalueinbytes(default2)根据你自己的高峰期的访问量，在高峰期，瞬时最大用户量会达到10万+，-c100000，-n10000000，-d50三、哨兵配置1.解决异步复制和脑裂导致的数据丢失min-slaves-to-write1#从服务器的数量少于1个，或者小于1个从服务器的延迟（lag）值都小于等于10秒时min-slaves-max-lag10#允许丢失多长时间的数据量要求至少有一个slave数据复制和同步的延迟不能超过10秒如果说一旦所有的slaves，数据复制和同步的延迟都超过了10秒钟，或者当前连接的slave数少于1，那么这个时候，master将会变成只读上面两个配置可以减少异步复制和脑裂导致的数据丢失（1）减少异步复制的数据丢失有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内（2）减少脑裂的数据丢失如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失上面的配置就确保了，如果跟所有的slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求因此在脑裂场景下，最多就丢失10秒的数据2.配置经典三节点哨兵哨兵的配置文件在sentinel.conf每一个哨兵都可以去监控多个maser-slaves的主从架构因为可能你的公司里，为不同的项目，部署了多个master-slaves的redis主从集群相同的一套哨兵集群，就可以去监控不同的多个redis主从集群你自己给每个redis主从集群分配一个逻辑的名称类似这种配置，来指定对一个master的监控，给监控的master指定的一个名称，因为后面分布式集群架构里会讲解，可以配置多个master做数据拆分核心配置：sentineldown-after-millisecondsmymaster60000#哨兵主管认为的宕机时间（60s）sentinelfailover-timeoutmymaster180000#一台机器故障转移超时时间（180s）sentinelparallel-syncsmymaster1#故障转移每次转移几台机器上面的三个配置，都是针对某个监控的master配置的，给其指定上面分配的名称即可上面这段配置，就监控了两个masternode这是最小的哨兵配置，如果发生了master-slave故障转移，或者新的哨兵进程加入哨兵集群，那么哨兵会自动更新自己的配置文件sentinelmonitormaster-group-namehostnameportquorumquorum的解释如下：至少多少个哨兵要一致同意，master进程挂掉了，或者slave进程挂掉了，或者要启动一个故障转移操作quorum是用来识别故障的，真正执行故障转移的时候，还是要在哨兵集群执行选举，选举一个哨兵进程出来执行故障转移操作假设有5个哨兵，quorum设置了2，那么如果5个哨兵中的2个都认为master挂掉了;2个哨兵中的一个就会做一个选举，选举一个哨兵出来，执行故障转移;如果5个哨兵中有3个哨兵都是运行的，那么故障转移就会被允许执行down-after-milliseconds超过多少毫秒跟一个redis实例断了连接，哨兵就可能认为这个redis实例挂了parallel-syncs新的master别切换之后，同时有多少个slave被切换到去连接新master，重新做同步，数字越低，花费的时间越多假设你的redis是1个master，4个slave然后master宕机了，4个slave中有1个切换成了master，剩下3个slave就要挂到新的master上面去这个时候，如果parallel-syncs是1，那么3个slave，一个一个地挂接到新的master上面去，1个挂接完，而且从新的mastersync完数据之后，再挂接下一个如果parallel-syncs是3，那么一次性就会把所有slave挂接到新的master上去failover-timeout执行故障转移的timeout超时时长配置sentinalmkdir/etc/sentinalmkdir-p/var/sentinal/5000mkdir-p/var/log/sentinal/5000cp/var/sentinal/5000/26379.log/var/log/sentinal/5000/5000.logcp/usr/local/redis/redis-3.2.8/sentinel.conf/etc/sentinal/5000.confvi/etc/sentinal/5000.conf详细配置port5000bind0.0.0.0dir/var/sentinal/5000sentinelmonitormymaster192.168.31.18763792sentineldown-after-millisecondsmymaster30000sentinelfailover-timeoutmymaster60000sentinelparallel-syncsmymaster1daemonizeyes#配置成后台进程logfile/var/log/sentinal/5000/5000.logsentinelauth-passmymasterredis-pass#配置主节点的密码启动哨兵redis-sentinel/etc/sentinal/5000.conf连接哨兵查看状态redis-cli-h127.0.0.1-p5000infosentinel#展示基本信息日志里会显示出来，每个哨兵都能去监控到对应的redismaster，并能够自动发现对应的slave哨兵之间，互相会自动进行发现，用的就是之前说的pub/sub，消息发布和订阅channel消息系统和机制3.常用命令增加sentinal，会自动发现删除sentinal的步骤停止sentinal进程SENTINELRESET*#在所有sentinal上执行，清理所有的master状态slave的永久下线SENTINELRESETmymaster#让master摘除某个已经下线的slave四、Redis-cluster集群配置1.rediscluster的重要配置cluster-enabled&lt;yes/no&gt;：开启集群cluster-config-file&lt;filename&gt;：这是指定一个文件，供cluster模式下的redis实例将集群状态保存在那里，包括集群中其他机器的信息，比如节点的上线和下限，故障转移，不是我们去维护的，给它指定一个文件，让redis自己去维护的cluster-node-timeout&lt;milliseconds&gt;：节点存活超时时长，超过一定时长，认为节点宕机，master宕机的话就会触发主备切换，slave宕机就不会提供服务2.编写配置文件port7001cluster-enabledyescluster-config-file/etc/redis-cluster/node-7001.confcluster-node-timeout15000daemonizeyespidfile/var/run/redis_7001.piddir/var/redis/7001logfile/var/log/redis/7001.logbind192.168.31.187appendonlyyes3.准备环境准备启动脚本并启动mkdir-p/etc/redis-clustermkdir-p/var/log/redismkdir-p/var/redis/7001mkdir-p/var/redis/7002cd/etc/init.dcpredis_63797001_rediscpredis_63797002_redisvi7001_redisvi7002_redis./7002_redisstart./7002_redisstart4.创建集群wgethttps://cache.ruby-lang.org/pub/ruby/2.3/ruby-2.3.1.tar.gztar-zxvfruby-2.3.1.tar.gz./configure-prefix=/usr/local/rubymake&amp;&amp;makeinstallcd/usr/local/ruby/ruby-2.3.1cpbin/ruby/usr/local/bincpbin/gem/usr/local/binwgethttp://rubygems.org/downloads/redis-3.3.0.gemgeminstall-l./redis-3.3.0.gemgemlist--checkredisgemcp/usr/local/redis-3.2.8/src/redis-trib.rb/usr/local/binredis-trib.rbcreate--replicas1192.168.31.187:7001192.168.31.187:7002192.168.31.19:7003192.168.31.19:7004192.168.31.227:7005192.168.31.227:7006redis-trib.rbcheck192.168.31.187:70015.添加删除节点添加redis-trib.rbadd-node192.168.31.227:7007192.168.31.187:7001redis-trib.rbreshard192.168.31.187:7001#迁移slot到一个node的id删除先用resharding将数据都移除到其他节点，确保node为空之后，才能执行remove操作redis-trib.rbdel-node192.168.31.187:7001bd5a40a6ddccbd46a0f4a2208eb25d2453c2a8db","link":"https://xzzz2020.github.io/post/IAIpFCygR/"},{"title":"【总结】Redis基础","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：Redis专栏一、简单介绍一下Redis二、五种数据结构1.字符串string2.列表list3.字典hash4.集合set5.有序列表zset二、Redis和Memcached的区别？三、为什么Redis那么快？四、从海量Key里查询出某一固定前缀的Key？五、如何用Redis实现异步消息队列六、Redis有哪些使用场景？七、redis的删除策略有哪些八、什么是布隆过滤器？1.原理2.使用场景九、缓存穿透有哪些解决办法？十、缓存雪崩十一、缓存预热十二、缓存降级十三、过期键的删除策略十四、Redis的内存用完了会发生什么？十五、Redis事务相关一、简单介绍一下Redis一个C语言开发的数据库，是一个非关系型数据库，不过与传统数据库不同的是Redis的数据是存在内存中的，同时，所以读写速度非常快，因此Redis被广泛应用于缓存方向。除了做缓存之外，Redis也经常用来做分布式锁Redis提供了多种数据类型来支持不同的业务场景。Redis还支持事务、持久化、Lua脚本、多种集群方案。二、五种数据结构Redis有5种基础数据结构，它们分别是：string(字符串)、list(列表)、hash(字典)、set(集合)和zset(有序集合)。每种数据结构都有自己底层的内部编码实现，而且是多种实现，这样Redis会在合适的场景选择合适的内部编码。可以看到每种数据结构都有两种以上的内部编码实现，例如string数据结构就包含了raw、int和embstr三种内部编码。同时，有些内部编码可以作为多种外部数据结构的内部实现，例如ziplist就是hash、list和zset共有的内部编码。1.字符串stringRedis中的字符串是一种动态字符串，这意味着使用者可以修改，它的底层实现有点类似于Java中的ArrayList，有一个字符数组为什么对于String这同样一组结构，Redis使用泛型定义了好多次，而不直接使用int定义一组结构？对于字符串的定义是SDS，结构里不直接使用int类型定义的原因是：当字符串比较短的时候，像长度len就可以用byte和short表示，为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。struct__attribute__((__packed__))sdshdr8{uint8_tlen;/*used*/uint8_talloc;/*excludingtheheaderandnullterminator*/unsignedcharflags;/*3lsboftype,5unusedbits*/charbuf[];};SDS与C字符串的区别？因为C语言这种简单的字符串表示方式不符合Redis对字符串在安全性、效率以及功能方面的要求。例如C语言使用了一个长度为N+1的字符数组来表示长度为N的字符串，并且字符数组最后一个元素总是'\\0'这样简单的数据结构可能会造成一些问题，比如获取字符串长度为O(N)级别的操作，因为C不保存数组的长度，每次都需要遍历一遍整个数组；不能很好的杜绝缓冲区溢出或者内存泄漏的问题，比如在做拼接字符串的时候，如果操作不当，就很容易出现问题；C字符串只能保存文本数据，因为C语言中的字符串必须符合某种编码（比如ASCII），例如中间出现的'\\0'可能会被判定为提前结束的字符串而识别不了；Redis规定了字符串的长度不得超过512MB常用的操作有哪些？通常使用SET和GET来设置和获取字符串值。还可以使用EXISTS和DEL关键字来查询是否存在和删除键值对还可以用EXPIRE设置过期时间可以进行原子的递增INCR或递减DECRSET+EXPIRE+NX实现分布式锁，SETkeyvalue[EXseconds]NXEX2.列表listRedis的列表相当于Java语言中的LinkedList，注意它是链表而不是数组。这意味着list的插入和删除操作非常快，时间复杂度为O(1)，但是索引定位很慢，时间复杂度为O(n)。底层定义一个头指针和尾指针实现双向链表，也就是可以实现队列和栈的功能typedefstructlist{listNode*head;listNode*tail;void*(*dup)(void*ptr);void(*free)(void*ptr);int(*match)(void*ptr,void*key);unsignedlonglen;}list;基本操作LPUSH和RPUSH分别可以向list的左边（头部）和右边（尾部）添加一个新元素；LRANGE命令可以从list中取出一定范围的元素；3.字典hashRedis中的字典相当于Java中的HashMap，内部实现也差不多类似，都是通过&quot;数组+链表&quot;的链地址法来解决部分哈希冲突，同时这样的结构也吸收了两种不同数据结构的优点。内部定义就是哈希表，但是实际上定义了两个HashTable，而一般只使用其中一个，另一个用于渐进式Rehashtypedefstructdictht{//哈希表数组dictEntry**table;//哈希表大小unsignedlongsize;//哈希表大小掩码，用于计算索引值，总是等于size-1unsignedlongsizemask;//该哈希表已有节点的数量unsignedlongused;}dictht;typedefstructdict{dictType*type;void*privdata;//内部有两个dictht结构dicththt[2];longrehashidx;/*rehashingnotinprogressifrehashidx==-1*/unsignedlongiterators;/*numberofiteratorscurrentlyrunning*/}dict;渐进式ReHash大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的Redis很难承受这样耗时的过程渐进式rehash会在rehash的同时，保留新旧两个hash结构，然后在后续的定时任务以及hash操作指令中，循序渐进的把旧字典的内容迁移到新字典中。当搬迁完成了，就会使用新的hash结构取而代之。扩容和缩容正常情况下，当hash表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的2倍，不过如果Redis正在做bgsave(持久化命令)，Redis尽量不去扩容，但是如果hash表非常满了，达到了第一维数组长度的5倍了，这个时候就会强制扩容。元素个数低于数组长度的10%就会缩容，缩容不会考虑Redis是否在做持久化。和String的取舍Hash使用上相当于一个key存储了多个String，但是底层更加复杂，占的空间更大一般用Hash存储对象，但是String也可以存储转换成JSON串的对象4.集合setRedis的集合相当于Java语言中的HashSet，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典，字典中所有的value都是一个值NULL。5.有序列表zset类似于Java中SortedSet，内部实现用的是一种叫做「跳跃表」的数据结构什么是跳跃表，可以看看这篇文章二、Redis和Memcached的区别？两者都是非关系型内存键值数据库数据类型：Memcached仅支持字符串类型，而Redis支持五种不同的数据类型，可以更灵活地解决问题。数据持久化：Redis支持两种持久化策略：RDB快照和AOF日志，而Memcached不支持持久化。分布式：Memcached不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。RedisCluster实现了分布式的支持主从：Memcached不支持主从，而Redis支持内存管理机制：在Redis中，并不是所有数据都一直存储在内存中，可以将一些很久没用的value交换到磁盘，而Memcached的数据则会一直在内存中。vm-enabledyes#开启虚拟内存功能vm-max-memory268435456#redis使用的最大内存上限（256MB），超过上限后redis开始交换value到磁盘swap文件中。建议设置为系统空闲内存的60%-80%vm-swap-file/tmp/redis.swap#交换出来value保存的文件路径/tmp/redis.swap三、为什么Redis那么快？完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高数据结构简单，对数据操作也简单，主要都是key-value，类似于hashmap实用的单线程，在高并发的时候，避免了线程切换和锁的竞争使用多路I/O复用模型，非阻塞IO，通过多路复用函数，检测文件是否可读和可写的状态四、从海量Key里查询出某一固定前缀的Key？在回答问题之前，需要注意一下:摸清数据规模，问清楚边界如果直接使用keys指令，但是这个这个指令是O(n)，会阻塞当前的redis可以使用scan指令，每次执行都只会返回少量元素，是一个基于游标的迭代器。这意味着命令每次被调用都需要使用上一次这个调用返回的游标作为该次调用的游标参数，以此来延续之前的迭代过程，可以使用给定一个count来控制返回的结果数，但是并不会严格的控制，但是这个可能会获取到重复的key，可以使用HashSet去重五、如何用Redis实现异步消息队列方案一可以使用list这个数据结构实现，使用rpush和lpop实现但是当队列中没有元素，可以在Java端加一个sleep去等待生产者产生新的元素也可以使用blpop+timeout阻塞住，等待队列中有新的元素方案二pub/sub:主题订阅者模式，发送者(pub)发送消息，订阅者(sub)接收消息，可以订阅多个频道解决了方案一只能让一个消费者消费的问题但是消息的发布是无状态的，无法保证消息是否可达六、Redis有哪些使用场景？计数器：可以对String进行自增自减运算，从而实现计数器功能。缓存：将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。消息队列：List是一个双向链表，可以通过lpush和rpop写入和读取消息，不过最好使用RocketMq分布式Session：可以使用Redis来统一存储多台应用服务器的会话信息分布式锁实现：在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步，可以使用Redis自带的SETNX命令实现分布式锁，除此之外，还可以使用官方提供的RedLock分布式锁实现。七、redis的删除策略有哪些主要分成两大类，一个是对设置缓存时间的淘汰以及对所有数据进行淘汰对于缓存策略都存在一个是LRU、一个是随机，在Redis4.0之后，引入了LFU。LRU是淘汰最近使用时间最久远的，LFU是淘汰最近使用频率最小的对于设置缓存时间的，还可以淘汰快要过期的最后一个策略是不允许淘汰Redis具体有6种淘汰策略：策略描述volatile-lru从已设置过期时间的数据集中挑选最近最少使用的数据淘汰volatile-ttl从已设置过期时间的数据集中挑选将要过期的数据淘汰volatile-random从已设置过期时间的数据集中任意选择数据淘汰allkeys-lru从所有数据集中挑选最近最少使用的数据淘汰allkeys-random从所有数据集中任意选择数据进行淘汰noeviction禁止驱逐数据作为内存数据库，出于对性能和内存消耗的考虑，Redis的淘汰算法实际实现上并非针对所有key，而是抽样一小部分并且从中选出被淘汰的key使用Redis缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用allkeys-lru淘汰策略，将最近最少使用的数据淘汰Redis4.0引入了volatile-lfu和allkeys-lfu淘汰策略，LFU策略通过统计访问频率，将访问频率最少的键值对淘汰。八、什么是布隆过滤器？可以把它简单理解为一个不怎么精确的set结构，当你使用它的contains方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那么一定不存在。1.原理布隆过滤器本质上是由长度为m的位向量或位列表（仅包含0或1位值的列表）组成，最初所有的值均设置为0，所以我们先来创建一个稍微长一些的位向量用作展示：当我们向布隆过滤器中添加数据时，会使用多个hash函数对key进行运算，算得一个证书索引值，然后对位数组长度进行取模运算得到一个位置，每个hash函数都会算得一个不同的位置。再把位数组的这几个位置都置为1就完成了add操作，例如，我们添加一个wmyskxz：向布隆过滤器查查询key是否存在时，跟add操作一样，会把这个key通过相同的多个hash函数进行运算，查看对应的位置是否都为1，只要有一个位为0，那么说明布隆过滤器中这个key不存在。如果这几个位置都是1，并不能说明这个key一定存在，只能说极有可能存在，因为这些位置的1可能是因为其他的key存在导致的，因为Hash函数会存在哈希冲突的问题。注意：不要让实际元素数量远大于初始化数量2.使用场景大数据判断是否存在：这就可以实现出上述的去重功能，如果你的服务器内存足够大的话，那么使用HashMap可能是一个不错的解决方案，理论上时间复杂度可以达到O(1)的级别，但是当数据量起来之后，还是只能考虑布隆过滤器。解决缓存穿透：我们经常会把一些热点数据放在Redis中当作缓存，例如产品详情。通常一个请求过来之后我们会先查询缓存，而不用直接读取数据库，这是提升性能最简单也是最普遍的做法，但是如果一直请求一个不存在的缓存，那么此时一定不存在缓存，那就会有大量请求直接打到数据库上，造成缓存穿透，布隆过滤器也可以用来解决此类问题。九、缓存穿透缓存穿透说简单点就是大量请求的key根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的key发起大量请求，导致大量请求落到数据库。有哪些解决办法？最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库id不能小于0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。1）缓存无效key如果缓存和数据库都查不到某个key的数据就写一个到Redis中去并设置过期时间，具体命令如下：SETkeyvalueEX10086。这种方式可以解决请求的key变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求key，会导致Redis中缓存大量无效的key。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的key的过期时间设置短一点比如1分钟。2）布隆过滤器布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断key是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。加入布隆过滤器之后的缓存处理流程图如下。但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是：布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。我们先来看一下，当一个元素加入布隆过滤器中的时候，会进行哪些操作：使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。根据得到的哈希值，在位数组中把对应下标的值置为1。我们再来看一下，当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：对给定元素再次进行相同的哈希计算；得到值之后判断位数组中的每个元素是否都为1，如果值都为1，那么说明这个值在布隆过滤器中，如果存在一个值不为1，说明该元素不在布隆过滤器中。然后，一定会出现这样一种情况：不同的字符串可能哈希出来的位置相同。十、缓存雪崩缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。可能因为系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。也可能有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。Redis服务不可用：采用Redis集群，避免单机出现问题整个缓存服务都没办法使用。限流，避免同时处理大量的请求。热点缓存失效：设置不同的失效时间比如随机设置缓存的失效时间。缓存永不失效。十一、缓存预热缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！解决方案：直接写个缓存刷新页面，上线时手工操作一下；数据量不大，可以在项目启动的时候自动进行加载；定时刷新缓存；十二、缓存降级当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。缓存降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。服务降级的目的，是为了防止Redis服务故障，导致数据库跟着一起发生雪崩问题。因此，对于不重要的缓存数据，可以采取服务降级策略，例如一个比较常见的做法就是，Redis出现问题，不去数据库查询，而是直接返回默认值给用户。十三、过期键的删除策略过期策略通常有以下三种：定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果。(expires字典会保存所有设置了过期时间的key的过期时间数据，其中，key是指向键空间中的某个键的指针，value是该键的毫秒精度的UNIX时间戳表示的过期时间。键空间是指该Redis集群中保存的所有键。)十四、Redis的内存用完了会发生什么？如果达到设置的上限，Redis的写命令会返回错误信息（但是读命令还可以正常返回。）或者你可以配置内存淘汰机制，当Redis达到内存上限时会冲刷掉旧的内容。十五、Redis事务相关Redis事务的本质是通过一组命令的集合，去执行多个命令，一个事务中所有命令都会被序列化。redis不支持回滚，“Redis在事务失败时不进行回滚，而是继续执行余下的命令”，所以Redis的内部可以保持简单且快速。","link":"https://xzzz2020.github.io/post/xjKzNVypB/"},{"title":"【总结】Redis持久化","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：Redis专栏一、持久化的意义持久化详解1、RDB和AOF两种持久化机制的介绍2、RDB持久化机制的优点3、RDB持久化机制的缺点4、AOF持久化机制的优点5、AOF持久化机制的缺点6、RDB和AOF到底该如何选择主要解决以下问题：redis的持久化，RDB，AOF，区别，各自的特点是什么，适合什么场景redis的企业级的持久化方案是什么，是用来跟哪些企业级的场景结合起来使用的？？？一、持久化的意义比如你部署了一个redis，作为cache缓存，当然也可以保存一些较为重要的数据如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的持久化详解1、RDB和AOF两种持久化机制的介绍RDB持久化机制，对redis中的数据执行周期性的持久化AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集如果我们想要redis仅仅作为纯内存的缓存来用，那么可以禁止RDB和AOF所有的持久化机制通过RDB或AOF，都可以将redis内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云，云服务如果redis挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动redis，redis就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整。2、RDB持久化机制的优点（1）RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说Amazon的S3云服务上去，在国内可以是阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据（2）RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可（3）相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速3、RDB持久化机制的缺点（1）如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据（2）RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒4、AOF持久化机制的优点（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据（2）AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复（3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewritelog的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。（4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据5、AOF持久化机制的缺点（1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大（2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的6、RDB和AOF到底该如何选择（1）不要仅仅使用RDB，因为那样会导致你丢失很多数据（2）也不要仅仅使用AOF，因为那样有两个问题，第一，你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快;第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug（3）综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择;用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复","link":"https://xzzz2020.github.io/post/Y_OlIRTju/"},{"title":"【总结】跳跃表","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：Redis专栏一、为什么要使用跳跃表？二、什么是跳跃表？三、Redis实现一、为什么要使用跳跃表？Zset要支持随机的插入和删除，所以它不宜使用数组来实现，关于排序问题，我们也很容易就想到红黑树/平衡树这样的树形结构，为什么Redis不使用这样一些结构呢？性能考虑：在高并发的情况下，树形结构需要执行一些类似于rebalance这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部实现考虑：在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；大小考虑：平衡树结构更复杂，占的空间更多，而跳跃表相对简单二、什么是跳跃表？对于一个普通链表，需要这个链表按照score值进行排序，这也就意味着，当我们需要添加新的元素时，我们需要定位到插入点，这样才可以继续保证链表是有序的，通常我们会使用二分查找法，但二分查找是有序数组的，链表没办法进行位置定位，我们除了遍历整个找到第一个比给定数据大的节点为止（时间复杂度O(n))似乎没有更好的办法。假如我们每相邻两个节点之间就增加一个指针，让指针指向下下一个节点，如图所示：这样所有新增的指针连成了一个新的链表，但它包含的数据却只有原来的一半现在假设我们想要查找数据时，可以根据这条新的链表查找，如果碰到比待查找数据大的节点时，再回到原来的链表中进行查找，比如，我们想要查找7，查找的路径则是沿着下图中标注出的红色指针所指向的方向进行的：通过新增加的指针查找，我们不再需要与链表上的每一个节点逐一进行比较，这样改进之后需要比较的节点数大概只有原来的一半利用同样的方式，我们可以在新产生的链表上，继续为每两个相邻的节点增加一个指针，从而产生第三层链表：在这个新的三层链表结构中，我们试着查找13，那么沿着最上层链表首先比较的是11，发现11比13小，于是我们就知道只需要到11后面继续查找，从而一下子跳过了11前面的所有节点。可以想象，当链表足够长，这样的多层链表结构可以帮助我们跳过很多下层节点，从而加快查找的效率，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(logn)。但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。为了避免这一问题，不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。从上面的创建和插入的过程中可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点并不会影响到其他节点的层数，因此，插入操作只需要修改节点前后的指针，而不需要对多个节点都进行调整，这就降低了插入操作的复杂度。现在我们假设从我们刚才创建的这个结构中查找23这个不存在的数，那么查找路径会如下图：三、Redis实现随机层数：对于每一个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数，Redis跳跃表默认允许最大的层数是32插入节点实现：1.找到当前我需要插入的位置，其中包括相同score时的处理，如果值相同，则比较value值，是一个字符串的比较；2.创建新节点，调整前后的指针指向，完成插入元素排名的实现：跳跃表本身是有序的，Redis在skiplist的forward指针上进行了优化，给每一个forward指针都增加了span属性，用来表示从前一个节点沿着当前层的forward指针跳到当前这个节点中间会跳过多少个节点。","link":"https://xzzz2020.github.io/post/MiE8tJSYr/"},{"title":"【总结】网络原理","content":"一、简单介绍一下OSI和TCP/IP结构和功能，分别用到哪些协议？1.应用层2.运输层3.网络层4.数据链路层5.物理层二、TCP三次握手和四次挥手1.为什么要三次握手？2.为什么要四次挥手？三、TCP和UDP的区别四、TCP协议如何保证可靠传输4.1连续ARQ协议4.2滑动窗口和流量控制4.3拥塞控制五、在浏览器中输入url地址-&gt;&gt;显示主页的过程六、状态码九、各协议与HTTP协议的关系十、HTTP长连接和短连接十一、Cookie的作用是什么?和Session有什么区别？十二、HTTP1.0和HTTP1.1的主要区别是什么?十三、URI和URL的区别是什么?十四、HTTP和HTTPS的区别？十五、HTTP/2.0二进制分帧层服务端推送首部压缩十六、GET和POST的比较十七、Socket简介1.Socket的通讯流程2.利用Java实现Socket实现TCP和UDP一、简单介绍一下OSI和TCP/IP结构和功能，分别用到哪些协议？一般我们采用折中的思想，将计算系网络分为五层：应用层运输层网络层数据链路层物理层1.应用层**应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。**应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。常用的协议有：域名系统DNS协议支持万维网应用的HTTP协议支持电子邮件的SMTP协议简单介绍一下DNS协议负责将IP地址和域名相互映射，这样人们不需要记住复杂的IP地址，而只需要记住方便记忆的域名即可简单介绍一下Http协议所有的WWW（万维网）文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。支持客户/服务器模式，客户端可以发送请求，服务器会相应请求并返回数据2.运输层运输层(transportlayer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务。常用协议：传输控制协议TCP：面向连接的、可靠的用户数据协议UDP：面向无连接的、不可靠的3.网络层网络层的任务就是选择合适的网间路由和交换结点，确保数据及时传送。常用协议：IP协议4.数据链路层两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。5.物理层在物理层上所传送的数据单位是比特。物理层(physicallayer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。二、TCP三次握手和四次挥手1.为什么要三次握手？三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。第一次握手:建立连接时，客户端发送SYN包(syn=j)到服务器，并进入SYN_SEND状态,等待服务器确认;第二次握手:服务器收到SYN包,必须确认客户的SYN(ack=j+1),同时自己也发送一个SYN包(syn=k),即SYN+ACK包，此时服务器进入SYN_RECV状态:第三次握手:客户端收到服务器的SYN+ACK包,向服务器发送确认包ACK(ack=k+1),此包发送完毕,客户端和服务器进入ESTABLISHED状态,完成三次握手。目的是：为了初始化SequenceNumber的初始值，同时保证建立可靠的连接SYN和ACK中的SequenceNumber初始化使用了随机值，而每个包都有个序号，超时重传机制根据这个序号来判断确认收到了是哪个包。在三次握手的时候，告诉了对方初始化的序号是多少，这样就可以根据序号对应接下来哪些包收到了。首次握手的隐患---SYN超时Server收到Client的SYN,回复SYN-ACK的时候未收到ACK确认Server不断重试直至超时,Linux默认等待63秒才断开连接可能会遭到SYNFlood攻击，即恶意用户发送一个SYN后，就下线，让服务端等到63秒，最后导致SYN等待队列被占满，无法和正常的用户建立连接针对SYNFlood的防护措施SYN队列满后,通过tcp_syncookies参数回发SYNCookie若为正常连接则Client会回发SYNCookie,直接根据cookie建立连接，不会因为队列满而无法建立连接；如果是恶意用户，则不会发送Cookie建立连接后,Client出现故障怎么办？保护机制：向对方发送保活探测报文,如果未收到响应则继续发送，尝试次数达到保活探测数仍未收到响应则中断连接下面是三次握手的含义：第一次握手：Client什么都不能确认；Server确认了对方发送正常，自己接收正常第二次握手：Client确认了：自己发送、接收正常，对方发送、接收正常；Server确认了：对方发送正常，自己接收正常第三次握手：Client确认了：自己发送、接收正常，对方发送、接收正常；Server确认了：自己发送、接收正常，对方发送、接收正常SYN是TCP/IP建立连接时使用的握手信号。在客户机和服务器之间建立正常的TCP网络连接时，客户机首先发出一个SYN消息，服务器使用SYN-ACK应答表示接收到了这个消息，最后客户机再以ACK(Acknowledgement）消息响应。这样在客户机和服务器之间才能建立起可靠的TCP连接，数据才可以在客户机和服务器之间传递。2.为什么要四次挥手？客户端-发送一个FIN，用来关闭客户端到服务器的数据传送服务器-收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。和SYN一样，一个FIN将占用一个序号服务器-关闭与客户端的连接，发送一个FIN给客户端客户端-发回ACK报文确认，并将确认序号设置为收到序号加1举个例子：A和B打电话，通话即将结束后，A说“我没啥要说的了”，B回答“我知道了”，但是B可能还会有要说的话，A不能要求B跟着自己的节奏结束通话，于是B可能又巴拉巴拉说了一通，最后B说“我说完了”，A回答“知道了”，这样通话才算结束服务器出现大量CLOSE_WAIT状态的原因？可能浏览器发送关闭请求后，服务器在忙于读写也可能代码出现了问题，特别是释放资源的代码忘记释放了资源三、TCP和UDP的区别TCP是面向连接，需要通过三次握手建立可靠连接，而UDP是面向无连接的可靠性：TCP有ARQ协议、超时重传等，可以保证其可靠性，而UDP没有这些东西，只是尽最大努力交付,不保证可靠交付有序性：TCP利用序列号可以保证其有序性，到达可能无序，最后会进行排序，而UDP无法保证有序性速度：TCP比较复杂所以比减慢，UDP比较快量级：TCP报文是20个字节，UDP报文是8个字节UDP在传送数据之前不需要先建立连接，远地主机在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP确是一种最有效的工作方式（一般用于即时通信），比如：QQ语音、QQ视频、直播等等TCP提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP一般用于文件传输、发送和接收邮件、远程登录等场景。四、TCP协议如何保证可靠传输应用数据被分割成TCP认为最适合发送的数据块。TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。校验和：TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。TCP的接收端会丢弃重复的数据。流量控制：TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP使用的流量控制协议是可变大小的滑动窗口协议。（TCP利用滑动窗口实现流量控制）拥塞控制：当网络拥塞时，减少数据的发送。ARQ协议：也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。超时重传：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。4.1连续ARQ协议对于ARQ协议，如果每个数据报都发送确认收到，将十分消耗网络资源，在此问题上，提出了连续ARQ协议：连续ARQ协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。4.2滑动窗口和流量控制RTT：发送一个数据包到收到对应的ACK,所花费的时间RTO：重传时间间隔，将根据RTT进行改变滑动窗口的作用：保证TCP的可靠性：采用ARQ协议和超时重传机制保证可靠性实现流量控制：TCP利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为0，则发送方不能发送数据。4.3拥塞控制当网络比较拥堵时，会控制发送数据的速度，防止发送较大的文件导致网络瘫痪为了进行拥塞控制，TCP发送方要维持一个拥塞窗口(cwnd)的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。有四种算法：慢开始：慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。拥塞避免：拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1.快重传与快恢复：在TCP/IP中，快速重传和恢复（fastretransmitandrecovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有FRR，如果数据包丢失了，TCP将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了FRR，就不会因为重传时要求的暂停被耽误。当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。五、在浏览器中输入url地址-&gt;&gt;显示主页的过程总体来说分为以下几个过程:浏览器解析域名查找IP地址，使用的协议是DNS协议，DNS过程为：浏览器缓存、路由器缓存、DNS缓存与服务器三次握手建立TCP连接（在建立TCP协议时，需要发送数据，需要使用IP协议、IP数据包在路由器之间传输，路由器的选择使用的OSPF协议、路由器和服务器通信时，需要将IP地址转换成MAC地址，需要用到ARP协议）向服务器发送HTTP请求服务器处理请求并返回HTTP响应可能会释放TCP连接，这取决于HTTP版本浏览器解析渲染页面连接结束六、状态码1XX信息：100Continue：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应2XX成功“：200OK204NoContent：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，而不需要返回数据时使用。206PartialContent：表示客户端进行了范围请求，响应报文包含由Content-Range指定范围的实体内容。3XX重定向：301MovedPermanently：永久性重定向302Found：临时性重定向303SeeOther：和302有着相同的功能，但是303明确要求客户端应该采用GET方法获取资源。注：虽然HTTP协议规定301、302状态下重定向时不允许把POST方法改成GET方法，但是大多数浏览器都会在301、302和303状态下的重定向把POST方法改成GET方法。304NotModified：如果请求报文首部包含一些条件，例如：If-Match，If-Modified-Since，If-NoneMatch，If-Range，If-Unmodified-Since，如果不满足条件，则服务器会返回304状态码。307TemporaryRedirect：临时重定向，与302的含义类似，但是307要求浏览器不会把重定向请求的POST方法改成GET方法。4XX客户端错误：**400BadRequest：**请求报文中存在语法错误。**401Unauthorized：**该状态码表示发送的请求需要有认证信息（BASIC认证、DIGEST认证）。如果之前已进行过一次请求，则表示用户认证失败。403Forbidden：请求被拒绝，比如说IP被禁止404NotFound：可能输入错误了URL5XX服务器错误：**500InternalServerError：**服务器正在执行请求时发生错误。**503ServiceUnavailable：**服务器暂时处于超负载或正在进行停机维护，现在无法处理请求，可能连接池满了或者服务器宕机九、各协议与HTTP协议的关系十、HTTP长连接和短连接在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：Connection:keep-alive在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。十一、Cookie的作用是什么?和Session有什么区别？Cookie和Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。Cookie一般用来保存用户信息比如①我们在Cookie中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个Token在Cookie中，下次登录的时候只需要根据Token值来查找用户即可(为了安全考虑，重新登录一般要将Token重写)；③登录一次网站后访问网站其他页面不需要重新登录。Session的主要作用就是通过服务端记录用户的状态。典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为HTTP协议是无状态的。服务端给特定的用户创建特定的Session之后就可以标识这个用户并且跟踪这个用户了。Cookie数据保存在客户端(浏览器端)，Session数据保存在服务器端。Cookie存储在客户端中，而Session存储在服务器上，相对来说Session安全性更高。如果要在Cookie中存储一些敏感信息，不要直接写入Cookie中，最好能将Cookie信息加密然后使用到的时候再去服务器端解密。十二、HTTP1.0和HTTP1.1的主要区别是什么?长连接:在HTTP/1.0中，默认使用的是短连接，也就是说每次请求都要重新建立一次连接。HTTP是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。HTTP1.1起，默认使用长连接,默认开启Connection：keep-alive。HTTP/1.1的持续连接有非流水线方式和流水线方式。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。错误状态响应码:在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。缓存处理:在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entitytag，If-Unmodified-Since,If-Match,If-None-Match等更多可供选择的缓存头来控制缓存策略。带宽优化及网络连接的使用:HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（PartialContent），这样就方便了开发者自由的选择以便于充分利用带宽和连接。十三、URI和URL的区别是什么?URI(UniformResourceIdentifier)是统一资源标志符，可以唯一标识一个资源。URL(UniformResourceLocation)是统一资源定位符，可以提供该资源的路径。它是一种具体的URI，即URL可以用来标识一个资源，而且还指明了如何locate这个资源。十四、HTTP和HTTPS的区别？如果有恶意的软件劫持了用户发送的请求，最后模仿服务器向浏览器发送响应，浏览器是无法识别的，这就是劫持。端口：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。HTTPS需要到CA申请证书，HTTP不需要安全性和资源消耗：HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP安全性没有HTTPS高，但是HTTPS比HTTP耗费更多服务器资源。对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等；非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等。哈希算法:将任意长度的信息转换为固定长度的值,算法不可逆，比如说MD5算法SSL(SecuritySocketsLayer,安全套接层)为网络通信提供安全及数据完整性的一-种安全协议是操作系统对外的API,SSL3.0后更名为TLS采用身份验证和数据加密保证网络通信的安全和数据的完整性HTTPS真的很安全吗?浏览器默认填充http://，请求到服务器后需要进行https的跳转，在建立起HTTPS连接之前存在一次明文的HTTP请求和重定向，有被劫持的风险可以使用HSTS(HTTPStrictTransportSecurity)优化HSTS的作用是强制客户端（如浏览器）使用HTTPS与服务器创建连接。HSTS最为核心的是一个HTTP响应头（HTTPResponseHeader），正是它可以让浏览器得知，在接下来的一段时间内，当前域名只能通过HTTPS进行访问，并且在浏览器发现当前连接不安全的情况下，强制拒绝用户的后续访问要求。比如设置在第一次HTTP连接中，得知要在接下来1年内在个对于当前域名及其子域名的后续通信应该强制性的只使用HTTPS，直到超过有效期为止。同时，第一次的HTTP连接也可能会被劫持，所以浏览器中可以内置一个列表，放入那些必须使用https的域名，保证安全性十五、HTTP/2.0HTTP/1.x缺陷，HTTP/1.x实现简单是以牺牲性能为代价的客户端需要使用多个连接才能实现并发和缩短延迟；不会压缩请求和响应首部，从而导致不必要的网络流量；不支持有效的资源优先级，致使底层TCP连接的利用率低下。二进制分帧层HTTP/2.0将报文分成HEADERS帧和DATA帧，它们都是二进制格式的。服务端推送HTTP/2.0在客户端请求一个资源时，会把相关的资源一起发送给客户端，客户端就不需要再次发起请求了。例如客户端请求page.html页面，服务端就把script.js和style.css等与之相关的资源一起发给客户端。首部压缩HTTP/1.1的首部带有大量信息，而且每次都要重复发送。HTTP/2.0要求客户端和服务器同时维护和更新一个包含之前见过的首部字段表，从而避免了重复传输。不仅如此，HTTP/2.0也使用Huffman编码对首部字段进行压缩。十六、GET和POST的比较作用不同：GET用于获取资源，而POST用于传输实体主体。参数不同：GET和POST的请求都能使用额外的参数，但是GET的参数是以查询字符串出现在URL中，URL长度可能会受到浏览器的限制，而POST的参数存储在实体主体中，长度没有限制。不能因为POST参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。安全和幂等性：安全的HTTP方法不会改变服务器状态，也就是说它只是可读的，而幂等性指同样的请求被执行一次与连续执行多次的效果是一样的。GET方法是安全的也是幂等的，而POST却不是，因为POST的目的是传送实体主体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。缓存：GET请求可以被缓存、被存储，保存在浏览器上，而POST是非幂等的，所以必须交由服务器处理十七、Socket简介Socket是对TCP/IP协议的抽象，是操作系统对外开放的接口1.Socket的通讯流程2.利用Java实现Socket实现TCP和UDPTCPServerpublicclassTCPServer{publicstaticvoidmain(String[]args)throwsIOException{//创建socket,并将socket绑定到65000端口ServerSocketss=newServerSocket(65000);//死循环，使得socket一直等待并处理客户端发送过来的请求while(true){//监听65000端口，直到客户端返回连接信息后才返回Socketsocket=ss.accept();//获取客户端的请求信息后，执行相关业务逻辑newLengthCalculator(socket).start();}}}LengthCalculatorpublicclassLengthCalculatorextendsThread{privateSocketsocket;publicLengthCalculator(Socketsocket){this.socket=socket;}@Overridepublicvoidrun(){try{//获取socket的输出流OutputStreamos=socket.getOutputStream();//获取socket的输入流InputStreamis=socket.getInputStream();intch;byte[]buff=newbyte[1024];//buff主要用来读取输入的内容，存成byte数组，ch主要用来获取读取数组的长度ch=is.read(buff);//将接收流的byte数组转换成字符串，这里获取的内容是客户端发送过来的字符串Stringcontent=newString(buff,0,ch);System.out.println(content);//往输出流里写入获得的字符串的长度，回发给客户端os.write(String.valueOf(content.length()).getBytes());//不要忘记关闭输入输出流以及socketis.close();os.close();socket.close();}catch(IOExceptione){e.printStackTrace();}}}TCPClientpublicclassTCPClient{publicstaticvoidmain(String[]args)throwsIOException{//创建socket，并指定连接的是本机的端口号为65000的服务器socketSocketsocket=newSocket(&quot;127.0.0.1&quot;,65000);//获取输出流OutputStreamos=socket.getOutputStream();//获取输入流InputStreamis=socket.getInputStream();//将要传递给server的字符串参数转换成byte数组，并数组写入到输出流中os.write(&quot;helloworld&quot;.getBytes());intch;byte[]buff=newbyte[1024];//buff主要用来读取输入的内容，存成byte数组，ch主要用来获取读取数组的长度ch=is.read(buff);//将接收流的byte数组转换成字符串，这里是从服务端回发回来的字符串参数的长度Stringcontent=newString(buff,0,ch);System.out.println(content);//不要忘记关闭输入输出流以及socketis.close();os.close();socket.close();}}UDPServerpublicclassUDPServer{publicstaticvoidmain(String[]args)throwsIOException{//服务端接受客户端发送的数据报DatagramSocketsocket=newDatagramSocket(65001);//监听的端口号byte[]buff=newbyte[100];//存储从客户端接受到的内容DatagramPacketpacket=newDatagramPacket(buff,buff.length);//接受客户端发送过来的内容，并将内容封装进DatagramPacket对象中socket.receive(packet);byte[]data=packet.getData();//从DatagramPacket对象中获取到真正存储的数据//将数据从二进制转换成字符串形式Stringcontent=newString(data,0,packet.getLength());System.out.println(content);//将要发送给客户端的数据转换成二进制byte[]sendedContent=String.valueOf(content.length()).getBytes();//服务端给客户端发送数据报//从DatagramPacket对象中获取到数据的来源地址与端口号DatagramPacketpacketToClient=newDatagramPacket(sendedContent,sendedContent.length,packet.getAddress(),packet.getPort());socket.send(packetToClient);//发送数据给客户端}}UDPClientpublicclassUDPClient{publicstaticvoidmain(String[]args)throwsIOException{//客户端发数据报给服务端DatagramSocketsocket=newDatagramSocket();//要发送给服务端的数据byte[]buf=&quot;HelloWorld&quot;.getBytes();//将IP地址封装成InetAddress对象InetAddressaddress=InetAddress.getByName(&quot;127.0.0.1&quot;);//将要发送给服务端的数据封装成DatagramPacket对象需要填写上ip地址与端口号DatagramPacketpacket=newDatagramPacket(buf,buf.length,address,65001);//发送数据给服务端socket.send(packet);//客户端接受服务端发送过来的数据报byte[]data=newbyte[100];//创建DtagramPacket对象用来存储服务端发送过来的数据DatagramPacketreceivedPacket=newDatagramPacket(data,data.length);//将接受到的数据存储到DatagramPacket对象中socket.receive(receivedPacket);//将服务器端发送过来的数据取出来并打印到控制台Stringcontent=newString(receivedPacket.getData(),0,receivedPacket.getLength());System.out.println(content);}}","link":"https://xzzz2020.github.io/post/SfR2cO5PD/"},{"title":"【总结】SQL语句","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：数据库专栏一、常用数据处理函数1.substr2.trim3.ifnull4.case…when…then…else...end二、常用聚合函数三、分组查询1.groupby2.having3.select语句顺序总结四、连接查询（重点）内连接外连接的区别？五、视图的作用六、如何创建删除索引？一、常用数据处理函数函数名解释substr取子串（substr(被截取的字符串,起始下标,截取的长度)）trim去空Ifnull可以将null转换成一个具体值case…when…then…else...end多个条件判断1.substr查询姓名以M开头所有的员工select*fromempwheresubstr(ename,1,1)=upper('m');2.trim会去首尾空格，不会去除中间的空格取得工作岗位为manager的所有员工select*fromempwherejob=trim(upper('manager'));3.ifnullselectifnull(comm,0)fromemp;如果comm为null就替换为0在SQL语句当中若有NULL值参与数学运算，计算结果一定是NULL为了防止计算结果出现NULL，建议先使用ifnull空值处理函数预先处理。以下SQL是计算年薪的：selectempno,ename,sal,(sal+ifnull(comm,0))*12asyearsalfromemp;4.case…when…then…else...end如果job为MANAGERG薪水上涨10%,如果job为SALESMAN工资上涨50%selectempno,ename,job,sal,casejobwhen'MANAGER'thensal*1.1when'SALESMAN'thensal*1.5endasnewsalfromemp;其他的工资不动，需要加elseselecte.*,sal,casejobwhen'salesman'thensal*1.1when'clerk'thensal*1.2elsesalendasnew_salfromempe;二、常用聚合函数函数名解释count取得记录数sum求和avg取平均max取最大的数min取最小的数注意：分组函数自动忽略空值，不需要手动的加where条件排除空值。selectcount(*)fromempwherexxx;符合条件的所有记录总数。selectcount(comm)fromemp;comm这个字段中不为空的元素总数。聚合函数不能直接使用在where关键字后面。三、分组查询1.groupby取得每个工作岗位的工资合计，要求显示岗位名称和工资合计selectjob,sum(sal)fromempgroupbyjob;注意：在SQL语句中若有groupby语句，那么在select语句后面只能跟聚合函数+参与分组的字段。错误示范：selectempno,deptno,avg(sal)fromempgroupbydeptno;2.having如果想对分组数据再进行过滤需要使用having子句取得每个岗位的平均工资大于2000selectjob,avg(sal)fromempgroupbyjobhavingavg(sal)&gt;2000;3.select语句顺序总结select字段from表名where…….groupby……..having…….(就是为了过滤分组后的数据而存在的—不可以单独的出现)orderby……..语句的执行顺序：首先执行where语句过滤原始数据执行groupby进行分组执行having对分组数据进行操作执行select选出数据执行orderby排序原则：能在where中过滤的数据，尽量在where中过滤，效率较高。having的过滤是专门对分组之后的数据进行过滤的。四、连接查询（重点）也可以叫跨表查询，需要关联多个表进行查询SQL99语法相比92语法，将连接条件和where分离内连接外连接的区别？内连接：只有两张表相匹配的行才能出现在结果集外连接：左连接以左面的表为准和右边的表比较，和左表相等的不相等都会显示出来，右表符合条件的显示内连接表1innerjoin表2on关联条件做连接查询的时候一定要写上关联条件inner可以省略外连接左外连接表1leftouterjoin表2on关联条件做连接查询的时候一定要写上关联条件outer可以省略右外连接表1rightouterjoin表2on关联条件做连接查询的时候一定要写上关联条件outer可以省略左外连接（左连接）和右外连接（右连接）的区别：左连接以左面的表为准和右边的表比较，和左表相等的不相等都会显示出来，右表符合条件的显示左外连接（左连接）和右外连接（右连接）的区别：左连接以左面的表为准和右边的表比较，和左表相等的不相等都会显示出来，右表符合条件的显示,不符合条件的不显示右连接恰恰相反，以上左连接和右连接也可以加入outer关键字，但一般不建议这种写法五、视图的作用某些频繁使用的查询语句(如级联查询)，可能很复杂，可以利用视图简化查询，重用sql保护数据，只授予特定权限，如查询权限视图本身不包含数据，只是对sql语句的一个封装，如果需要封装复杂的sql需要先测试性能用于数据检索，不能更新数据六、如何创建删除索引？修改索引需要先删除在添加添加PRIMARYKEY（主键索引）ALTERTABLE`table_name`ADDPRIMARYKEY(`column`)添加UNIQUE(唯一索引)ALTERTABLE`table_name`ADDUNIQUE(`column`)添加INDEX(普通索引)ALTERTABLE`table_name`ADDINDEXindex_name(`column`)添加FULLTEXT(全文索引)ALTERTABLE`table_name`ADDFULLTEXT(`column`)添加多列索引ALTERTABLE`table_name`ADDINDEXindex_name(`column1`,`column2`,`column3`)删除索引DROPINDEXlogin_name_indexONuser;","link":"https://xzzz2020.github.io/post/B4oG0L7Z4/"},{"title":"【总结】MySQL索引总结","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：数据库专栏一、为什幺要用索引？二、索引这么多优点，为什么不对表中的每一个列创建一个索引呢？三、使用索引的注意事项？四、索引什么时候会失效？五、最左前缀原则是什么？六、MySQL索引的主要数据结构1.哈希索引2.B+树索引七、为什么索引能提高查询速度？八、索引都有哪些类型？1.主键索引(PrimaryKey)2.二级索引(辅助索引)3.聚集索引4.非聚集索引5.覆盖索引九、索引创建的原则一、为什幺要用索引？通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。可以大大加快数据的检索速度（大大减少的检索的数据量）,这也是创建索引的最主要的原因。帮助服务器避免排序和临时表。将随机IO变为顺序IO可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。二、索引这么多优点，为什么不对表中的每一个列创建一个索引呢？当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。三、使用索引的注意事项？在经常需要搜索的列上，可以加快搜索的速度；在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间在使用InnoDB时使用与业务无关的自增主键作为主键避免索引失效四、索引什么时候会失效？有or关键字必须所有字段全有索引;复合索引未用左列字段;like以%开头where中索引列有运算where中索引列使用了函数如果mysql觉得全表扫描更快时（数据少）五、最左前缀原则是什么？主要针对的聚合索引是否生效，假如有一个聚合索引ABC：最左边的列必须要用到，比如这个A列中间是不能断的，如只查询了A和C列，只会用到C的索引遇到范围后，终止，比如where条件是这样的，whereA=xandB&gt;yandC=z，这个时候只会用到AB索引，无法使用C索引六、MySQL索引的主要数据结构1.哈希索引​对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引因为Hash索引比较的是经过Hash计算的值，所以只能进行等式比较，不能用于范围查询当哈希值大量重复且数据量非常大时，其检索效率并没有Btree索引高的哈希值映射的真正数据在哈希表中就不一定按照顺序排列，所以无法利用Hash索引来加速任何排序操作2.B+树索引为磁盘或其他直接存取的辅助设备而设计的平衡二叉树所有的记录节点都是按照键值的大小顺序存放在同一层的叶节点同时最后一层叶字节点之间存在指针，这样可以保证其是连续的数据排列​B+树相对于B树的区别？单一节点存储的元素更多，使得查询的IO次数更少，所以也就使得它更适合做为数据库MySQL的底层数据结构了所有的查询都要查找到叶子节点，查询性能是稳定的，而B树，每个节点都可以查找到数据，所以不稳定。所有的叶子节点形成了一个有序链表，更加便于查找。B+树与红黑树的比较？更少的查找次数：平衡树查找操作的时间复杂度和树高h相关，O(h)=O(logdN)，其中d为每个节点的出度。红黑树的出度为2，而B+Tree的出度一般都非常大，所以红黑树的树高h很明显比B+Tree大非常多，查找的次数也就更多。利用磁盘预读特性：为了减少磁盘I/O操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。数据库系统将索引的一个节点的大小设置为页的大小，使得一次I/O就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入B+数树和B-树的区别？B+树相当于B-树的变种，主要差异在于B+树数据都保存在叶子节点，同时叶子节点之间形成了链表B+树查询时间复杂度固定是logn，B-树查询复杂度最好是O(1)B+树相邻接点的指针可以大大增加区间访问性，可使用在范围查询等，而B-树每个节点key和data在一起，则无法区间查找MyISAM和InnoDB实现BTree索引方式的区别？MyISAM：B+Tree叶节点的data域存放的是数据记录的地址。在索引检索的时候，首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。InnoDB：其数据文件本身就是索引文件。相比MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按B+Tree组织的一个索引结构，树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”，而其余的索引都作为辅助索引，辅助索引的data域存储相应记录主键的值而不是地址，这也是和MyISAM不同的地方。在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，在走一遍主索引。七、为什么索引能提高查询速度？MySQL底层每16k的数据为一页，一页中有多个记录值。如果我们写select*fromuserwhereindexname='xxx'这样没有进行任何优化的sql语句，默认会这样做：定位到记录所在的页：需要遍历双向链表，找到所在的页从所在的页内中查找相应的记录：由于不是根据主键查询，只能遍历所在页的单链表了很明显，在数据量很大的情况下这样查找会很慢！这样的时间复杂度为O（n）。使用了索引其实就是将无序的数据变成相对有序，其实底层结构就是B+树，B+树作为树的一种实现，时间复杂度近似为O(logn)，能够让我们很快地查找出对应的记录。八、索引都有哪些类型？1.主键索引(PrimaryKey)数据表的主键列使用的就是主键索引。一张数据表有只能有一个主键，并且主键不能为null，不能重复。在mysql的InnoDB的表中，当没有显示的指定表的主键时，InnoDB会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则InnoDB将会自动创建一个6Byte的自增主键。2.二级索引(辅助索引)二级索引又称为辅助索引，是因为二级索引的叶子节点在InnoDB中存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置；在MyISAM中存储的数据是地址。唯一索引(UniqueKey)：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为NULL，一张表允许创建多个唯一索引。**建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。普通索引(Index)：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和NULL。前缀索引(Prefix)：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小，因为只取前几个字符。全文索引(FullText)：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6之前只有MYISAM引擎支持全文索引，5.6之后InnoDB也支持了全文索引。3.聚集索引聚集索引即索引结构和数据一起存放的索引。InnoDB存储引擎中主键索引属于聚集索引，B+树的每个非叶子节点存储索引，叶子节点存储索引和索引对应的数据。优点：聚集索引的查询速度非常的快，因为整个B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。缺点：依赖于有序的数据：因为B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或UUID这种又长又难比较的数据，插入或查找的速度肯定比较慢。更新代价大：如果对索引列的数据被修改时，那么对应的索引也将会被修改，可能涉及自旋操作维护平衡，而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的。4.非聚集索引非聚集索引即索引结构和数据分开存放的索引，比如说MyISAM中的索引保存的指向数据文件的指针。优点：更新代价比聚集索引要小：非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的缺点：可能会二次查询(回表):这应该是非聚集索引最大的缺点了。当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。非聚集索引一定回表查询吗(覆盖索引)?不一定。虽然MYISAM的主键索引确实需要回表，因为它的主键索引的叶子节点存放的是指针。但是如果SQL查的就是主键呢?或者想要查询的字段刚好建立了索引，查到对应的字段直接返回就行了，无需回表查询5.覆盖索引如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。我们知道InnoDB存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值。最终还是要“回表”，也就是先定位主键值，再定位行记录，它的性能较扫一遍索引树更低，这样就会比较慢。覆盖索引就是把要查询出的列和索引是对应的，不做回表操作假如索引是AB列，想要查询出来的列是AB+主键列，则此时是覆盖索引；而想要查询出来的列是ABC列，C的数据不在索引中，就需要回表。所以切忌使用Select*总结：覆盖索引的优化及限制优点：1、索引项通常比记录要小，所以MySQL访问更少的数据。2、索引都按值得大小存储，相对于随机访问记录，需要更少的I/O。3、数据引擎能更好的缓存索引，比如MyISAM只缓存索引。4、覆盖索引对InnoDB尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引包含查询所需的数据，就不再需要在聚集索引中查找了。限制：1、覆盖索引也并不适用于任意的索引类型，索引必须存储列的值。2、Hash和full-text索引不存储值，因此MySQL只能使用BTree。3、不同的存储引擎实现覆盖索引都是不同的，并不是所有的存储引擎都支持覆盖索引。4、如果要使用覆盖索引，一定要注意SELECT列表值取出需要的列，不可以SELECT*，因为如果将所有字段一起做索引会导致索引文件过大，查询性能下降。九、索引创建的原则最左前缀原则：虽然我目前的Mysql版本较高，好像不遵守最左前缀原则，索引也会生效。但是我们仍应遵守最左前缀原则，以免版本更迭带来的麻烦。选择合适的字段索引字段的数据应该尽量不为NULL，因为对于数据为NULL的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为NULL，建议使用默认值。我们创建索引的字段应该是查询操作非常频繁的字段，而不是增删改比较多的。被作为WHERE条件查询的字段，应该被考虑建立索引。经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。需要注意的地方注意避免冗余索引考虑在字符串类型的字段上使用前缀索引代替普通索引，前缀索引仅限于字符串类型，较普通索引会占用更小的空间，所以可以考虑使用前缀索引带替普通索引。","link":"https://xzzz2020.github.io/post/EM2P_CVYa/"},{"title":"【总结】MySql架构","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：数据库专栏一、Mysql的架构图二、Server层1.连接器2.查询缓存3.分析器4.优化器5.执行器三、执行流程一、Mysql的架构图客户端：比如window和linux的黑窗口、SQLlyog、java的JDBC标准等等Server层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块binglog日志模块。存储引擎：主要负责数据的存储和读取，采用可以替换的插件式架构，支持InnoDB、MyISAM、Memory等多个存储引擎，其中InnoDB引擎有自有的日志模块redolog模块。现在最常用的存储引擎是InnoDB，它从MySQL5.5.5版本开始就被当做默认存储引擎了。数据：都是二进制文件二、Server层1.连接器连接器主要和身份认证和权限相关的功能相关客户端通过连接器连接到MySql客户端连接连接器是需要网络时间，所以建议使用数据库连接池，可以复用连接2.查询缓存查询缓存主要用来缓存我们所执行的SELECT语句以及该语句的结果集。连接建立后，执行查询语句的时候，会先查询缓存，MySQL会先校验这个sql是否执行过，以Key-Value的形式缓存在内存中如果缓存key被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用MySQL查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空，MySQL8.0版本后删除了缓存的功能缓存虽然能够提升数据库的查询性能，但是缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。存在的问题查询缓存的内存分配问题，不可避免地产生一些内存碎片；查询缓存对是否是一样的查询语句，要求非常苛刻，而且还不智能查询缓存中涉及的表，每一个表对象都有一个属于自己的全局性质的锁，表对象的DML操作，必须优先判断是否需要清理相关查询缓存的记录信息，将不可避免地出现锁等待事件表若是做DDL等类似操作，触发相关表的查询缓存信息清空3.分析器没有命中缓存的话，SQL语句就会经过分析器，分析器说白了就是要先看你的SQL语句要干嘛，再检查你的SQL语句语法是否正确。分析器也会分为几步：第一步，词法分析，一条SQL语句有多个字符串组成，首先要提取关键字，比如select，提出查询的表，提出字段名，提出查询条件等等。做完这些操作后，就会进入第二步。第二步，语法分析，主要就是判断你输入的sql是否正确，是否符合MySQL的语法。完成这2步之后，MySQL就准备开始执行了，但是如何执行，怎么执行是最好的结果呢？这个时候就需要优化器上场了4.优化器优化器的作用就是它认为的最优的执行方案去执行（有时候可能也不是最优），比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等。可以说，经过了优化器之后可以说这个语句具体该如何执行就已经定下来。5.执行器当选择了执行方案后，MySQL就准备开始执行了，首先执行前会校验该用户有没有权限，如果没有权限，就会返回错误信息，如果有权限，就会去调用引擎的接口，从存储引擎返回执行的结果。三、执行流程客户端连接连接器分析器处理客户端的SQL语句，进行词法分析和语法分析，检查SQL语法是否正确优化器优化分析器处理的语句，选择一个它认为的最优的执行方案去执行，比如多个索引的时候该如何选择索引，多表查询的时候如何选择关联顺序等最后执行器执行优化器确定的方案，但是由于不了解数据是怎么存储的，需要调用存储引擎的接口，从存储引擎返回执行的结果存储引擎决定怎么存储数据，常见的有三种：InnoDB存储引擎、MyISAM存储引擎和Memory引擎（博主主要掌握的InnoDB存储引擎）当然中间还有一个查询缓存，会存储查询出来的数据，但是查询缓存命中不高，MySQL查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空，MySQL8.0版本后删除了缓存的功能，","link":"https://xzzz2020.github.io/post/aY-DgheCd/"},{"title":"【总结】MySQL存储引擎","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：数据库专栏一、MyISAM存储引擎二、InnoDB存储引擎三、MEMORY存储引擎四、MyISAM和InnoDB区别存储引擎是表级别的，不同的表可以使用不同的存储引擎！！！一、MyISAM存储引擎没有提供对数据库事务的支持，也不支持行级锁和外键，所以写操作需要锁定整个表，效率便会低一些执行读取操作的速度很快，而且不占用大量的内存和存储资源，在设计之初就预想数据组织成有固定长度的记录，按顺序存储的可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。二、InnoDB存储引擎是MySQL默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLEREAD）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+间隙锁（Next-KeyLocking）防止幻影读。主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取三、MEMORY存储引擎数据存在内存不支持持久化四、MyISAM和InnoDB区别MyISAM是MySQL的默认数据库引擎（5.5版之前）。虽然性能极佳，而且提供了大量的特性，包括全文索引、压缩、空间函数等，但MyISAM不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。不过，5.5版本之后，MySQL引入了InnoDB（事务性数据库引擎），MySQL5.5版本后默认的存储引擎为InnoDB。大多数时候我们使用的都是InnoDB存储引擎，但是在某些情况下使用MyISAM也是合适的比如读密集的情况下。（如果你不介意MyISAM崩溃恢复问题的话）。两者的对比：是否支持行级锁:MyISAM只有表级锁(table-levellocking)，而InnoDB支持行级锁(row-levellocking)和表级锁,默认为行级锁。是否支持事务和崩溃后的安全恢复：MyISAM强调的是性能，每次查询具有原子性,其执行速度比InnoDB类型更快，但是不提供事务支持。但是InnoDB提供事务支持事务，外部键等高级数据库功能。具有事务(commit)、回滚(rollback)和崩溃修复能力(crashrecoverycapabilities)的事务安全(transaction-safe(ACIDcompliant))型表。是否支持外键：MyISAM不支持，而InnoDB支持。是否支持MVCC：仅InnoDB支持。应对高并发事务,MVCC比单纯的加锁更高效;MVCC只在READCOMMITTED和REPEATABLEREAD两个隔离级别下工作;MVCC可以使用乐观(optimistic)锁和悲观(pessimistic)锁来实现;各数据库中MVCC实现并不统一。索引的差别：MyISAM的B+Tree叶节点的data域存放的是数据记录的地址，然后以data域的值为地址读取相应的数据记录；InnoDB的数据文件本身就是索引文件，在根据主索引搜索时，直接找到key所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，否则会降低查询的素的。一般情况下我们选择InnoDB都是没有问题的，但是某些情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择MyISAM也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。","link":"https://xzzz2020.github.io/post/j_WKr1zJr/"},{"title":"【总结】InnoDB存储引擎","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：数据库专栏一、InnoDB存储引擎工作方式二、关键特性1.插入缓存2.两次写3.自适应哈希索引三、redolog、binlog和undolog1.什么是redolog？2.什么是binlog？3.redolog和binlog区别4.回滚日志（undolog）5.redolog和undolog的区别6.一条更新语句执行的顺序一、InnoDB存储引擎工作方式将数据库文件按页（每页16k）读取到缓冲池，然后按照最近最少使用的算法（LRU）保留缓存数据。如果数据发生更改，总是先修改缓存池的页（脏页），然后再保存在磁盘中二、关键特性1.插入缓存因为主键是表唯一标识，所以插入顺序按照主键递增（自增主键）的顺序插入。因此，插入的聚集索引一般是顺序的，不需要对磁盘随机读取，所以速度很快。但是一个表不止有聚集索引，索引的插入不再是顺序的插入索引对于非聚集索引，不是一次性插入到索引页，先判断索引页是否在缓存池。如果在，直接插入；如果不在，先放入插入缓存，将多个插入合并在一个中(因为都是在一个索引页中)，在根据磁盘IO情况更新到磁盘中。索引必须是辅助索引，索引不是唯一的默认最多占一半缓存池空间缺点：由于并没有及时把索引更新到磁盘中，如果数据库宕机，则需要很多的时间恢复数据2.两次写当数据库宕机时，数据库可能正在写一个页面，而这个页面只写了一部分，则称之为部分写失效，从而导致数据丢失如果此时直接使用Undo日志，由于页出现了损坏，所以此时是无意义的在执行Undo日志之前，先需要一个页副本用来恢复的没有写之前的状态，再进行重做。doublewrite由两部分组成：内存中的doublewritebuffer，物理磁盘共享表中的两个区在缓冲池脏页刷新时，先将数据拷贝到内存中的doublewritebuffer，然后在写入物理磁盘共享表中的两个区，然后在更新磁盘数据由于doublewrite是连续的，所以对其的IO操作时顺序写的，开销不大3.自适应哈希索引哈希是一种查找办法，常用于join连接操作会监控表上索引的查找，如果建立哈希索引可以提供速度，则建立哈希索引。哈希索引通过缓存池中的B+数构造而来，因此建立速度很快并不是整个表都需要建立哈希索引，InnoDB会根据访问的频率为某些页单独建立哈希索引三、redolog、binlog和undolog1.什么是redolog？redolog是InnoDB存储引擎层的日志，又称重做日志文件，用于记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。在实例和介质失败（mediafailure）时，redolog文件就能派上用场，如数据库掉电，InnoDB存储引擎会使用redolog恢复到掉电前的时刻，以此来保证数据的完整性。在一条更新语句进行执行的时候，InnoDB引擎会把更新记录写到redolog日志中，然后更新内存，此时算是语句执行完了，然后在空闲的时候或者是按照设定的更新策略将redolog中的内容更新到磁盘中，这里涉及到WAL即WriteAheadlogging技术，他的关键点是先写日志，再写磁盘。有了redolog日志，那么在数据库进行异常重启的时候，可以根据redolog日志进行恢复，也就达到了crash-safe。redolog日志的大小是固定的，即记录满了以后就从头循环写，并且会暂停当前的所有数据更改操作，先将redolog日志同步到磁盘中。2.什么是binlog？可以作为数据恢复，在MySQL层面保证数据一致性的属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑也可以用于主从之间保证数据一致性3.redolog和binlog区别redolog是属于innoDB层面，binlog属于MySQLServer层面的，这样在数据库用别的存储引擎时可以达到一致性的要求。redolog是物理日志，记录该数据页更新的内容；binlog是逻辑日志，记录的是这个更新语句的原始逻辑redolog是循环写，日志空间大小固定；binlog是追加写，是指一份写到一定大小的时候会更换下一个文件，不会覆盖。binlog可以作为恢复数据使用，也可以用于主从复制搭建，redolog作为异常宕机或者介质故障后的数据恢复使用。4.回滚日志（undolog）属于InnoDB层面保证事务的原子性保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读5.redolog和undolog的区别redolog是保证事务持久性的，undolog是保证事务原子性的undolog用于备份一个事务开始前的数据，不会影响原本的数据，都是先在备份中更改，最后写入磁盘redolog用于记录每一个数据更新的内容，用于在二次写中恢复破损的数据6.一条更新语句执行的顺序updateTsetc=c+1whereID=2;执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。引擎将这行新数据更新到内存中，同时将这个更新操作记录到redolog里面，此时redolog处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。执行器生成这个操作的binlog，并把binlog写入磁盘。执行器调用引擎的提交事务接口，引擎把刚刚写入的redolog改成提交（commit）状态，更新完成。","link":"https://xzzz2020.github.io/post/M3FXzw5ip/"},{"title":"【总结】数据库优化策略","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：数据库专栏一、数据结构的优化二、服务器优化三、线上定位四、查询语句的优化1.sql语句的时间花在哪儿?2.sql语句的执行时间,又花在哪儿了?3.sql语句的优化思路？4.如何定量分析查的多少行,和是否沿着索引查?5.常见的查询优化6.缓存优化7.读写分离8.mysql的分库分表9.EXPLAIN使用五、索引及优化1.索引的作用2.索引的分类3.索引的优点（查的快）4.索引的缺点（增删改慢）5.哪些情况或字段适合加索引6.哪些情况不适合创建索引7.哪些情况会造成索引失效8.索引原理六、插入优化七、大表优化1.限定数据的范围2.读/写分离3.垂直分区4.水平分区5.数据库分库策略6.分库分表之后,id主键如何处理？一、数据结构的优化三大范式：数据库设计尽量遵循三范式根据实际情况进行取舍，有时可能会拿冗余换速度，减少表的关联查询，用空间换时间对于需要经常联合查询的表，可以建立中间表以提高查询效率对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表数据库命令规范：所有数据库对象名称必须使用小写字母并用下划线分割数据库对象的命名要能做到见名识意，并且最后不要超过32个字符所有存储相同数据的列名和列类型必须一致（一般作为关联列，如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低）列的选择：字段类型优先级整型&gt;date,time&gt;char,varchar&gt;blob尽量不要有null，可以设置为不允许空，或者加一个默认值数据大小够用就行不要使用大数据字段，如TEXT，BLOB财务数据使用decimal，不会丢失精度主键的选择：在myisam中,字符串索引会被压缩,用字符串做主键性能不如整型用递增的值,不要用离散的值,离散值会导致文件在磁盘的位置有间隔,浪费空间且不易连续读取二、服务器优化优化服务器硬件配置较大的内存配置高速磁盘，比如SSD配置多核处理器，MySQL是多线程的数据库，多处理器可以提高同时执行多个线程的能力优化MySQL的参数修改my.conf或者my.ini配置文件key_buffer_size：表示索引缓冲区大小，缓存数据，只对MyISAM表起作用，不是越大越好，大小取决于内存innodb_buffer_pool_size：表示InnoDB类型表和索引的最大缓存，值越大查询速度越快query_cache_size：表示查询缓冲区大小，MySQL8以上已经移除max_connections：表示数据库的最大连接数，也不是越多越好，过多连接可能会导致僵死三、线上定位发现系统运行缓慢，如何定位和分析查询慢的sql语句？开启mysql慢日志查询定位查询较慢的sql语句（200ms500ms）使用EXPLAIN关键字可以让你知道MySQL是如何处理你的SQL语句的。这可以帮你分析你的查询语句或是表结构的性能瓶颈。EXPLAIN的查询结果还会告诉你你的索引主键被如何利用的，你的数据表是如何被搜索和排序的……等等，等等代码中可以使用AOP的操作对每个持久层的service方法打印执行时间，将所有执行时间较长的sql语句进行预警查看sql语句是否出现了临时表，临时表可能会通过IO落地到磁盘上，要尽可能避免四、查询语句的优化1.sql语句的时间花在哪儿?等待数据的等待时间，以及执行SQL语句时间.这两个时间并非孤立的,如果单条语句执行的快了,对其他语句的锁定的也就少了2.sql语句的执行时间,又花在哪儿了?查----&gt;沿着索引查,甚至全表扫描取----&gt;查到行后,把数据取出来(sendingdata)3.sql语句的优化思路？不查,通过业务逻辑来计算,比如论坛的注册会员数,我们可以根据前3个月统计的每天注册数,用程序来估算少查,尽量精准数据,少取行.我们观察新闻网站,评论内容等,一般一次性取列表10-30条左右必须要查,尽量走在索引上查询行取时,取尽量少的列4.如何定量分析查的多少行,和是否沿着索引查?用explain来分析5.常见的查询优化SELECT语句务必指明字段名称（避免直接使用select*），使用*时，分析器，会要分析出都有什么列，会消耗很多时间，同时执行的时候，会返回很多没有必要的列SQL语句要避免造成索引失效的写法当只需要一条数据的时候，使用limit1，这样就通过sql语句过滤，而避免了执行时的过滤如果排序字段没有用到索引，就尽量少排序如果限制条件中其他字段没有索引，尽量少用or避免在where子句中对字段进行null值判断不建议使用%前缀模糊查询避免在where子句中对字段进行表达式操作Join优化能用innerjoin就不用leftjoinrightjoin，如必须使用一定要已小表为驱动可以使用连接查询（JOIN）代替子查询，连接查询时不需要建立临时表，其速度比子查询快6.缓存优化为了提高查询速度，我们可以通过不同的方式去缓存我们的结果从而提高响应效，可以去打开查询缓存或者使用Redis7.读写分离如果数据库的使用场景读的操作比较的时候，为了避免写的操作所造成的性能影响可以采用读写分离的架构，读写分离，解决的是，数据库的写入，影响了查询的效率。读写分离的基本原理是让主数据库处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库处理SELECT查询操作8.mysql的分库分表数据量越来越大时，单体数据库无法满足要求，可以考虑分库分表两种拆分方案：垂直拆分：（分库）业务表太多？将业务细化不同的小业务专门用一个库来维护水平拆分：（分表）单个表存的数据太多，装不下了？将该表查分成多个分库分表常用工具：MyCat9.EXPLAIN使用select_type，表示SELECT语句的类型，取值如下SIMPLE：表示简单查询，其中不包含连接查询和子查询PRIMARY：主键查血UNION：表示连接查询UNIONRESULT：连接查询的结果SUBQUERY：子查询type，表示表的连接类型，取值如下：system：表仅有一行，这是const类型的特列，平时不会出现，这个也可以忽略不计const：数据表最多只有一个匹配行，因为只匹配一行数据，所以很快，常用于PRIMARYKEY或者UNIQUE索引的查询，可理解为const是最优化的eq_ref：读取本表中和关联表表中的每行组合成的一行，索引是主键或唯一非NULL索引ref：查询条件索引既不是UNIQUE也不是PRIMARYKEY的情况ref_or_null：该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。上面这五种情况都是很理想的索引使用情况。index_merge：该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单unique_subquery：是一个索引查找函数,可以完全替换子查询,效率更高。index_subquery：只检索给定范围的行,使用一个索引来选择行range：只检索给定范围的行,使用一个索引来选择行index：该联接类型与ALL相同,除了只有索引树被扫描。ALL：对于每个来自于先前的表的行组合,进行完整的表扫描，性能最差**possible_keys，可能用到的索引****key，最终用的索引，如果没有选择索引,键是NULL**五、索引及优化注意避免冗余索引，比如说(name)和(name,price)，(name)就是冗余索引1.索引的作用当表中的数据量越来越大时，索引对于性能的影响愈发重要。索引优化应该是对查询性能优化最有效的手段了。索引能够轻易将查询性能提高好几个数量级。有了索引相当于我们给数据库的数据加了目录一样，可以快速的找到数据，如果不适用索引则需要一点一点去查找数据。简单来说提高数据查询的效率。2.索引的分类普通索引index:加速查找唯一索引主键索引：primarykey：加速查找+约束（不为空且唯一）唯一索引：unique：加速查找+约束（唯一）联合索引（组合索引）3.索引的优点（查的快）可以通过建立唯一索引或者主键索引,保证数据库表中每一行数据的唯一性.建立索引可以大大提高检索的数据,以及减少表的检索行数在表连接的连接条件可以加速表与表直接的相连在分组和排序字句进行数据检索,可以减少查询时间中分组和排序时所消耗的时间(数据库的记录会重新排序)建立索引,在查询中使用索引可以提高性能4.索引的缺点（增删改慢）在创建索引和维护索引会耗费时间,随着数据量的增加而增加索引文件会占用物理空间,除了数据表需要占用物理空间之外,每一个索引还会占用一定的物理空间当对表的数据进行INSERT,UPDATE,DELETE的时候,索引也要动态的维护,这样就会降低数据的维护速度,(建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会膨胀很快)5.哪些情况或字段适合加索引在经常需要搜索的列上,可以加快索引的速度主键列上可以确保列的唯一性在表与表的而连接条件上加上索引,可以加快连接查询的速度在经常需要排序(orderby),分组(groupby)和的distinct列上加索引可以加快排序查询的时间6.哪些情况不适合创建索引查询中很少使用到的列不应该创建索引,如果建立了索引然而还会降低mysql的性能和增大了空间需求.很少数据的列也不应该建立索引,比如一个性别字段0或者1,在查询中,结果集的数据占了表中数据行的比例比较大,mysql需要扫描的行数很多,增加索引,并不能提高效率定义为text和image和bit数据类型的列不应该增加索引,当表的修改(UPDATE,INSERT,DELETE)操作远远大于检索(SELECT)操作时不应该创建索引,这两个操作是互斥的关系7.哪些情况会造成索引失效如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)索引字段的值不能有null值，有null值会使该列索引失效对于多列索引，不是使用的第一部分，则不会使用索引（最左原则）like查询以%开头如果列类型是字符串，那一定要在条件中将数据使用单引号引用起来,否则不使用索引在索引的列上使用表达式或者函数会使索引失效8.索引原理MySQL的基本存储结构是页(记录都存在页里边)：各个数据页可以组成一个双向链表每个数据页中的记录又可以组成一个单向链表每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录以其他列(非主键)作为搜索条件：只能从最小记录开始依次遍历单链表中的每条记录。所以说，如果我们写select*fromuserwhereindexname='xxx'这样没有进行任何优化的sql语句，默认会这样做：定位到记录所在的页：需要遍历双向链表，找到所在的页从所在的页内中查找相应的记录：由于不是根据主键查询，只能遍历所在页的单链表了很明显，在数据量很大的情况下这样查找会很慢！这样的时间复杂度为O（n）使用索引之后其实就是将无序的数据变成有序(相对)：很明显的是：没有用索引我们是需要遍历双向链表来定位对应的页，现在通过“目录”就可以很快地定位到对应的页上了！（二分查找，时间复杂度近似为O(logn)）其实底层结构就是B+树，B+树作为树的一种实现，能够让我们很快地查找出对应的记录面试题有商品表,有主键,goods_id,栏目列cat_id,价格price说:在价格列上已经加了索引,但按价格查询还是很慢,问可能是什么原因,怎么解决?答:在实际场景中,一个电商网站的商品分类很多,直接在所有商品中,按价格查商品,是极少的,一般客户都来到分类下,然后再查.改正:去掉单独的Price列的索引,加(cat_id,price)复合索引再查询索引优化策略选择唯一性索引唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。为经常需要排序、分组和联合操作的字段建立索引：为常作为查询条件的字段建立索引。限制索引的数目：越多的索引，会使更新表变得很浪费时间。尽量使用数据量少的索引如果索引的值很长，那么查询的速度会受到影响。尽量使用前缀来索引如果索引字段的值很长，最好使用值的前缀来索引。删除不再使用或者很少使用的索引最左前缀匹配原则，非常重要的原则。尽量选择区分度高的列作为索引区分度的公式是表示字段不重复的比例索引列不能参与计算，保持列“干净”：带函数的查询不参与索引。尽量的扩展索引，不要新建索引。六、插入优化InnoDB：禁用唯一性检查，唯一性校验会降低插入记录的速度，可以在插入记录之前禁用唯一性检查，插入数据完成后再开启禁用外键检查，插入数据之前执行禁止事务的自动提交禁止自动提交，插入数据之前执行禁止事务的自动提交批量插入数据，可以使用一条INSERT语句插入一条数据七、大表优化当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：1.限定数据的范围务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；2.读/写分离经典的数据库拆分方案，主库负责写，从库负责读；3.垂直分区根据数据库里面数据表的相关性进行拆分。例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。如下图所示，这样来说大家应该就更容易理解了4.水平分区保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。水平拆分可以支撑非常大的数据量。水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以水平拆分最好分库。5.数据库分库策略客户端代理：分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。当当网的Sharding-JDBC、阿里的TDDL是两种比较常用的实现。中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。我们现在谈的Mycat、360的Atlas、网易的DDB等等都是这种架构的实现。6.分库分表之后,id主键如何处理？因为要是分成多个表之后，每个表都是从1开始累加，这样是不对的，我们需要一个全局唯一的id来支持。生成全局id有下面这几种方式：UUID：不适合作为主键，因为太长了，并且无序不可读，查询效率低。比较适合用于生成唯一的名字的标示比如文件的名字。数据库自增id::两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。这种方式生成的id有序，但是需要独立部署数据库实例，成本高，还会有性能瓶颈。利用redis生成id:性能比较好，灵活方便，不依赖于数据库。但是，引入了新的组件造成系统更加复杂，可用性降低，编码更加复杂，增加了系统成本。Twitter的snowflake算法、美团的Leaf分布式ID生成系统","link":"https://xzzz2020.github.io/post/5NPno0The/"},{"title":"【总结】数据库基础","content":"该文章为知识总结的文章，如果是初学者，建议先从专栏学习：数据库专栏一、能简单介绍一下什么是Mysql吗？二、SQL的分类三、数据库三大范式1.第一范式2.第二范式3.第三范式4.总结四、事务的简介五、事务的特性1.原子性2.一致性3.隔离性4.持久性六、并发事务出现的问题七、事务隔离级别1.四个隔离级别八、数据库锁和并发策略1.常见的锁2.页级锁3.乐观锁4.悲观锁5.InnoDB锁算法九、给定业务场景说明设计数据库的思路十、说一下什么是池化设计十一、一条SQL语句执行慢的原因？1.分类讨论2.针对偶尔很慢的情况a.数据库在刷新脏页（flush）b.拿不到锁我能怎么办3.针对一直都这么慢的情况a.没用到索引b.用到了索引，但是系统误判了一、能简单介绍一下什么是Mysql吗？MySQL是一种关系型数据库在Java企业级开发中非常常用，因为MySQL是开源免费的阿里巴巴数据库系统也大量用到了MySQL，因此它的稳定性是有保障的MySQL的默认端口号是3306二、SQL的分类DQL--数据查询语言：代表关键字:selectDML--数据操纵语言：代表关键字:insert,delete,updateDDL--数据定义语言：代表关键字:create,drop,alter,TCL--事务控制语言：代表关键字:commit,rollback;DCL--数据控制语言：代表关键字:grant,revoke.三、数据库三大范式1.第一范式数据库表中不能出现重复记录，每个字段是原子性的不能再分学生编号学生姓名联系方式1001张三zs@gmail.com,13599999991002李四ls@gmail.com,136999999991001王五ww@163.net,13488888888学生编号重复，因为没有主键联系方式既有邮箱和电话因此需要修改成如下形式：学生编号(pk)学生姓名email联系电话1001张三zs@gmail.com13599999991002李四ls@gmail.com136999999991003王五ww@163.net13488888888每个行必须唯一，且存在主键列不能再分2.第二范式要求所有非主键字段完全依赖主键，不能产生部分依赖学生编号(PK)教师编号(PK)学生姓名教师姓名1001001张三王老师1002002李四赵老师1003001王五王老师1001002张三赵老师1001002爱迪生赵老师如果只是拿学生编号或者教师编号做主键，都不能确定唯一一行数据，所以采用联合主键学生姓名部分依赖了主键的一个字段学生编号，而没有依赖教师编号，而教师姓名部门依赖了主键的一个字段教师编号，这就是第二范式部分依赖。解决就是分表：学生信息表学生编号（PK）学生姓名1001张三1002李四1003王五教师信息表教师编号（PK）教师姓名001王老师002赵老师教师和学生的关系表学生编号(PK)教师编号(PK)10010011002002100300110010023.第三范式非主键字段不能传递依赖于主键字段。学生编号（PK）学生姓名班级编号班级名称1001张三01一年一班1002李四02一年二班1003王五03一年三班班级名称字段没有直接依赖于主键，班级名称字段依赖于班级编号，班级编号依赖于学生编号，那么这就是传递依赖继续分表学生信息表学生编号（PK）学生姓名班级编号1001张三011002李四021003王五03班级信息表班级编号班级名称01一年一班02一年二班03一年三班4.总结第一范式：有主键，具有原子性，字段不可分割第二范式：完全依赖，没有部分依赖第三范式：没有传递依赖数据库设计尽量遵循三范式，但是还是根据实际情况进行取舍，有时可能会拿冗余换速度，最终用目的要满足客户需求四、事务的简介当执行DML语句是其实就是开启一个事务关于事务的回滚需要注意：只能回滚insert、delete和update语句，不能回滚select（回滚select没有任何意义），对于create、drop、alter这些无法回滚.事务只对DML有效果。注意：rollback，或者commit后事务就结束了。五、事务的特性1.原子性整个事务中的所有操作，必须作为一个单元全部完成（或全部取消）。undolog名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的sql语句，他需要记录你要回滚的相应日志信息。undolog记录了这些回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undolog中的信息将数据回滚到修改之前的样子。2.一致性关注数据的可见性，中间状态的数据对外部不可见，只有最初状态和最终状态的数据对外可见数据库无法保证，需要从应用层角度考虑，用业务来实现。从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据3.隔离性并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的事务的隔离性是利用的是锁和MVCC机制。至于MVCC,即多版本并发控制(MultiVersionConcurrencyControl),一个行记录数据有多个版本对快照数据，这些快照数据在undolog中。如果一个事务读取的行正在做DELELE或者UPDATE操作，读取操作不会等行上的锁释放，而是读取该行的快照版本。4.持久性在事务完成以后，该事务对数据库所作的更改将持久地保存在数据库之中，并不会被回滚。事务的持久性是利用Innodb的redolog六、并发事务出现的问题脏读（Dirtyread）:当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。丢失修改（Losttomodify）:指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。不可重复读（Unrepeatableread）:指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。幻读（Phantomread）:幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。不可重复读和幻读区别：不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。七、事务隔离级别1.四个隔离级别读未提交：允许一个事务可以看到其他事务未提交的修改，可能会导致脏读、幻读或不可重复读。读已提交：允许一个事务只能看到其他事务已经提交的修改，可以阻止脏读，但是幻读或不可重复读仍有可能发生。可重复读：确保如果在一个事务中执行两次相同的SELECT语句，都能得到相同的结果，不管其他事务是否提交这些修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。串行化：将一个事务与其他事务完全地隔离，相当于加锁，该级别可以防止脏读、不可重复读以及幻读。隔离级别脏读不可重复读幻影读READ-UNCOMMITTED√√√READ-COMMITTED×√√REPEATABLE-READ××√SERIALIZABLE×××MySQLInnoDB存储引擎的默认支持的隔离级别是REPEATABLE-READ（可重读）。InnoDB存储引擎REPEATABLE-READ（可重读）事务隔离级别下使用的是Next-KeyLock锁算法，因此可以避免幻读的产生，这与其他数据库系统(如SQLServer)是不同的。所以说InnoDB存储引擎的默认支持的隔离级别是REPEATABLE-READ（可重读）已经可以完全保证事务的隔离性要求，即达到了SQL标准的SERIALIZABLE(可串行化)隔离级别。八、数据库锁和并发策略1.常见的锁MyIsam实现了表锁。表锁可以针对数据库表加锁，在锁的灵活性上不如行锁。表锁分为两种锁：读锁与写锁。InnoDB存储引擎实现了行锁与表锁（意向锁）。行锁可以以行为单位对数据集进行锁定。行锁也分为两种锁：共享锁与排他锁。InnoDB对于Update、Delete、insert语句会自动给涉及的数据集隐式的加上排他锁。对于select语句InnoDB不会加任何锁共享锁：允许一个事务读取一行，阻止其他事务获得相同数据集的排他锁。但允许其他事务获取共享锁。显示加锁select*fromtablewhere...lockinsharemode排他锁：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享与排他锁。但是可以对获取了排他锁的数据集进行单纯的查询访问。显示加锁sqlselect*fromtablewhere...forupdateinnoDB的行锁的实现方式是基于索引项的。这意味着即使你尝试获取不同行的排他锁，若使用了相同的索引键，也可能会造成锁冲突。表级锁和行级锁对比：表级锁：MySQL中锁定粒度最大的一种锁，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁。其锁定粒度最大，触发锁冲突的概率最高，并发度最低，MyISAM和InnoDB引擎都支持表级锁。行级锁：MySQL中锁定粒度最小的一种锁，只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。事务更新大表中的大部分数据直接使用表级锁效率更高；事务比较复杂，使用行级索很可能引起死锁导致回滚。2.页级锁页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁3.乐观锁乐观锁认为一个用户读数据的时候，别人不会去写自己所读的数据实现：时间戳就是在数据库表中单独加一列时间戳，比如“TimeStamp”，每次读出来的时候，把该字段也读出来，当写回去的时候，把该字段加1，提交之前，跟数据库的该字段比较一次，如果比数据库的值大的话，就允许保存，否则不允许保存，这种处理方法虽然不使用数据库系统提供的锁机制，但是这种方法可以大大提高数据库处理的并发量#每一个记录都有version，会有冗余，可以一个表一个versionSelectdata,versionfrombiaowhereid=#{id};Updatebiaosetdata=#{data},version=vsersion+1whereid=#{id}andversion=#{version};#一个表一个修改begin;Selectversionfromversion_biaowheretable_name=#{table_name};Updatebiaosetdata=#{data}whereid=#{id};Updateversion_biaosetversion=vsersion+1fromwhereversion=#{version};commit;4.悲观锁悲观锁就是在读取数据的时候，为了不让别人修改自己读取的数据，就会先对自己读取的数据加锁，只有自己把数据读完了，才允许别人修改那部分数据，或者反过来说，就是自己修改某条数据的时候，不允许别人读取该数据，只有等自己的整个事务提交了，才释放自己加上的锁，才允许其他用户访问那部分数据。实现：sql语句后边加上forupdateselectid,namfrombiaoforupdate;5.InnoDB锁算法间隙锁：锁定一个一个区间记录中的间隙，不包括记录本身行锁：单个行记录上的锁临键锁：锁定一个一个区间记录中的间隙以及记录本身九、给定业务场景说明设计数据库的思路分析场景选择存储引擎，比如业务是读多还是写多？需不需要支持事务？数据库设计的原则，遵循三大范式，但是可以做一些适当的反三大范式字段的设计，选择类型十、说一下什么是池化设计我们常见的如java线程池、jdbc连接池、redis连接池等就是这类设计的代表实现。这种设计会初始预设资源，解决的问题就是抵消每次获取资源的消耗，如创建线程的开销，获取远程连接的开销等。池化设计会配置一些参数，比如初始线程数，最大线程数等等，还会有一个阻塞队列，当一些请求过多时，会采用一些拒绝的策略在连接池中，创建连接后，将其放置在池中，并再次使用它，因此不必建立新的连接。如果使用了所有连接，则会建立一个新连接并将其添加到池中。连接池还减少了用户必须等待建立与数据库的连接的时间。十一、一条SQL语句执行慢的原因？1.分类讨论大多数情况是正常的，只是偶尔会出现很慢的情况。在数据量不变的情况下，这条SQL语句一直以来都执行的很慢。2.针对偶尔很慢的情况一条SQL大多数情况正常，偶尔才能出现很慢的情况，针对这种情况，我觉得这条SQL语句的书写本身是没什么问题的，而是其他原因导致的，那会是什么原因呢？a.数据库在刷新脏页（flush）当我们要往数据库插入一条数据、或者要更新一条数据的时候，我们知道数据库会在内存中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到磁盘中去，而是把这些更新的记录写入到redolog日记中去，等到空闲的时候，在通过redolog里的日记把最新的数据同步到磁盘中去。当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。刷脏页有两种场景会影响性能**redolog写满了：**redolog里的容量是有限的，如果数据库一直很忙，更新又很频繁，这个时候redolog很快就会被写满了，这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，全身心来把数据同步到磁盘中去的，而这个时候，就会导致我们平时正常的SQL语句突然执行的很慢，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了。**内存不够用了：**如果一次查询较多的数据，恰好碰到所查数据页不在内存中时，需要申请内存，而此时恰好内存不足的时候就需要淘汰一部分内存数据页，如果是干净页，就直接释放，如果恰好是脏页就需要刷脏页。b.拿不到锁我能怎么办这个就比较容易想到了，我们要执行的这条语句，刚好这条语句涉及到的表，别人在用，并且加锁了，我们拿不到锁，只能慢慢等待别人释放锁了。或者，表没有加锁，但要使用到的某个一行被加锁了，这个时候，我也没办法啊。3.针对一直都这么慢的情况先通过EXPLAN去分析SQL语句是否用到索引，主要关注type，possible_key，keys这几个字段a.没用到索引如果该字段没有加索引，那么自然没有用到索引字段有索引，但却没有用索引，那说明出现了索引失效，比如说like查询以%开头，或者不满足索引的最左原则，或者使用了Or关键字，或者索引字段的值有NULL值，或者使用了函数b.用到了索引，但是系统误判了非主键索引存储的是主键索引的值，如果SQL语句走的非主键索引，那么还需要到主键索引去寻找对应的data当一个SQL语句范围比较大，比如wherex&gt;0andx&lt;20000或者没有where条件，那么可能命中的数据非常多，甚至命中全表，而全表扫描顶多就是O(n)，此时再走索引，还会有两次索引寻找的时间消耗，即使索引查找非常快此时分析器就要判断是否走索引，采用的方式是抽样检测，来预测SQL语句范围中出现相同值的概率，比如在0-20000范围中，数字3可能出现了10次，也可能只出现1次，显然如果重复数字越少，走索引的性能越好","link":"https://xzzz2020.github.io/post/74It5jkMz/"},{"title":"【总结】ThreadLocal","content":"简介内存泄漏问题简介threadlocal在线程间是隔离的，不共享，用于存储线程的变量即使多个线程使用同一个ThreadLocal，也只能访问自己的属性ThreadLocal是使用的Key/Value的结构实现，内部有一个ThreadLocalMap内存泄漏问题ThreadLocal从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。在一些场景尤其是使用线程池)下，线程不会关闭，由于ThreadLocal.ThreadLocalMap的底层数据结构导致ThreadLocal中key可以被回收，但是这些key为null的Entry的value就会一直存在一条强引用链，会造成内存泄漏的情况，应该尽可能在每次使用ThreadLocal后手动调用remove()，以避免出现ThreadLocal经典的内存泄漏甚至是造成自身业务混乱的风险。","link":"https://xzzz2020.github.io/post/aX_Ohmt2H/"},{"title":"【总结】JUC并发包","content":"该文章为面试精华版，如果是初学者，建议学习专栏：Java并发专栏Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：JVM专栏和操作系统专栏1.CountDownLatch2.CyclicBarrier3.Semaphore4.FutureTask5.ForkJoinForkJoinPoolForkJoinTask6.Exchange7.Condition8.StampedLock9.ReentrantReadWriteLock读写锁10.锁的使用推荐比较总结1.CountDownLatch用来控制一个线程等待多个线程。维护了一个计数器cnt，每次调用countDown()方法会让计数器的值减1，减到0的时候，那些因为调用await()方法而在等待的线程就会被唤醒计数器的初始值是线程的数量或者任务的数量每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。通过CAS成功置为0的那个线程将会同时承担起唤醒队列中第一个节点线程的任务不足：CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。文章地址：https://blog.csdn.net/qq_43040688/article/details/1059353072.CyclicBarrier用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。和CountdownLatch相似，都是通过维护计数器来实现的。线程执行await()方法之后计数器会减1，并进行等待，直到计数器为0，所有调用await()方法而在等待的线程才能继续执行。CyclicBarrier有两个构造函数，其中parties指示计数器的初始值，barrierAction在所有线程都到达屏障的时候会执行一次。CyclicBarrier和CountdownLatch的区别？CyclicBarrier的计数器通过调用reset()方法可以循环使用，所以它才叫做循环屏障，而CountdownLatch是一次性的。CountdownLatch用于一个线程等待一组线程执行完任务，CyclicBarrier用于一组线程互相等待3.SemaphoreSemaphore类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。以下代码模拟了对某个服务的并发请求，每次只能有3个客户端同时访问，请求总数为10。publicclassSemaphoreExample{publicstaticvoidmain(String[]args){finalintclientCount=3;finalinttotalRequestCount=10;Semaphoresemaphore=newSemaphore(clientCount);ExecutorServiceexecutorService=Executors.newCachedThreadPool();for(inti=0;i&lt;totalRequestCount;i++){executorService.execute(()-&gt;{try{semaphore.acquire();System.out.print(semaphore.availablePermits()+&quot;&quot;);}catch(InterruptedExceptione){e.printStackTrace();}finally{semaphore.release();}});}executorService.shutdown();}}实现循环打印？下面的例子有ABC三个线程。A负责输出147B负责输出258C负责369。要求通过信号量机制控制这三个线程按照顺序输出。思路就是考虑前驱图，利用信号量实现：publicclassTest{publicstaticvoidmain(String[]args){newSemaphoreTest().print();}}classSemaphoreTest{privateinti=1;privateSemaphores1=newSemaphore(1);privateSemaphores2=newSemaphore(0);privateSemaphores3=newSemaphore(0);privateExecutorServicees=Executors.newFixedThreadPool(3);publicvoidprint(){es.execute(()-&gt;{while(i&lt;7){try{s1.acquire();System.out.println(i);i++;}catch(InterruptedExceptione){e.printStackTrace();}finally{s2.release();}}});es.execute(()-&gt;{while(i&lt;8){try{s2.acquire();System.out.println(i);i++;}catch(InterruptedExceptione){e.printStackTrace();}finally{s3.release();}}});es.execute(()-&gt;{while(i&lt;9){try{s3.acquire();System.out.println(i);i++;}catch(InterruptedExceptione){e.printStackTrace();}finally{s1.release();}}});es.shutdown();}}或者利用两个线程通过加锁，输出完就唤醒，自己等待，来实现循环打印4.FutureTask在介绍Callable时我们知道它可以有返回值，返回值通过Future进行封装。FutureTask实现了RunnableFuture接口，该接口继承自Runnable和Future接口，这使得FutureTask既可以当做一个任务执行，也可以有返回值。publicclassFutureTaskExample{publicstaticvoidmain(String[]args)throwsExecutionException,InterruptedException{FutureTask&lt;Integer&gt;futureTask=newFutureTask&lt;Integer&gt;(newCallable&lt;Integer&gt;(){@OverridepublicIntegercall()throwsException{intresult=0;for(inti=0;i&lt;100;i++){Thread.sleep(10);result+=i;}returnresult;}});ThreadcomputeThread=newThread(futureTask);computeThread.start();ThreadotherThread=newThread(()-&gt;{System.out.println(&quot;othertaskisrunning...&quot;);try{Thread.sleep(1000);}catch(InterruptedExceptione){e.printStackTrace();}});otherThread.start();System.out.println(futureTask.get());//获取返回值}}5.ForkJoin一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架，主要用于并行计算中思想：分治，fork分解任务，join收集数据Java标准库提供的java.util.Arrays.parallelSort(array)可以进行并行排序，它的原理就是内部通过Fork/Join对大数组分拆进行并行排序，在多核CPU上就可以大大提高排序的速度。ForkJoinPoolForkJoin使用ForkJoinPool来启动，它是一个特殊的线程池，线程数量取决于CPU核数ForkJoinPool实现了工作窃取算法来提高CPU的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。例如下图中，Thread2从Thread1的队列中拿出最晚的Task1任务，Thread1会拿出Task2来执行，这样就避免发生竞争。但是如果队列中只有一个任务时还是会发生竞争。ForkJoinTaskForkJoinTask就是ForkJoinPool里面的每一个任务。他主要有两个子类：RecursiveAction和RecursiveTask。然后通过fork()方法去分配任务执行任务，通过join()方法汇总任务结果，6.Exchange用于两个工作线程之间交换数据的封装工具类简单说就是一个线程在完成一定的事务后想与另一个线程交换数据，则第一个先拿出数据的线程会一直等待第二个线程，直到第二个线程拿着数据到来时才能彼此交换对应数据如果交换的是引用类型，发送的对象和接收的对象是同一个对象，可能会用严重的线程安全问题7.Condition提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式，但是这两者在使用方式以及功能特性上还是有差别的，等待是用await，通知是signal或者signalAll。await和Object.wait()类似，都会自动的释放锁，并且在唤起后需要重新获得锁想要await操作必须需要获得到锁wait和await的区别？waitawait是配合synchronized关键字的是配合Lock锁的等待队列的唤醒受到JVM的影响，是随机的唤醒等待队列FIFO的，先阻塞先唤醒不可以被打断可以被打断等待队列只有一个每一个Condition都具有一个等待队列，可以创建多个Condition8.StampedLock如果我们深入分析ReadWriteLock，会发现它有个潜在的问题：如果有线程正在读，写线程需要等待读线程释放锁后才能获取写锁，即读的过程中不允许写，这是一种悲观的读锁。要进一步提升并发执行效率，Java8引入了新的读写锁：StampedLock。出现的问题：如果有999个需要读锁，1个需要写锁，此时，写的线程，很难得到执行。StampedLock和ReadWriteLock相比，改进之处在于：读的过程中也允许获取写锁后写入！这样一来，我们读的数据就可能不一致，所以，需要一点额外的代码来判断读的过程中是否有写入，这种读锁是一种乐观锁。乐观锁的意思就是乐观地估计读的过程中大概率不会有写入，因此被称为乐观锁。反过来，悲观锁则是读的过程中拒绝有写入，也就是写入必须等待。显然乐观锁的并发效率更高，但一旦有小概率的写入导致读取的数据不一致，需要能检测出来，再读一遍就行。这是个不可重入锁。publicclassPoint{privatefinalStampedLockstampedLock=newStampedLock();privatedoublex;privatedoubley;publicvoidmove(doubledeltaX,doubledeltaY){longstamp=stampedLock.writeLock();//获取写锁try{x+=deltaX;y+=deltaY;}finally{stampedLock.unlockWrite(stamp);//释放写锁}}publicdoubledistanceFromOrigin(){longstamp=stampedLock.tryOptimisticRead();//获得一个乐观读锁//注意下面两行代码不是原子操作//假设x,y=(100,200)doublecurrentX=x;//此处已读取到x=100，但x,y可能被写线程修改为(300,400)doublecurrentY=y;//此处已读取到y，如果没有写入，读取是正确的(100,200)//如果有写入，读取是错误的(100,400)if(!stampedLock.validate(stamp)){//检查乐观读锁后是否有其他写锁发生stamp=stampedLock.readLock();//获取一个悲观读锁try{currentX=x;currentY=y;}finally{stampedLock.unlockRead(stamp);//释放悲观读锁}}returnMath.sqrt(currentX*currentX+currentY*currentY);}}9.ReentrantReadWriteLock读写锁一般情况下都不会使用读锁和写锁是分离的一个线程读的时候允许其他线程也可以读一个线程写的时候不允许其他线程写读和写也不允许同时进行出现的问题是：可能会造成饥饿现象，写的线程迟迟无法执行任务10.锁的使用推荐原文：https://blog.csdn.net/qq_43040688/article/details/106032189比较synchronizedStampedLockLock是JVM的的内置锁，每个JDK版本都会优化是一个Java类，可以更好的扩展是一个Java类，可以更好的扩展都是悲观锁提供了写的乐观锁都是悲观锁，但是提供了自旋锁，或者不阻塞的获取锁性能一般，因为有一个从用户态到内核态的过程性能最好，可以代替读写锁性能十分不稳定，在复杂的读写环境下，性能十分差不具有公平锁不具有公平锁具有公平锁锁会自动释放锁需要手动释放锁需要手动释放总结StampedLock是性能最好的，可以胜任复杂的读写多线程环境令人惊奇的是synchronized，由于是内置锁，每个JDK版本都会优化，尤其在复杂的读写多线程情况下，表现依然很优秀。Lock虽然提供了读写锁，但是性能特别差；而ReentrantLock性能十分好，同时功能丰富个人推荐：如果时读写环境，推荐使用StampedLock；如果是正常的加锁，推荐使用synchronized；如果需要对锁有更多的控制，推荐使用ReentrantLock","link":"https://xzzz2020.github.io/post/2imuXDnFS/"},{"title":"【总结】Java内存模型","content":"该文章为面试精华版，如果是初学者，建议学习专栏：Java并发专栏Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：JVM专栏和操作系统专栏一、Java内存模型JMM二、内存间交互操作三、内存模型三大特性原子性可见性有序性四、重排序五、happens-before原则六、volatitle1.volatitle变量为何立即可见？2.如何禁止重排序优化？3.和synchronized的区别？七、单例模式1.饿汉式2.普通的懒汉式3.同步方法的懒汉式4.二次检查5.Holder方式6.枚举一、Java内存模型JMM处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。二、内存间交互操作1.lock（锁定）：作用于`主内存`的变量，它把一个变量标识为一条线程独占的状态。2.unlock（解锁）：作用于`主内存`的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。//读入工作内存3.read（读取）：主内存---&gt;工作内存。4.load（载入）：把read操作从主内存中得到的`变量值`---&gt;`工作内存的变量副本`。//中间步骤5.use（使用）：工作内存中一个`变量的值`---&gt;`执行引擎`，每当虚拟机遇到一个需要`使用到变量的值`的字节码指令时将会执行这个操作。6.assign（赋值）：把一个`从执行引擎`接收到的值---赋给---&gt;`工作内存的变量`，每当虚拟机遇到一个给变量`赋值`的字节码指令时执行这个操作。//写入主内存7.store（存储）：把工作内存中一个`变量的值`---&gt;`主内存`。8.write（写入）：把store操作从工作内存中得到的变量的值---&gt;主内存的变量。三、内存模型三大特性原子性Java内存模型保证了read、load、use、assign、store、write、lock和unlock操作具有原子性，例如对一个int类型的变量执行assign赋值操作，这个操作就是原子性的。但是Java内存模型允许虚拟机将没有被volatile修饰的64位数据（long，double）的读写操作划分为两次32位的操作来进行，即load、store、read和write操作可以不具备原子性。int等原子性的类型在多线程环境中不会出现线程安全问题？有一个错误认识就是，int等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt属于int类型变量，1000个线程对它进行自增操作之后，得到的值为997而不是1000。为了方便讨论，将内存间的交互操作简化为3个：load、assign、store。下图演示了两个线程同时对cnt进行操作，load、assign、store这一系列操作整体上看不具备原子性，那么在T1修改cnt并且还没有将修改后的值写入主内存，T2依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中cnt的值最后为1而不是2。因此对int类型读写操作满足原子性只是说明load、assign、store这些单个操作具备原子性。如何保证原子性呢？Atomic原子类可以利用CAS的方式，在不加锁的情况下保证原子性synchronized互斥锁来保证操作的原子性，它对应的内存间交互操作为：lock和unlock可见性可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。主要有三种实现可见性的方式：volatile关键字，是工作内存失效synchronized，对一个变量执行unlock操作之前，必须把变量值同步回主内存。final，被final关键字修饰的字段在构造器中一旦初始化完成，并且没有发生this逃逸（其它线程通过this引用访问到初始化了一半的对象），那么其它线程就能看见final字段的值。publicclassFinalTest{finalinti;staticFinalTestobj;publicFinalTest(){i=1;/***这里会使正在被构造的对象逸出，如果和上一句做了重排序，那么其他线程就可以通过obj访问到还为被初始化的final域。**/obj=this;}}类的final域在编译器层面会保证在类的构造器运行结束之前一定要初始化完成，同时Java内存模型会保证对象实例化后它的final域对其他线程是可见的，然而非final域并没有这种待遇。例如如下代码：publicclassFinalFiled{finalintx;inty;staticFinalFiledf;publicFinalFiled(){x=100;y=100;}staticvoidwriter(){f=newFinalFiled();}staticvoidreader(){if(f!=null){inti=f.x;//保证此时一定是100intj=f.y;//有可能此时还是0}}}有序性有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在Java内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。如何保证有序性？volatile关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。通过synchronized来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。四、重排序执行任务的时候，为了提高编译器和处理器的执行性能，编译器和处理器(包括内存系统，内存在行为没有重排但是存储的时候是有变化的)会对指令重排序。编译器优化的重排序是在编译时期完成的，指令重排序和内存重排序是处理器重排序编译器优化的重排序，在不改变单线程语义的情况下重新安排语句的执行顺序指指令级并行重排序，处理器的指令级并行技术将多条指令重叠执行，如果不存在数据的依赖性将会改变语句对应机器指令的执行顺序内存系统的重排序，因为使用了读写缓存区，使得看起来并不是顺序执行的五、happens-before原则程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。volatile规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。传递性：如果Ahappens-beforeB，并且Bhappens-beforeC，那么Ahappens-beforeC。start()规则：如果线程A执行操作ThreadB.start()，那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B的任意操作happens-before于线程A从ThreadB.join()操作成功返回。含义：两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按照happens-before关系来执行的结果一致，那么这种重排序并不非法。所以只要能够满足A的操作结果一定要对B可见六、volatitle1.volatitle变量为何立即可见？在对有volatile修饰符修饰的共享变量进行写操作时，汇编代码会多一条lock前缀的指令。该指令有如下两个作用：将当前缓存行的数据回写到内存中使其他cpu里缓存了该内存地址的数据无效(缓存一致性机制)2.如何禁止重排序优化？通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化3.和synchronized的区别？volatile本质是在告诉JVM当前变量在寄存器(工作内存)中的值是不确定的,需要从主存中读取;synchronized则是锁定当前变量，只有当前线程可以访问该变量,其他线程被阻塞住直到该线程完成变量操作为止volatile仅能使用在变量级别;synchronized则可以使用在变量、方法和类级别volatile仅能实现变量的修改可见性,不能保证原子性;而synchronized则可以保证变量修改的可见性和原子性volatile不会造成线程的阻塞;synchronized可能会造成线程的阻塞volatile标记的变量不会被编译器优化;synchronized标记的变量可以被编译器优化七、单例模式1.饿汉式publicclassSingleton{privatefinalstaticSingletonINSTANCE=newSingleton();privateSingleton(){}publicstaticSingletongetInstance(){returnINSTANCE;}}2.普通的懒汉式publicclassSingleton{privatestaticSingletoninstance;privateSingleton(){}publicstaticSingletongetInstance(){if(instance==null){instance=newSingleton();}returninstance;}}线程不安全，不支持多线程3.同步方法的懒汉式classSingleton{privatestaticSingletonsingleton;privateSingleton(){}publicstaticsynchronizedSingletongetSingleton(){if(singleton==null){singleton=newSingleton();}returnsingleton;}}线程安全，但是性能差4.二次检查classSingleton{privatestaticvolatileSingletonsingleton;privateSingleton(){}publicstaticSingletongetSingleton(){if(singleton==null){synchronized(Singleton.class){if(singleton==null){singleton=newSingleton();}}}returnsingleton;}}需要加一个volatile关键字，避免指令重排序如果不加volatile关键字，可能会出现空指针异常，因为在构造singleton的时候，可能也会构造其他的对象，如果出现了指令重排序，会导致singleton构造完成时，其他对象没有构造完成5.Holder方式classSingleton{privateSingleton(){}privatestaticclassinstanceHolder{privatestaticSingletonsingleton=newSingleton();}publicstaticSingletongetSingleton(){returninstanceHolder.singleton;}}静态内部类方式在Singleton类被装载时并不会立即实例化，而是在需要实例化时，调用getInstance方法，才会装载SingletonInstance类，从而完成对象的实例化。同时，因为类的静态属性只会在第一次加载类的时候初始化，也就保证了SingletonInstance中的对象只会被实例化一次，并且这个过程也是线程安全的。6.枚举classSingleton{privateSingleton(){}privateenumenmuSingleton{INSTANCE;privateSingletonsingleton;enmuSingleton(){singleton=newSingleton();}publicSingletongetSingleton(){returnsingleton;}}publicstaticSingletongetSingleton(){returnenmuSingleton.INSTANCE.getSingleton();}}","link":"https://xzzz2020.github.io/post/vKnc9DHsO/"},{"title":"【总结】Java并发实现原理","content":"该文章为面试精华版，如果是初学者，建议学习专栏：Java并发专栏Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：JVM专栏和操作系统专栏1.类锁和对象锁的区别2.synchronize底层实现原理3.什么是锁重入？4.为什么会对synchronized嗤之以鼻4.锁优化5.自旋锁和自适应自旋锁6.锁消除7.锁粗化8.锁膨胀和锁降级9.偏向锁10.轻量级锁10.重量级锁11.ReentrantLock12.synchronize和ReentrantLock1.类锁和对象锁的区别对象锁对象锁有两种，第一种是在普通方法上加synchronize关键字，一种是使用synchronize同步代码块同步一个对象//同步代码块publicvoidfunc(){synchronized(this){//...}}//同步一个方法publicsynchronizedvoidfunc(){//...}作用都是同一个对象，如果不同线程去争抢同一个对象的头，就会陷入阻塞，如果是争抢不同对象的头，则不会阻塞类锁类锁有两种，第一种是在静态方法上加synchronize关键字，一种是使用synchronize同步代码块同步类//同步一个类publicvoidfunc(){synchronized(SynchronizedExample.class){//...}}publicsynchronizedstaticvoidfun(){//...}作用于整个类，如果是一个类不同的对象，调用这些方法的时候，会陷入阻塞类锁是一种特殊的对象锁，类锁和对象锁互不干扰，也就是说一个线程访问同步静态方法，另一个线程访问同步普通方法，是不会阻塞的publicclassTest{publicstaticvoidmain(String[]args){ExecutorServiceexecutor=Executors.newFixedThreadPool(2);Solutionsolution=newSolution();executor.execute(newRunnable(){@Overridepublicvoidrun(){solution.fun2();}});executor.execute(newRunnable(){@Overridepublicvoidrun(){Solution.fun1();}});executor.shutdown();}}classSolution{publicsynchronizedstaticvoidfun1(){System.out.println(&quot;fun1...&quot;);try{TimeUnit.SECONDS.sleep(5);}catch(InterruptedExceptione){e.printStackTrace();}}publicsynchronizedvoidfun2(){System.out.println(&quot;fun2...&quot;);try{TimeUnit.SECONDS.sleep(5);}catch(InterruptedExceptione){e.printStackTrace();}}}2.synchronize底层实现原理每个对象出生就有一个对象头，而MarkWord的中会包含锁信息和hashcode信息synchronize获取锁的过程其实是在MarkWord加入线程信息的过程Monitor:每个Java对象天生自带了一把看不见的锁3.什么是锁重入？就是如果一个线程获取了一个对象的锁，如果在这个时候，又尝试获取这个对象的锁，会直接进入：classSolution{privatevoidtest(){synchronized(this){synchronized(this){//执行代码}}}}synchronize和ReentrantLock都是支持可重入的4.为什么会对synchronized嗤之以鼻早期版本中,synchronized属于重量级锁,依赖于MutexLock实现线程之间的切换需要从用户态转换到核心态,开销较大4.锁优化synchronized有四种状态无锁、偏向锁、轻量级锁、重量级锁偏向锁不会使用CAS操作获取锁，直接让第一次获取对象头markword线程访问，当有其他线程争用对象头时，会结束偏向，膨胀成轻量级锁轻量级锁会使用CAS操作来获取锁，当获取锁失败的时候，会采用自旋的方式，如果多次失败，会锁升级为重量级锁同时优化了自旋使用自适应自旋，自旋的次数不固定，会根据上次自旋的次数来决定这次自旋的次数来决定这次自旋的次数重量级锁和轻量级锁的差异在于，线程获取不到锁，就会陷入阻塞，切换锁的性能十分差，频繁的切换锁就会造成大量的性能优化锁升级策略主要应对一系列操作频繁的获取锁和释放锁，将扩大加锁的范围，一次加锁就可以完成操作锁消除会根据逃逸分析，当共享变量并不会被其他线程访问，则可以消除加锁的过程5.自旋锁和自适应自旋锁互斥同步进入阻塞状态的开销都很大，应该尽量避免。在许多应用中，共享数据的锁定状态只会持续很短的一段时间。自旋锁的思想是让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用CPU时间，它只适用于共享数据的锁定状态很短的场景。在JDK1.6中引入了自适应的自旋锁。自适应意味着自旋的次数不再固定了，而是由前一次在同一个锁上的自旋次数及锁的拥有者的状态来决定。6.锁消除锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。对于一些看起来没有加锁的代码，其实隐式的加了很多锁。例如下面的字符串拼接代码就隐式加了锁publicstaticStringconcatString(Strings1,Strings2,Strings3){returns1+s2+s3;}String是一个不可变的类，编译器会对String的拼接自动优化。在JDK1.5之前，会转化为StringBuffer对象的连续append()操作（JDK1.6之后变成StringBuider）：publicstaticStringconcatString(Strings1,Strings2,Strings3){StringBuffersb=newStringBuffer();sb.append(s1);sb.append(s2);sb.append(s3);returnsb.toString();}每个append()方法中都有一个同步块。虚拟机观察变量sb，很快就会发现它的动态作用域被限制在concatString()方法内部。也就是说，sb的所有引用永远不会逃逸到concatString()方法之外，其他线程无法访问到它，因此可以进行消除。​7.锁粗化如果一系列的连续操作都对同一个对象反复加锁和解锁，频繁的加锁操作就会导致性能损耗。上一节的示例代码中连续的append()方法就属于这类情况。如果虚拟机探测到由这样的一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。对于上一节的示例代码就是扩展到第一个append()操作之前直至最后一个append()操作之后，这样只需要加锁一次就可以了。8.锁膨胀和锁降级所谓锁的升级、降级，就是JVM优化synchronized运行的机制，当JVM检测到不同的竞争状况时，会自动切换到适合的锁实现，这种切换就是锁的升级、降级。9.偏向锁偏向锁的思想是偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连CAS操作也不再需要。当锁对象第一次被线程获得的时候，进入偏向状态，标记为101。同时使用CAS操作将线程ID记录到MarkWord中，如果CAS操作成功，这个线程以后每次进入这个锁相关的同步块就不需要再进行任何同步操作。当有另外一个线程去尝试获取这个锁对象时，偏向状态就宣告结束，此时撤销偏向（RevokeBias）后恢复到未锁定状态或者轻量级锁状态10.轻量级锁轻量级锁是相对于传统的重量级锁而言，它使用CAS操作来避免重量级锁使用互斥量的开销。对于绝大部分的锁，在整个同步周期内都是不存在竞争的，因此也就不需要都使用互斥量进行同步，可以先采用CAS操作进行同步，如果CAS失败了再改用互斥量进行同步。当尝试获取一个锁对象时，如果锁对象标记为001，说明锁对象的锁未锁定（unlocked）状态。此时虚拟机在当前线程的虚拟机栈中创建LockRecord，然后使用CAS操作将对象的MarkWord更新为LockRecord指针。如果CAS操作成功了，那么线程就获取了该对象上的锁，并且对象的MarkWord的锁标记变为00，表示该对象处于轻量级锁状态。如果CAS操作失败了，虚拟机首先会检查对象的MarkWord是否指向当前线程的虚拟机栈，如果是的话说明当前线程已经拥有了这个锁对象，那就可以直接进入同步块继续执行，否则说明这个锁对象已经被其他线程线程抢占了。当竞争线程尝试占用轻量级锁失败多次之后（使用自旋）轻量级锁就会膨胀为重量级锁，重量级线程指针指向竞争线程，竞争线程也会阻塞，等待轻量级线程释放锁后唤醒他。10.重量级锁重量级锁的加锁、解锁过程和轻量级锁差不多，区别是：竞争失败后，线程阻塞，释放锁后，唤醒阻塞的线程，不使用自旋锁，不会那么消耗CPU，所以重量级锁适合用在同步块执行时间长的情况下。11.ReentrantLockReentrantLock是java.util.concurrent（J.U.C）包中的锁。ReenTrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。想尽办法避免线程进入内核的阻塞状态是我们去分析和理解锁设计的关键钥匙。支持公平锁，但是只是相对公平，并不能一定的保证公平，可以避免线程的饥饿现象，即长时间获取不到CPU的执行权，但是如果没有业务需求，不建议使用，因为其会降低性能必须手动的释放锁，一般使用try...catch..finally释放锁支持可重入12.synchronize和ReentrantLockLock基于AQS实现，通过int类型状态和CAS机制来维护锁的获取与释放synchronized需要通过monitor，经历一个从用户态到内核态的转变过程，更加耗时比较synchronizedLock锁的实现是java内置关键字，在jvm层面是个java类能否判断状态无法判断是否获取锁的状态可以判断是否获取到锁释放锁的方式会自动释放锁需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁等待可中断线程会一直等待下去如果尝试获取不到锁，线程可以不用一直等待就结束公平锁不支持支持公平锁性能新版本Java对synchronized进行了很多优化，例如自旋锁等基于AQS实现，性能和synchronize差不多使用建议：除非需要使用ReentrantLock的高级功能，否则优先使用synchronized。这是因为synchronized是JVM实现的一种锁机制，JVM原生地支持它，而ReentrantLock不是所有的JDK版本都支持。并且使用synchronized不用担心没有释放锁而导致死锁问题，因为JVM会确保锁的释放。","link":"https://xzzz2020.github.io/post/7zdoEh6sT/"},{"title":"【总结】Java并发基础","content":"该文章为面试精华版，如果是初学者，建议学习专栏：Java并发专栏Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：JVM专栏和操作系统专栏1.进程和线程的区别2.start()方法和run()方法的区别3.JAVA线程实现/创建方式4.如何实现处理线程的返回值5.线程的状态6.sleep和wait方法的差异7.notify和notifyAll的区别8.守护线程机制9.中断机制InterruptedExceptioninterrupted()10.保证线程安全的方式不可变对象互斥同步非阻塞同步--CAS无同步方案11.Java中用到的线程调度1.进程和线程的区别初期计算机采用串行方式执行任务，需要等待用户输入指令，效率很低；接着计算机采用批处理批量执行用户指令，但是如果有一条指令需要读取大量的数据，此时CPU仍然处于停滞状态，此时就出现了进程。进程有自己的内存空间，互相之间不干扰，可以保存自己的运行状态可以互相切换，虽然一个CPU依然只能运行一个进程，但当时间片比较小的时候，看起来就像是运行多个程序一样而线程是为了更进一步的粒度控制，是进程的一个子任务，共享进程的资源，相互切换更加迅速进程和线程的区别？拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程CPU环境的保存及新调度进程CPU环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小通信方面：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助IPC。Java与进程和线程的关系：Java对操作系统提供的功能进行封装,包括进程和线程运行一个程序会产生一个进程,进程包含至少一个线程每个进程对应一个JVM实例,多个线程共享JVM里的堆Java采用单线程编程模型,程序会自动创建主线程主线程可以创建子线程,原则上要后于子线程完成执行2.start()方法和run()方法的区别Thread中调用start方法默认调用的start0方法，会创建一个子线程并执行run方法。Thread中run方法，默认调用的是类属性中Runnable接口的run方法，这个体现了策略模式，即执行和策略分离，由用户定义执行的策略3.JAVA线程实现/创建方式有三种使用线程的方法：实现Runnable接口；实现Callable接口；继承Thread类实现Runnable和Callable接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过Thread来调用。可以说任务是通过线程驱动从而执行的。实现接口比继承Thread要好，因为：Java不支持多重继承，因此继承了Thread类就无法继承其它类，但是可以实现多个接口；类可能只要求可执行就行，继承整个Thread类开销过大。4.如何实现处理线程的返回值主线程等待法：利用循环不断的判断，控制和实现很复杂使用Thread的join方法，阻塞主线程使用Callable接口实现：通过FutureTask或者线程池获取5.线程的状态新建（New）创建后尚未启动。可运行（Runnable）可能正在运行，也可能正在等待CPU时间片。包含了操作系统线程状态中的Running和Ready。阻塞（Blocked）等待获取一个排它锁，如果其线程释放了锁就会结束此状态。无限期等待（Waiting）等待其它线程显式地唤醒，否则不会被分配CPU时间片。进入方法退出方法没有设置Timeout参数的Object.wait()方法Object.notify()/Object.notifyAll()没有设置Timeout参数的Thread.join()方法被调用的线程执行完毕LockSupport.park()方法LockSupport.unpark(Thread)限期等待（TimedWaiting）无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。调用Thread.sleep()方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。调用Object.wait()方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用Thread.sleep()和Object.wait()等方法进入进入方法退出方法Thread.sleep()方法时间结束设置了Timeout参数的Object.wait()方法时间结束/Object.notify()/Object.notifyAll()设置了Timeout参数的Thread.join()方法时间结束/被调用的线程执行完毕LockSupport.parkNanos()方法LockSupport.unpark(Thread)LockSupport.parkUntil()方法LockSupport.unpark(Thread)死亡（Terminated）可以是线程结束任务之后自己结束，或者产生了异常而结束6.sleep和wait方法的差异最主要的本质区别：Thread.sleep只会让出CPU,不会导致锁行为的改变Object.wait不仅让出CPU,还会释放已经占有的同步资源锁7.notify和notifyAll的区别锁池：假设线程A已经拥有了某个对象(不是类)的锁，而其它线程B、C想要调用这个对象的某个synchronized方法(或者块)，由于B、C线程在进入对象的synchronized方法(或者块)之前必须先获得该对象锁的拥有权，而恰巧该对象的锁目前正被线程A所占用，此时B、C线程就会被阻塞，进入一个地方去等待锁的释放，这个地方便是该对象的锁池等待池：假设线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁，同时线程A就进入到了该对象的等待池中，进入到等待池中的线程不会去竞争该对象的锁。notifyAll会让所有处于等待池的线程全部进入锁池去竞争获取锁的机会notify只会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会。8.守护线程机制守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。main()属于非守护线程。可以使用setDaemon()方法将一个线程设置为守护线程publicstaticvoidmain(String[]args){Threadthread=newThread(newMyRunnable());thread.setDaemon(true);}9.中断机制InterruptedException通过调用一个线程的interrupt()来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出InterruptedException，从而提前结束该线程。但是不能中断I/O阻塞和synchronized锁阻塞。对于以下代码，在main()中启动一个线程之后再中断它，由于线程中调用了Thread.sleep()方法，因此会抛出一个InterruptedException，从而提前结束线程，不执行之后的语句。publicclassInterruptExample{privatestaticclassMyThread1extendsThread{@Overridepublicvoidrun(){try{Thread.sleep(2000);System.out.println(&quot;Threadrun&quot;);}catch(InterruptedExceptione){e.printStackTrace();}}}publicstaticvoidmain(String[]args)throwsInterruptedException{Threadthread1=newMyThread1();thread1.start();thread1.interrupt();System.out.println(&quot;Mainrun&quot;);}}interrupted()如果一个线程的run()方法执行一个无限循环，并且没有执行sleep()等会抛出InterruptedException的操作，那么调用线程的interrupt()方法就无法使线程提前结束。但是调用interrupt()方法会设置线程的中断标记，此时调用interrupted()方法会返回true。因此可以在循环体中使用interrupted()方法来判断线程是否处于中断状态，从而提前结束线程。publicclassInterruptExample{privatestaticclassMyThread2extendsThread{@Overridepublicvoidrun(){while(!interrupted()){//..}System.out.println(&quot;Threadend&quot;);}}publicstaticvoidmain(String[]args)throwsInterruptedException{Threadthread2=newMyThread2();thread2.start();thread2.interrupt();}}10.保证线程安全的方式不可变对象这是一种无锁的设计模式，因为对于不可变对象没有任何机会去修改这个对象的属性或者引用类型final关键字修饰的基本数据类型String枚举类型Number部分子类，如Long和Double等数值包装类型，BigInteger和BigDecimal等大数据类型。但同为Number的原子类AtomicInteger和AtomicLong则是可变的。对于集合类型，可以使用Collections.unmodifiableXXX()方法来获取一个不可变的集合，先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常互斥同步synchronize和ReentrantLock非阻塞同步--CAS是一种乐观锁，先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。CAS指令需要有3个操作数，分别是内存地址V、旧的预期值A和新值B。当执行操作时，只有当V的值等于A，才将V的值更新为B。无同步方案要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。栈封闭多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。publicclassStackClosedExample{publicvoidadd100(){intcnt=0;for(inti=0;i&lt;100;i++){cnt++;}System.out.println(cnt);}publicstaticvoidmain(String[]args){StackClosedExampleexample=newStackClosedExample();ExecutorServiceexecutorService=Executors.newCachedThreadPool();executorService.execute(()-&gt;example.add100());executorService.execute(()-&gt;example.add100());executorService.shutdown();}}线程本地存储可以使用ThreadLocal，实现线程本地存储功能，这样不同线程访问数据时，只能访问属于本线程的数据，不会干扰到其他点线程可重入代码最简单的理解就是任何变量都是局部变量，保证在被任何一个函数调用时都以同样的方式运行美，也就是说多个线程执行这个代码，只要赋予方法参数相同，方法结果则都一样11.Java中用到的线程调度抢占式调度：抢占式调度指的是每条线程执行的时间、线程的切换都由系统控制，系统控制指的是在系统某种运行机制下，可能每条线程都分同样的执行时间片，也可能是某些线程执行的时间片较长，甚至某些线程得不到执行的时间片。在这种机制下，一个线程的堵塞不会导致整个进程堵塞。Java中线程会按优先级分配CPU时间片运行，且优先级越高越优先执行，但优先级高并不代表能独自占用执行时间片，可能是优先级高得到越多的执行时间片，反之，优先级低的分到的执行时间少但不会分配不到执行时间","link":"https://xzzz2020.github.io/post/k2Dw6UqvL/"},{"title":"【总结】CAS","content":"该文章为面试精华版，如果是初学者，建议学习专栏：Java并发专栏Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：JVM专栏和操作系统专栏一、CAS原理及缺陷二、ABA问题及解决三、atomic类四、Unsafe类一、CAS原理及缺陷原理：CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。从思想上来说，Synchronized属于悲观锁，悲观地认为程序中的并发情况严重，所以严防死守。CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。缺点：在竞争激烈的时候，CPU开销较大在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。不能保证代码块的原子性CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证多个变量共同进行原子性的更新，就不得不使用Synchronized了二、ABA问题及解决什么是ABA？CAS的机制是在赋值的时候进行比较，如果此时的数值没有修改，则可以完成修改但是，如果一个对象或者变量出现了：A=&gt;B=&gt;......=&gt;A，此时CAS算法进行比较，会没有任何问题，进行修改。但是此时可能已经被修改过了无数次，其他线程的修改就丢失了，在复杂的数据结构比如链表，队列，栈、树等都可能出现不可预知的问题解决方式–AtomicStampedReference加一个版本号，除了比较对象值，还需要比较状态戳，类似于时间戳每次修改成功也会同时修改状态戳三、atomic类在高并发条件下，如果都需要对一些基本类型进行修改，就会破坏其原子性Java并发包提供了一个原子类，基于的是用了Unsafe类的CAS操作主要分为基本类型、数组类型、引用类型和对象的属性子四类四、Unsafe类很多Java的基础类库，包括一些被广泛使用的高性能开发库都是基于Unsafe类开发的，比如Netty、Cassandra、Hadoop、Kafka等。Unsafe类在提升Java运行效率，增强Java语言底层操作能力方面起了很大的作用。Java和C++语言的一个重要区别就是Java中我们无法直接操作一块内存区域，不能像C++中那样可以自己申请内存和释放内存。Java中的Unsafe类为我们提供了类似C++手动管理内存的能力，同时也有了指针的问题。","link":"https://xzzz2020.github.io/post/DjYrJcxKl/"},{"title":"【总结】阻塞队列","content":"该文章为面试精华版，如果是初学者，建议学习专栏：Java并发专栏Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：JVM专栏和操作系统专栏一、ArrayBlockingQueue二、LinkedBlockingQueue三、PriorityBlockingQueue四、DelayQueue五、SynchronousQueue六、LinkedTransferQueue七、LinkedBlockingDeque一、ArrayBlockingQueue用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指先阻塞的线程先访问，通常情况下为了保证公平性会降低吞吐量。二、LinkedBlockingQueue基于链表的无界阻塞队列，默认创建一个类似无限大小的容量同ArrayListBlockingQueue类似，此队列按照先进先出（FIFO）的原则对元素进行排序。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。三、PriorityBlockingQueue是一个支持优先级的无界队列。默认情况下元素采取自然顺序升序排列。可以自定义实现compareTo()方法来指定元素进行排序规则，或者初始化PriorityBlockingQueue时，指定构造参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。四、DelayQueue是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。可以用于：缓存系统设计，当可以取出任务时，代表缓存期到了；定时任务调度，保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行五、SynchronousQueue是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给另外一个线程使用SynchronousQueue的吞吐量高于LinkedBlockingQueue和ArrayBlockingQueue六、LinkedTransferQueue是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，LinkedTransferQueue多了tryTransfer和transfer方法，是一种预占的模式，判断有没有线程空闲，有就直接让其拿走，没有就占着这个位置直到任务被拿到或者超时或者中断：transfer方法：如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。tryTransfer方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。对于带有时间限制的tryTransfer(Ee,longtimeout,TimeUnitunit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。七、LinkedBlockingDeque是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。在初始化LinkedBlockingDeque时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在“工作窃取”模式中，Fork/Join框架会窃取其他线程队尾的任务。","link":"https://xzzz2020.github.io/post/YWCL9C2A8/"},{"title":"【总结】线程池","content":"该文章为面试精华版，如果是初学者，建议学习专栏：Java并发专栏Java并发需要结合JVM以及操作系统的相关知识，建议先学习这两个部分：JVM专栏和操作系统专栏一、ThreadPoolExecutor参数含义1.什么时候创建新的线程？2.如何关闭线程池？二、拒绝策略三、线程池的状态四、线程池分类newCachedThreadPoolnewFixedThreadPoolnewSingleThreadExecutornewScheduledThreadPoolnewWorkStealingPool五、使用线程池的好处一、ThreadPoolExecutor参数含义publicThreadPoolExecutor(intcorePoolSize,intmaximumPoolSize,longkeepAliveTime,TimeUnitunit,BlockingQueue&lt;Runnable&gt;workQueue,ThreadFactorythreadFactory,RejectedExecutionHandlerhandler)corePoolSize：线程池始终线程数，即使有些是空闲的。设置allowCoreThreadTimeOut参数为true，才会进行回收。maximumPoolSize：线程池最大线程数，表示在线程池中最多能创建多少个线程。如果当线程池中的数量到达这个数字时，新来的任务会抛出异常。keepAliveTime：表示线程没有任务执行时最多能保持多少时间会回收，然后线程池的数目维持在corePoolSize。unit：参数keepAliveTime的时间单位workQueue：一个阻塞队列，所有的任务都会先放在这里，务；如果对当前对线程的需求超过了corePoolSize大小，会用来存储等待执行的任。threadFactory：线程工厂，主要用来创建线程，比如指定线程的名字。handler：如果线程池已满，新的任务处理方式。注意一点：初始化线程池时，线程数为01.什么时候创建新的线程？线程初始化时线程数为0当前线程数小于corePoolSize时，提交任务会直接创建新的线程当前线程数大于等于为corePoolSize时，提交任务会放到阻塞队列中，当阻塞队列满时会创建线程2.如何关闭线程池？shutdown（高安全低响应）本质上执行的是interrupt方法阻止新来的任务提交，会将线程池的状态改成SHUTDOWN，当再将执行execute提交任务时，如果测试到状态不为RUNNING，则执行拒绝策略，从而达到阻止新任务提交的目的。对已经提交了的任务不会产生任何影响，当已经提交的任务执行完后，它会将那些闲置的线程进行中断，这个过程是异步的，也就是说只会打断空闲线程，如果当前还有任务队列还有任务未执行，线程将继续把任务执行完。shutdownNow（低安全高响应）阻止新来的任务提交，将线程池的状态改成STOP，当再将执行execute提交任务时，如果测试到状态不为RUNNING，则抛出rejectedExecution，从而达到阻止新任务提交的目的.会中断空闲进程，同时也会中断当前正在运行的线程，即workers中的线程。另外它还将workQueue中的任务给移除，并将这些任务添加到列表中进行返回。如遇已经激活的任务，并且处于阻塞状态时，shutdownNow()会执行1次中断阻塞的操作，此时对应的线程报InterruptedException，如果后续还要等待某个资源，则按正常逻辑等待某个资源的到达。例如，一个线程正在sleep状态中，此时执行shutdownNow()，它向该线程发起interrupt()请求，而sleep()方法遇到有interrupt()请求时，会抛出InterruptedException()，并继续往下执行。在这里要提醒注意的是，在激活的任务中，如果有多个sleep(),该方法只会中断第一个sleep()，而后面的仍然按照正常的执行逻辑进行。高安全低响应体现在shutdown等待任务执行完成再关闭，可以保证任务一定被执行，但是关闭线程池需要等待较长的时间低安全高响应体现在shutdownNow会关闭正在执行任务的线程，任务可能并没有执行完毕，也不会回退到任务队列中，将会消失，但是关闭线程池不需要等待较长的时间如果一个任务执行时间很长，导致线程池长时间关闭不了，可以在创建线程的时候将其设置为守护线程，此时被守护的线程是主线程，只要主线程执行完成，线程池就会强制关闭，可以配合awaitTermination使用：ThreadPoolExecutorthreadPoolExecutor=newThreadPoolExecutor(1,2,30,TimeUnit.SECONDS,newArrayBlockingQueue&lt;&gt;(5),r-&gt;{Threadt=newThread(r);t.setDaemon(true);returnt;},newThreadPoolExecutor.AbortPolicy());publicstaticvoidmain(String[]args)throwsInterruptedException{ThreadPoolExecutorthreadPoolExecutor=bulidThreadPoolExecutor();threadPoolExecutor.shutdown();threadPoolExecutor.awaitTermination(5,TimeUnit.SECONDS);System.out.println(&quot;强制关闭&quot;);}二、拒绝策略线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。JDK内置的拒绝策略如下：AbortPolicy：直接抛出异常，阻止系统正常运行。CallerRunsPolicy：导致该方法直接在调用者的主线程中执行，而不是在线程池中执行。从而导致主线程在该任务执行结束之前不能提交任何任务。从而有效的阻止了任务的提交。DiscardOldestPolicy：丢弃最老的一个请求，也就是即将被执行的一个任务，会直接出队，并尝试再次提交当前任务。DiscardPolicy：默认情况下它将丢弃被拒绝的任务以上内置拒绝策略均实现了RejectedExecutionHandler接口，若以上策略仍无法满足实际需要，完全可以自己扩展RejectedExecutionHandler接口。三、线程池的状态RUNNING：能够接收新任务，以及对已添加的任务进行处理。SHUTDOWN：不接收新任务，但能处理已添加的任务。STOP：程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。TIDYING：当所有的任务已终止TERMINATED：线程池彻底终止，就变成TERMINATED状态。四、线程池分类Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService摘自阿里巴巴开发手册:【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors返回的线程池对象的弊端如下：1）FixedThreadPool和SingleThreadPool:允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。2）CachedThreadPool和ScheduledThreadPool:允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。newCachedThreadPool线程池的参数：coreSize线程数0，最大线程数无限制，线程的允许空闲时间是60s，阻塞队列是SynchronousQueue这个线程池适用情况是短任务情况。采用SynchronousQueue，每当提交一个任务，都会超过阻塞队列的长度，导致创建线程，所以说：每当提交一个任务，都会创建一个线程，可能造成OOM。当线程空闲1分钟就会，销毁，所以该线程池会频繁的创建和销毁线程，最终会线程池会自己销毁newFixedThreadPoolcoreSize和最大线程数都是用户输入的，阻塞队列用的LinkedBlockingQueue，线程的允许空闲时间是0s该线程池的线程数是用户自定义的，不会增加，不会减少，线程池不会自己销毁，但是并不是刚开始就会直接创建coreSize的线程阻塞队列是无限大的，不会执行拒绝策略。可能会堆集无限的请求，导致OOMnewSingleThreadExecutor相当于线程数为1的newFixedThreadPool，缺点和newFixedThreadPool一样和一个线程的区别？newSingleThreadExecutorThread任务执行完成后，不会自动销毁，可以复用任务执行完成后，会自动销毁可以将任务存储在阻塞队列中，逐个执行无法存储任务，只能执行一个任务newScheduledThreadPool可以创建定时的任务，以固定周期执行或者固定的延迟时间执行如果任务时间超过了定时时长，就无法按照预定的时间执行而Linuxcrontab定时处理器为了确保时间的正确性，会重新启一个线程newWorkStealingPool采用的ForkJoin框架，可以将任务进行分割，同时线程之间会互相帮助阻塞队列采用的LinkedBlockingDeque，可以进行任务窃取五、使用线程池的好处线程重用：线程的创建和销毁的开销是巨大的，而通过线程池的重用大大减少了这些不必要的开销，当然既然少了这么多消费内存的开销，其线程执行速度也是突飞猛进的提升。控制线程池的并发数：线程不是并发的越多，性能越高，反而在线程并发太多时，线程的切换会消耗系统大量的资源，可以通过的设置线程池最大并发线程数目，维持系统高性能线程池可以对线程进行管理：虽然线程提供了线程组操控线程，但是线程池拥有更多管理线程的API可以储存需要执行的任务：当任务提交过多时，可以将任务储存起来，等待线程处理","link":"https://xzzz2020.github.io/post/oJRLv7myX/"},{"title":"【总结】虚拟内存","content":"本文档为面试精华版，如果是初学者，建议从专栏学习：操作系统专栏1.什么是虚拟内存(VirtualMemory)?2.局部性原理3.虚拟存储器4.虚拟内存的技术实现5.请求分页与分页存储管理的不同？6.常见的页面置换算法有哪些？1.什么是虚拟内存(VirtualMemory)?这个在我们平时使用电脑特别是Windows系统的时候太常见了。很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。为什么可以这样呢?正是因为虚拟内存的存在，通过虚拟内存可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉(每个进程拥有一片连续完整的内存空间)。这样会更加有效地管理内存并减少出错。总结而言就是：可以将内存扩展到外部磁盘存储器上，使得程序可以拥有超过物理内存的的空间大小让程序有一种错觉，认为自己获得了连续的可⽤的内存，而实际上这些内存分散在物理内存上甚至存放在外部磁盘上2.局部性原理局部性原理是虚拟内存技术的基础，正是因为程序运⾏具有局部性原理，才可以只装⼊部分程序到内存就开始运行。局部性原理表现在以下两个方面：时间局部性：如果程序中的某条指令⼀旦执⾏，不久以后该指令可能再次执⾏；如果某数据被访问过，不久以后该数据可能再次被访问。产⽣时间局部性的典型原因，是由于在程序中存在着⼤量的循环操作。空间局部性：⼀旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在⼀段时间内所访问的地址，可能集中在⼀定的范围之内，这是因为指令通常是顺序存放、顺序执⾏的，数据也⼀般是以向量、数组、表等形式簇聚存储的。时间局部性是通过将近来使⽤的指令和数据保存到⾼速缓存存储器中，并使⽤⾼速缓存的层次结构实现。空间局部性通常是使⽤较⼤的⾼速缓存，并将预取机制集成到⾼速缓存控制逻辑中实现。虚拟内存技术实际上就是建⽴了“内存⼀外存”的两级存储器的结构，3.虚拟存储器基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器一虚拟存储器。实际上，我觉得虚拟内存同样是一种时间换空间的策略，你用CPU的计算时间，页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。4.虚拟内存的技术实现虚拟内存的实现需要建立在离散分配的内存管理方式的基础上，虚拟内存的实现有以下三种方式:请求分页存储管理:建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。请求分段存储管理:建立在分段存储管理之.上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行;在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段;当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。请求段页式存储管理5.请求分页与分页存储管理的不同？根本区别在于，是否要求将程序所需全部的地址空间都装入内存，分页存储是这样要求的，所以无法提供虚拟内存6.常见的页面置换算法有哪些？在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。最佳置换算法（OPT）：理论上最好的算法，每次置换选择的将是最久不会被访问的页面最近最久未使用（LRU）:记录的是页面上次的访问时间，实现方式有栈或者寄存器两种，对于栈每次置换栈顶元素，每次访问都会将页面置于栈底；寄存器保存的是访问时间，每次置换掉访问时间离现在最晚的的最少使用（LFU）：该置换算法选择在之前时期使⽤最少的⻚⾯作为淘汰页，记录的是一段时间内的使用频率。先进先出（FIFO）：每次置换的将是最先进来的页面第二次机会算法：由于先进先出可能会将经常使用的页面置换出去，所以增加了一个访问位，当页面被访问时，将该位置成1，当发生缺页中断时，会将该位置成0，会给该页面一次机会。最近未使用（NRU）：每个页面都有两个状态位：R与M，当页面被访问时设置页面的R=1，当页面被修改时设置M=1。其中R位会定时被清零。当发生缺页中断时，最先置换00，最后置换11的页面，至于中间的两个分类，NRU优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）","link":"https://xzzz2020.github.io/post/IAw823Nme/"},{"title":"【总结】操作系统内存管理","content":"本文档为面试精华版，如果是初学者，建议从专栏学习：操作系统专栏1.操作系统的内存管理主要是做什么？2.操作系统的内存管理机制了解吗？内存管理有哪几种方式?3.快表和多级页表快表多级页表总结4.分页机制和分段机制有哪些共同点和区别呢?5.解释一下逻辑(虚拟)地址和物理地址6.CPU寻址了解吗?为什么需要虚拟地址空间?1.操作系统的内存管理主要是做什么？操作系统的内存管理主要负责内存的分配与回收（malloc函数：申请内存，free函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。2.操作系统的内存管理机制了解吗？内存管理有哪几种方式?**简单分为连续分配管理⽅式和⾮连续分配管理⽅式这两种。**连续分配管理⽅式是指为⼀个⽤户程序分配⼀个连续的内存空间，常⻅的如块式管理。同样地，⾮连续分配管理⽅式允许⼀个程序使⽤的内存分布在离散或者说不相邻的内存中，常⻅的如⻚式管理和段式管理：块式管理：远古时代的计算机操系统的内存管理⽅式。将内存分为⼏个固定⼤⼩的块，每个块中只包含⼀个进程。如果程序运⾏需要内存的话，操作系统就分配给它⼀块，如果程序运⾏只需要很⼩的空间话，分配的这块内存很⼤⼀部分⼏乎被浪费了。这些在每个块中未被利⽤的空间，我们称之为碎⽚。页式管理：把主存分为⼤⼩相等且固定的⼀⻚⼀⻚的形式，⻚较⼩，相对相⽐于块式管理的划分⼒度更⼤，提⾼了内存利⽤率，减少了碎⽚。⻚式管理通过⻚表对应逻辑地址和物理地址。段式管理：⻚式管理虽然提⾼了内存利⽤率，但是⻚式管理其中的⻚实际并⽆任何实际意义。段式管理把主存分为⼀段段的，每⼀段的空间⼜要⽐⼀⻚的空间⼩很多。但是，最重要的是段是有实际意义的，每个段定义了⼀组逻辑信息，例如,有主程序段MAIN、⼦程序段X、数据段D及栈段S等。段式管理通过段表对应逻辑地址和物理地址。最后还有一个很重要的段页式管理：段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若⼲段，每个段⼜分成若⼲⻚，也就是说段⻚式管理机制中段与段之间以及段的内部的都是离散的。3.快表和多级页表快表**为了解决虚拟地址到物理地址的转换速度，操作系统在页表方案基础之上引入了快表来加速虚拟地址到物理地址的转换。**我们可以把快表理解为一种特殊的高速缓冲存储器(Cache)，其中的内容是页表的一部分或者全部内容。作为页表的Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时CPU要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存,这样可加速查找并提高指令执行速度。使用快表之后的地址转换流程是这样的:根据虚拟地址中的页号查快表;如果该页在快表中，直接从快表中读取相应的物理地址;如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中;当快表填满后，又要登记新页时，就按照一-定的淘汰策略淘汰掉快表中的一个页。看完了之后你会发现快表和我们平时经常在我们开发的系统使用的缓存(比如Redis)很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。多级页表引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中，多级页表属于时间换空间的典型场景。总结为了提高内存的空间性能，提出了多级页表的概念;但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表(即TLB)的概念。不论是快表还是多级页表实际上都利用到了程序的局部性原理。4.分页机制和分段机制有哪些共同点和区别呢?共同点:分页机制和分段机制都是为了提高内存利用率，较少内存碎片。页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。区别:页的大小是固定的，由操作系统决定;而段的大小不固定，取决于我们当前运行的程序。分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。分页是一维地址空间，分段是二维的。5.解释一下逻辑(虚拟)地址和物理地址我们编程一般只有可能和逻辑地址打交道，比如在C语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。6.CPU寻址了解吗?为什么需要虚拟地址空间?现代处理器使用的是--种称为虚拟寻址(VirtualAddressing)的寻址方式。使用虚拟寻址，CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。实际上完成虚拟地址转换为物理地址转换的硬件是CPU中含有一个被称为内存管理单元(MemoryManagementUnit,MMU)的硬件。为什么要有虚拟地址空间呢？没有虚拟地址空间的时候，程序都是直接访问和操作的都是物理内存。如果直接把物理地址暴露出来的话会带来严重问题，⽐如可能对操作系统造成伤害以及给同时运⾏多个程序造成困难。通过虚拟地址访问内存有以下优势：程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页(通常大小为4KB)保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。","link":"https://xzzz2020.github.io/post/NnnE8vgmP/"},{"title":"美化JS生成随机颜色","content":"该代码应用到博客主题，展示地址：https://xzzz2020.gitee.io/tags/，如果有更好的优化思路，可以跟博主探讨探讨。生成随机颜色代码比较多，但是想要美化这个随机算法有点难。博主对此进行了一些相关测试，该测试结果因个人的审美会有较大的差距。基本优化思路是：如果固定一个颜色，再优化会更加简单，主要固定了一个是红色一个是蓝色（以绿为底，觉得很丑）剩下两个颜色不能过深或者过浅，所以进行了限定最后就是以红为底和以蓝为底的比例，就采用了经典黄金分割比&lt;script&gt;functiongetColor1(){//固定红色值varre=&quot;#&quot;;varcol=color();re+=col+&quot;FF&quot;;returnre}functiongetColor2(){//固定蓝色值varre=&quot;#FF&quot;;varcol=color();re+=col;returnre}functioncolor(){varre=&quot;&quot;;for(varxunhuan=0;xunhuan&lt;2;xunhuan++){vartemp=Math.floor(256*Math.random());if(temp&lt;130&amp;&amp;xunhuan==0){temp=130;}if(temp&gt;200&amp;&amp;xunhuan==1){temp=200;}temp=temp.toString(16);//将数值转换成16进制if(temp.length!==2){temp=&quot;0&quot;+temp}re+=temp//对颜色进行拼接}returnre;}varglobal_tags_random=5//这个是博主标签的按钮数目，这样让每个标签都有不同的颜色for(xunhuan=0;xunhuan&lt;=global_tags_random;xunhuan++){vartemp=document.getElementById(&quot;tag-&quot;+xunhuan.toString());varrandom=Math.random();if(random&lt;0.618){//分配红色和蓝色出现的比例temp.style.backgroundColor=getColor1()}else{temp.style.backgroundColor=getColor2()}}&lt;/script&gt;","link":"https://xzzz2020.github.io/post/ExM6FNFMM/"},{"title":"【总结】进程、线程和死锁","content":"本文档为面试精华版，如果是初学者，建议从专栏学习：操作系统专栏1.聊聊进程和线程2.进程有几种状态？3.进程间的通信方式4.线程间的同步的⽅式有哪些呢?5.你知道操作系统中进程的调度算法有哪些吗?6.发生死锁的必要条件7.解决死锁的方式1.聊聊进程和线程进程进程是进程实体的运行过程，是系统进行资源分配和调度的一一个独立单位。进程实体由程序段、相关数据段和PCB组成线程线程的提出源于在并发的时候，进程的切换需要消耗很大的时空开销，而线程的提出可以提高并发时系统的性能进程和线程的区别？拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程CPU环境的保存及新调度进程CPU环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小通信方面：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助IPC。2.进程有几种状态？有五种状态：创建：进程正在被分配资源结束：当进程正常或者异常退出。就绪：进程已处于准备运⾏状态，即进程获得了除了处理器之外的⼀切所需资源，⼀旦得到处理器资源(处理器分配的时间⽚)即可运⾏执行：进程正在处理器上上运⾏阻塞：进程正在等待某⼀事件⽽暂停运⾏如等待某资源为可⽤或等待IO操作完成。即使处理器空闲，该进程也不能运⾏应该注意以下内容：只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得CPU时间，转为运行状态；而运行状态的进程，在分配给它的CPU时间片用完之后就会转为就绪状态，等待下一次调度。阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括CPU时间，缺少CPU时间会从运行态转换为就绪态。3.进程间的通信方式大概有7种常见的进程间的通信⽅式：管道/匿名管道(Pipes)：⽤于具有亲缘关系的⽗⼦进程间或者兄弟进程之间的通信。有名管道(NamesPipes):克服了管道只能⽤于亲缘关系的进程间通信这个缺点，严格遵循先进先出(firstinfirstout)。有名管道以磁盘⽂件的⽅式存在，可以实现本机任意两个进程通信。信号(Signal)：信号是⼀种⽐较复杂的通信⽅式，⽤于通知接收进程某个事件已经发⽣；消息队列(MessageQueuing)：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（⽆名管道：只存在于内存中的⽂件；命名管道：存在于实际的磁盘介质或者⽂件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除⼀个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不⼀定要以先进先出的次序读取,也可以按消息的类型读取.⽐FIFO更有优势。消息队列克服了信号承载信息量少，管道只能承载⽆格式字节流以及缓冲区大小受限等缺。信号量(Semaphores)：信号量是⼀个计数器，⽤于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信⽅式主要⽤于解决与同步相关的问题并避免竞争条件。共享内存(Sharedmemory)：使得多个进程可以访问同⼀块内存空间，不同进程可以及时看到对⽅进程中对共享内存中数据的更新。这种⽅式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有⽤的进程间通信⽅式。套接字(Sockets):此⽅法主要⽤于在客户端和服务器之间通过⽹络进⾏通信。套接字是⽀持TCP/IP的⽹络通信的基本操作单元，可以看做是不同主机之间的进程进⾏双向通信的端点，简单的说就是通信的两⽅的⼀种约定，⽤套接字中的相关函数来完成通信过程。4.线程间的同步的⽅式有哪些呢?线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统-般有下面三种线程同步的方式:互斥量(Mutex):采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为.互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如Java中的synchronized关键词和各种Lock都是这种机制。信号量(Semphares):它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量事件(Event):通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作5.你知道操作系统中进程的调度算法有哪些吗?不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。a.批处理系统批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。先来先服务first-comefirst-serverd（FCFS）非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。短作业优先shortestjobfirst（SJF）非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。最短剩余时间优先shortestremainingtimenext（SRTN）最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。b.交互式系统交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。时间片轮转将所有就绪进程按FCFS的原则排成一个队列，每次调度时，把CPU时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把CPU时间分配给队首的进程。时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。而如果时间片过长，那么实时性就不能得到保证优先级调度为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。多级反馈队列一个进程需要执行100个时间片，如果采用时间片轮转调度算法，那么需要交换100次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换7次。每个队列优先权也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。6.发生死锁的必要条件互斥：每个资源要么已经分配给了一个进程，要么就是可用的。占有和等待：已经得到了某个资源的进程可以再请求新的资源。不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。7.解决死锁的方式主要有以下四种方法：鸵鸟策略：因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。死锁检测与死锁恢复：检测主要是查看当前是否出现了环路等待；恢复可以通过杀死进程或者利用回滚死锁预防：在程序运行之前破坏发生死锁的条件，预防发生死锁，比如说破坏环路等待可以给资源统一编号，进程只能按编号顺序来请求资源。死锁避免：使用银行家算法，假设给进程分配资源，看能不能找到一个安全序列，如果系统处于不安全状态，不一定会发生死锁；但是死锁时，系统一定处于不安全状态","link":"https://xzzz2020.github.io/post/jURZ4BrJ2/"},{"title":"【总结】操作系统基础","content":"本文档为面试精华版，如果是初学者，建议从专栏学习：操作系统专栏1.什么是操作系统？2.什么是用户态和系统态？什么是系统调用呢？3.操作系统的基本特征4.中断分类1.什么是操作系统？我通过以下四点向您介绍⼀下什么是操作系统吧：操作系统（OperatingSystem，简称OS）是管理计算机硬件与软件资源的程序，是计算机系统的内核与基⽯；操作系统本质上是运⾏在计算机上的软件程序；操作系统为⽤户提供⼀个与系统交互的操作界⾯；操作系统分内核与外壳（我们可以把外壳理解成围绕着内核的应⽤程序，⽽内核就是能操作硬件的程序）。关于内核多插⼀嘴：内核负责管理系统的进程、内存、设备驱动程序、⽂件和⽹络系统等等，决定着系统的性能和稳定性。是连接应⽤程序和硬件的桥梁。内核就是操作系统背后⿊盒的核⼼。2.什么是用户态和系统态？什么是系统调用呢？根据进程访问资源的特点，我们可以把进程在系统上的运⾏分为两个级别：⽤户态(usermode):⽤户态运⾏的进程或可以直接读取⽤户程序的数据，能执行部分指令。系统态(kernelmode):可以简单的理解系统态运⾏的进程或程序⼏乎可以访问计算机的任何资源，能执行全部的指令，不受限制。我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢?那就需要系统调用了!也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作(如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。这些系统调⽤按功能⼤致可分为如下⼏类：设备管理。完成设备的请求或释放，以及设备启动等功能。⽂件管理。完成⽂件的读、写、创建及删除等功能。进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。进程通信。完成进程之间的消息传递或信号传递等功能。内存管理。完成内存的分配、回收以及获取作业占⽤内存区⼤⼩及地址等功能。3.操作系统的基本特征并发：宏观上是一段时间内多个程序一起运行，而并行是同一时刻多个程序一起运行操作系统通过引入进程和线程，使得程序能够并发运行共享：系统中的资源可以被多个并发进程共同使用。虚拟：虚拟技术把一个物理实体转换为多个逻辑实体，主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换异步：异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。4.中断分类外中断：由CPU执行指令以外的事件引起，如I/O完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。异常：由CPU执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。陷入：在用户程序中使用系统调用","link":"https://xzzz2020.github.io/post/aArRF4IZF/"},{"title":"Java集合面试题总结","content":"该文章为面试精华版，如果是初学者，建议先从专栏学习：Java集合专栏[TOC]一、主要容器概述注意Collection是一个接口，是List和Set的公共接口，Collections是一个工具类Java容器主要有三个：List:是一个有序集合，可以放重复的数据Set:是一个无序集合，不允许放重复的数据Map:是一个无序集合，集合中包含一个键对象，-一个值对象，键对象不允许重复，值对象可以重复(身份证号-姓名)size()，length，length()区别？size()是集合中使用，统计集合中元素的个数length是数组的一个成员属性length()是String的一个方法Iterator方法描述booleanhasNext()判断集合中是否还有下一个元素Objectnext()返回下一个元素voidremove()从集合中删除一个由next()方法返回的元素二、ListArrayList：查询数据比较快，添加和删除数据比较慢(基于可变数组)LinkedList：查询数据比较慢，添加和删除数据比较快（基于链表数据结构）1.ArrayList查找比较快，增删比较慢底层是基于数组。默认容量是10每次扩容1.5倍如果增加0.5倍后的新容量超过限制的容量，则用所需的最小容量与限制的容量进行判断，超过则指定为Integer的最大值通过数组的复制将原数据复制到一个更大(新的容量大小)的数组如何保证线程安全？继承ArrayList，重写其中的方法Listlist=Collections.synchronizedList(newArrayList());2.LinkedList增删比较快，查找比较慢基于链表的，除了存放数据，还需要存放指针，所以占用的空间会大一些它实现了Deque接口，使得LinkedList类也具有队列的特性不是线程安全的3.VectorVector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问ArrayList慢。4.ArrayList与LinkedList异同是否保证线程安全：ArrayList和LinkedList都是不同步的，也就是不保证线程安全；底层数据结构：Arraylist底层使用的是Object数组；LinkedList底层使用的是双向链表数据结构JDK1.6之前为循环链表，JDK1.7取消了循环。注意双向链表和双向循环链表的区别：节约空间）；插入和删除是否受元素位置的影响：ArrayList采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。比如：执行add(Ee)方法的时候，ArrayList会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是O(1)。但是如果要在指定位置i插入和删除元素的话（add(intindex,Eelement)）时间复杂度就为O(n-i)。因为在进行上述操作的时候集合中第i和第i个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。LinkedList采用链表存储，所以插入，删除元素时间复杂度不受元素位置的影响，都是近似O（1）而数组为近似O（n）。是否支持快速随机访问：LinkedList不支持高效的随机元素访问，而ArrayList支持。5.ArrayList和Vector的区别Vector类的所有方法都是同步的。可以由两个线程安全地访问一个Vector对象、但是一个线程访问Vector的话代码要在同步操作上耗费大量的时间。Arraylist不是同步的，所以在不需要保证线程安全时时建议使用ArrayList。【CopyOnWriteArrayList是同步的】。扩容倍数不一样：Vector每次扩容请求其大小的2倍空间，而ArrayList是1.5倍。6.System.arraycopy()和Arrays.copyOf()arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置copyOf()是系统自动在内部新建一个数组，并返回该数组。7.CopyOnWriteArrayList是一种读写分离的结构：写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。写操作需要加锁，防止并发写入时导致写入数据丢失。写操作结束之后需要把原始数组指向新的复制数组。publicbooleanadd(Ee){finalReentrantLocklock=this.lock;lock.lock();try{Object[]elements=getArray();intlen=elements.length;Object[]newElements=Arrays.copyOf(elements,len+1);newElements[len]=e;setArray(newElements);returntrue;}finally{lock.unlock();}}finalvoidsetArray(Object[]a){array=a;}@SuppressWarnings(&quot;unchecked&quot;)privateEget(Object[]a,intindex){return(E)a[index];}CopyOnWriteArrayList在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。但是CopyOnWriteArrayList有其缺陷:内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右；数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。所以CopyOnWriteArrayList不适合内存敏感以及对实时性要求很高的场景。三、Set在Set家族中，常用的有三种：HashSet:采用Hashmap的key来储存元素，主要特点是无序的，基本操作都是O(1)的时间复杂度，很快。LinkedHashSet:这个是一个HashSet+LinkedList的结构，特点就是既拥有了O(1)的时间复杂度，又能够保留插入的顺序。TreeSet:采用红黑树结构，特点是可以有序，可以用自然排序或者自定义比较器来排序；缺点就是查询速度没有HashSet快。1.哈希表哈希表是一种数据结构，哈希表能够提供快速存取操作。哈希表是基于数组的，所以也存在缺点，数组一旦创建将不能扩展。正常的数组，如果需要查询某个值，需要对数组进行遍历，只是一种线性查找，查找的速度比较慢。如果数组中的元素值和下标能够存在明确的对应关系，那么通过数组元素的值就可以换算出数据元素的下**标，通过下标就可以快数定位数组元素，这样的数组就是哈希表。**一张哈希表：元素值101112131415161718元素下标012345678以上我们的示例元素值和下标的关系为：元素下标=元素值-10，此时的示例hashcode就是和数组下标一致了,取得hashcode方法如下：//取得hashCodepubicinthashCode(intvalue){returnvalue–10;}2.HashSetHashSet中的数据是无序的不可重复的。采用Hashmap的key来储存元素3.hashCode()覆盖了equals和hashCode，当hashCode相同，它会调用equals进行比较，如果equals比较相等将不加把此元素加入到Set中但equals比较不相等会重新根据hashCode换算位置仍然会将该元素加入进去的。hashCode()与equals()的相关规定：如果两个对象相等，则hashcode一定也是相同的两个对象相等,对两个对象分别调用equals方法都返回true两个对象有相同的hashcode值，它们也不一定是相等的因此，equals方法被覆盖过，则hashCode方法也必须被覆盖hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）再次强调：特别是向HashSet或HashMap中加入数据时必须同时覆盖equals和hashCode方法，应该养成一种习惯覆盖equals的同时最好同时覆盖hashCodeJava要求：两个对象equals相等，那么它的hashcode相等两个对象equals不相等，那么它的hashcode并不要求它不相等，但一般建议不相等hashcode相等不代表两个对象相等（采用equals比较）为什么重写equals()就必须要重写hashCode()？当key的hashCode()计算的数值相同时，就会出现hash冲突处理hash冲突有哪些方法？Java中用的哪一种？为什么？另一种方法你在工作中用过吗？在什么情况下用得多？见：https://xzzz2020.gitee.io/post/d0otbdSTy4.TreeSetTreeSet可以对Set集合进行排序，默认自然排序（即升序）引用类型实现排序，需要实现Comparator或者ComparableComparable和Comparator的区别？Comparable是自然排序，需要实体类实现，需要修改源代码Comparator是定制排序，不需要更改源代码，定义一个比较规则，传递给需要调用的方法中，将比较策略与数据分离，体现了策略模式Comparator比Comparable优先级更高四、Map关于HashMap的全部面试题见：https://xzzz2020.gitee.io/post/hashmapMap中可以放置键值对，也就是每一个元素都包含键对象和值对象，Map实现较常用的为HashMap，HashMap对键对象的存取和HashSet一样，仍然采用的是哈希算法，所以如果使用自定类作为Map的键对象，必须复写equals和hashCode方法Map中常用的三个：HashMap:与HashSet对应，也是无序的，O(1)。LinkedHashMap:这是一个「HashMap+双向链表」的结构，落脚点是HashMap，所以既拥有HashMap的所有特性还能有顺序。TreeMap:是有序的，本质是用二叉搜索树来实现的。1.HashMap实现原理对于HashMap中的每个key，根据一个Hash函数，计算出一个Hash值，对应就是桶的编号，桶实际上是用数组实现的Hash函数跟HashMap的容量有关系如果不同的元素的key算出了相同的哈希值，那么该怎么存放呢？这就是哈希碰撞，即多个key对应了同一个桶。HashMap中是如何保证元素的唯一性的呢？即相同的元素会不会算出不同的哈希值呢？通过hashCode()和equals()方法来保证元素的唯一性。2.HashTable是一个线程安全的，但是锁住了全部数据效率低下HashMap和Hashtable的区别?线程是否安全：HashMap是非线程安全的，HashTable是线程安全的；HashTable内部的方法基本都经过synchronized修饰。（如果你要保证线程安全的话就使用ConcurrentHashMap吧！）；效率：因为线程安全的问题，HashMap要比HashTable效率高一点。另外，HashTable基本被淘汰，不要在代码中使用它；对Nullkey和Nullvalue的支持：HashMap中，null可以作为键，这样的键只有一个，可以有一个或多个键所对应的值为null。但是在HashTable中put进的键值只要有一个null，直接抛出NullPointerException。HashMap的迭代器是fail-fast迭代器，HashTable是用的Enumeration（枚举）的迭代器初始容量大小和每次扩充容量大小的不同：①创建时如果不指定容量初始值，Hashtable默认的初始大小为11，之后每次扩充，容量变为原来的2n+1。HashMap默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么Hashtable会直接使用你给定的大小，而HashMap会将其扩充为2的幂次方大小（HashMap中的tableSizeFor()方法保证，下面给出了源代码）。也就是说HashMap总是使用2的幂作为哈希表的大小,后面会介绍到为什么是2的幂次方。底层数据结构：JDK1.8以后的HashMap在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。Hashtable没有这样的机制。3.LinkedHashMap保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。内部维护了一个双向链表，用来维护插入顺序或者LRU顺序如何实现LRU缓存？构造方法提供了一个参数accessOrder，默认是false，表示按照插入顺序：publicLinkedHashMap(intinitialCapacity,floatloadFactor,booleanaccessOrder){super(initialCapacity,loadFactor);this.accessOrder=accessOrder;}而当accessOrder为true时，表示按照访问顺序，在节点多于MAX_ENTRIES就会将最近最久未使用的数据移除，MAX_ENTRIES默认为3需要继承LinkedHashMap，并且覆盖removeEldestEntry()方法实现：classLRUCache&lt;k,v&gt;extendsLinkedHashMap&lt;k,v&gt;{privatefinalstaticintMAX_CACHE_SIZE=100;privatefinalintlimitCacheSize;publicLRUCache(){this(MAX_CACHE_SIZE);}publicLRUCache(intcacheSize){super(cacheSize,0.75f,true);this.limitCacheSize=cacheSize;}/***判断什么时候删除缓存*/@OverrideprotectedbooleanremoveEldestEntry(Map.Entry&lt;k,v&gt;eldest){returnthis.size()&gt;this.limitCacheSize;}}五、Collections常用方法排序voidreverse(Listlist)//反转voidshuffle(Listlist)//随机排序voidsort(Listlist)//按自然排序的升序排序voidsort(Listlist,Comparatorc)//定制排序，由Comparator控制排序逻辑voidswap(Listlist,inti,intj)//交换两个索引位置的元素voidrotate(Listlist,intdistance)//旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将list的前distance个元素整体移到后面。查找,替换操作intbinarySearch(Listlist,Objectkey)//对List进行二分查找，返回索引，注意List必须是有序的intmax(Collectioncoll)//根据元素的自然顺序，返回最大的元素。intmin(Collectioncoll)intmax(Collectioncoll,Comparatorc)//根据定制排序，返回最大元素，排序规则由Comparatator类控制。intmin(Collectioncoll,Comparatorc)voidfill(Listlist,Objectobj)//用指定的元素代替指定list中所有元素。intfrequency(Collectionc,Objecto)//统计元素出现次数intindexOfSubList(Listlist,Listtarget)//统计target在list中第一次出现的索引，找不到则返回-1，intlastIndexOfSubList(Listsource,listtarget).booleanreplaceAll(Listlist,ObjectoldVal,ObjectnewVal),用新元素替换旧元素同步控制Collections提供了多个synchronizedXxx()方法，该方法可以将指定集合包装成线程同步的集合，从而解决多线程并发访问集合时的线程安全问题。我们知道HashSet，TreeSet，ArrayList,LinkedList,HashMap,TreeMap都是线程不安全的。Collections提供了多个静态方法可以把他们包装成线程同步的集合synchronizedCollection(Collection&lt;T&gt;c)//返回指定collection支持的同步（线程安全的）collection。synchronizedList(List&lt;T&gt;list)//返回指定列表支持的同步（线程安全的）List。synchronizedMap(Map&lt;K,V&gt;m)//返回由指定映射支持的同步（线程安全的）Map。synchronizedSet(Set&lt;T&gt;s)//返回指定set支持的同步（线程安全的）set。设置不可变集合emptyXxx()：返回一个空的、不可变的集合对象，此处的集合既可以是List，也可以是Set，还可以是Map。singletonXxx()：返回一个只包含指定对象（只有一个或一个元素）的不可变的集合对象，此处的集合可以是：List，Set，Map。unmodifiableXxx()：返回指定集合对象的不可变视图，此处的集合可以是：List，Set，Map。上面三类方法的参数是原有的集合对象，返回值是该集合的”只读“版本六、Fail-Fast和Fail-SafeIterator的安全失败是基于对底层集合做拷贝，因此，它不受源集合上修改的影响。java.util包下面的所有的集合类都是快速失败的，而java.util.concurrent包下面的所有的类都是安全失败的。快速失败的迭代器会抛出ConcurrentModificationException异常，而安全失败的迭代器永远不会抛出这样的异常。快速失败原理modCount用来记录ArrayList结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。在进行序列化或者迭代或者remove()等操作时，需要比较操作前后modCount是否改变，如果改变了需要抛出ConcurrentModificationException。privatevoidwriteObject(java.io.ObjectOutputStreams)throwsjava.io.IOException{//Writeoutelementcount,andanyhiddenstuffintexpectedModCount=modCount;s.defaultWriteObject();//Writeoutsizeascapacityforbehaviouralcompatibilitywithclone()s.writeInt(size);//Writeoutallelementsintheproperorder.for(inti=0;i&lt;size;i++){s.writeObject(elementData[i]);}if(modCount!=expectedModCount){thrownewConcurrentModificationException();}}解决fail-fast的原理在返回一个迭代器的时候，拷贝数据，因此，对容器内容的修改不影响遍历。privateCOWIterator(Object[]elements,intinitialCursor){cursor=initialCursor;snapshot=elements;}常见的的使用fail-safe方式遍历的容器有ConcerrentHashMap和CopyOnWriteArrayList等。","link":"https://xzzz2020.github.io/post/D60cWKdQu/"},{"title":"解决Hash冲突的方法总结","content":"1.开放地址法当出现冲突时，di是产生冲突的时候的增量序列，则将冲突的元素进行移动：-di值可能为1,2,3,…m-1，称线性探测再散列。如果di取1，则每次冲突之后，向后移动1个位置.-di取值可能为1,-1,4,-4,9,-9,16,-16,…kk,-kk(k&lt;=m/2）称二次探测再散列。-di取值可能为伪随机数列。称伪随机探测再散列。2.多哈希法设计多种哈希函数，可以避免冲突，但是冲突几率还是有的，函数设计的越好或越多都可以将几率降到最低。3.拉链法（Java中采用的）利用一个额外的空间比如链表来保存冲突的元素，此法可以完全避免哈希函数的冲突。4.建立一个公共溢出区一旦发生冲突，都填入溢出表。","link":"https://xzzz2020.github.io/post/d0otbdSTy/"},{"title":"HashMap面试题总结","content":"HashMap简介问题集合问点一：你了解HashMap的底层数据结构吗？问点二：为什么JDK7使用数组+链表？JDK8中为什么要使用红黑树？哈希冲突是怎么回事？HashMap又是怎么解决的？问点三：HashMap的扩容机制是怎么样的？JDK7与JDK8有什么不同吗？问点四：HashMap中的键值可以为Null吗？能简单说一下原理吗？问点五：HashMap中能put两个相同的Key吗？为什么能或为什么不能？问点六：聊一聊JDK7的HashMap中的“死锁”是怎么回事？问点七：HashMap是线程安全的吗？为什么安全或者不安全？问点八：什么HashMap的加载因子是0.75？为什么是超过“8”才用红黑树？问点九：HashMap、HashTable、ConcurrentHashMap的区别问点十：谈谈你理解的HashMap，讲讲其中的get和put过程由于HashMap在面试中是一个重点，内容十分多，需要单独写一篇文章总结HashMap在Jdk1.7与1.8之中有很大区别！！HashMap简介HashMap是用来存储数据的，它底层在JDK1.7是数组+链表实现的，而JDK1.8是使用数组+链表+红黑树实现，通过对key进行哈希计算等操作后得到数组下标，把value等信息存放在链表或红黑树存在此位置。如果两个不同的key运算后获取的数组下标一致，就出现了哈希冲突。数组默认长度是16，如果实际数组长度超过一定的值，就会进行扩容。问题集合问点一：你了解HashMap的底层数据结构吗？在JDK1.7使用的是数组+链表的实现，在JDK1.8中使用的是数组+链表+红黑树问点二：为什么JDK7使用数组+链表？JDK8中为什么要使用红黑树？哈希冲突是怎么回事？HashMap又是怎么解决的？JDK7使用数组+链表，是因为HashMap是根据Key计算Hash值，从而得到哈希表的索引下标，而哈希表本质是数组实现。当出现Hash冲突时，则一个桶可能需要存放多个数据。HashMap将会根据equals()方法，判断Hash冲突的Key是否是同一个值，此时如果仍然不相同，就会利用头插法，将出现Hash冲突的Key+Value存放在链表上。但是如果一个链表比较长，那么查询的效率将会降低，所以JDK8中又使用了红黑树来解决链表过长导致查询效率变差的问题，会在一个桶上链表长度为8时，进行树化。但是树化的时候，会判断当前的长度是否小于64，如果小于，则不进行树化，而是选择进行一次扩容，因为扩容的时候会使哈希表长度增加，hash值会重新计算，将重新打乱当前的元素排列，分配到新的空间上，这样也避免了链表过长。对于HashMap中的每个key，根据一个Hash函数，计算出一个Hash值，对应就是桶的编号，桶实际上是用数组实现的。//key进行哈希计算inthash=hash(key);//获取数组下标inti=indexFor(hash,table.length);通过计算后的下标，从而得到数组的对应下标的位置，最后把k，v值存进去，同样的当再次第二次存值的时候，同样把k，v传进来，当k再次进行计算出数组下标index，有可能和第一次计算的index的值相同。但是，两次的需要存进去的value值是不同的，这就出现了同一个数组后面有一条链表，会比较链表上的每一个value值与当前的value是否相同，若是不相同，通过头插法，将数值插入链表中。如下图所示：接下来通通过源码进行分析，在jdk7插入的put方法源码如下：publicVput(Kkey,Vvalue){//数组为空就进行初始化if(table==EMPTY_TABLE){inflateTable(threshold);}if(key==null)returnputForNullKey(value);//key进行哈希计算inthash=hash(key);//获取数组下标inti=indexFor(hash,table.length);//如果此下标有值，遍历链表上的元素，key一致的话就替换value的值for(Entry&lt;K,V&gt;e=table[i];e!=null;e=e.next){Objectk;if(e.hash==hash&amp;&amp;((k=e.key)==key||key.equals(k))){VoldValue=e.value;e.value=value;e.recordAccess(this);returnoldValue;}}modCount++;//新增一个keyaddEntry(hash,key,value,i);returnnull;}put方法中主要做了以下几件事：判断table数组是否为空，若为空进行初始化table数组。判断key值是否为null，将null是作为key存进去。若key不为空，通过key计算出数组下标，判断table[i]是否为空。若是不为空通过链表循环，判断在链表中是否存在与该key相等，若是存在，直接将value替换成新的value。若是table[i]为空或者链表中不存在与之相同的key，就addEntry(hash,key,value,i)新增一个节点。接下来看看addEntry(hash,key,value,i)新增节点的源码如下：voidaddEntry(inthash,Kkey,Vvalue,intbucketIndex){//数组长度大于阈值且存在哈希冲突（即当前数组下标有元素），就将数组扩容至2倍if((size&gt;=threshold)&amp;&amp;(null!=table[bucketIndex])){resize(2*table.length);hash=(null!=key)?hash(key):0;bucketIndex=indexFor(hash,table.length);}createEntry(hash,key,value,bucketIndex);}这个方法很简单，直接就是判断当前数组的大小是否&gt;=threshold并且table[bucketIndex]是否为null。若成立扩容，然后rehash，重新得到新数组的下标值，最后createEntry(hash,key,value,bucketIndex)创建新节点。最后来看一下createEntry(hash,key,value,bucketIndex)创建新节点的源码如下：voidcreateEntry(inthash,Kkey,Vvalue,intbucketIndex){//此位置有元素，就在链表头部插入新元素（头插法）Entry&lt;K,V&gt;e=table[bucketIndex];table[bucketIndex]=newEntry&lt;&gt;(hash,key,value,e);size++;}在JDK7中，链表存储有一个缺点，就是当数据很多的时候，链表就会很长，每次查询都会遍历很长的链表。因此在JDK8中为了优化HashMap的查询效率，将内部的结构改为数组+链表+和红黑树，当一个哈希桶后面的链表长度&gt;8的时候，就会将链表转化为红黑树，红黑树是二分查找，提高了查询的效率。接下来通过JDK8的put源码分析如下：publicVput(Kkey,Vvalue){returnputVal(hash(key),key,value,false,true);}finalVputVal(inthash,Kkey,Vvalue,booleanonlyIfAbsent,booleanevict){Node&lt;K,V&gt;[]tab;Node&lt;K,V&gt;p;intn,i;//数组为空就初始化if((tab=table)==null||(n=tab.length)==0)n=(tab=resize()).length;//当前下标为空，就直接插入if((p=tab[i=(n-1)&amp;hash])==null)tab[i]=newNode(hash,key,value,null);else{Node&lt;K,V&gt;e;Kk;//key相同就覆盖原来的值if(p.hash==hash&amp;&amp;((k=p.key)==key||(key!=null&amp;&amp;key.equals(k))))e=p;//树节点插入数据elseif(pinstanceofTreeNode)e=((TreeNode&lt;K,V&gt;)p).putTreeVal(this,tab,hash,key,value);else{for(intbinCount=0;;++binCount){//链表，尾插法插入数据if((e=p.next)==null){p.next=newNode(hash,key,value,null);//链表长度超过8，就把链表转为红黑树if(binCount&gt;=TREEIFY_THRESHOLD-1)//-1for1sttreeifyBin(tab,hash);break;}//key相同就覆盖原来的值if(e.hash==hash&amp;&amp;((k=e.key)==key||(key!=null&amp;&amp;key.equals(k))))break;p=e;}}if(e!=null){//existingmappingforkeyVoldValue=e.value;if(!onlyIfAbsent||oldValue==null)e.value=value;afterNodeAccess(e);returnoldValue;}}++modCount;//数组长度大于阈值，就扩容if(++size&gt;threshold)resize();afterNodeInsertion(evict);returnnull;}通过分析源码，上面的方法主要做了以下几件事：判断当前桶是否为空，空的就需要初始化（resize中会判断是否进行初始化）。根据当前key的hashcode定位到具体的桶中并判断是否为空，为空表明没有Hash冲突就直接在当前位置创建一个新桶即可。如果当前桶有值（Hash冲突），那么就要比较当前桶中的key、key的hashcode与写入的key是否相等，相等就赋值给e。如果当前桶为红黑树，那就要按照红黑树的方式写入数据。如果是个链表，就需要将当前的key、value封装成一个新节点写入到当前桶的后面（形成链表）。接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。如果在遍历过程中找到key相同时直接退出遍历。如果e!=null就相当于存在相同的key,那就需要将值覆盖。最后判断是否需要进行扩容。继续看下treeifyBin的源码：finalvoidtreeifyBin(Node&lt;K,V&gt;[]tab,inthash){intn,index;Node&lt;K,V&gt;e;//链表转为红黑树时，若此时数组长度小于64，扩容数组if(tab==null||(n=tab.length)&lt;MIN_TREEIFY_CAPACITY)resize();elseif((e=tab[index=(n-1)&amp;hash])!=null){TreeNode&lt;K,V&gt;hd=null,tl=null;//链表转为树结构do{TreeNode&lt;K,V&gt;p=replacementTreeNode(e,null);if(tl==null)hd=p;else{p.prev=tl;tl.next=p;}tl=p;}while((e=e.next)!=null);if((tab[index]=hd)!=null)hd.treeify(tab);}}由此可以看到1.8中，数组有两种情况会发生扩容：一是超过阈值二是链表转为红黑树且数组元素小于64时由此在jdk1.8中，默认长度为16情况下，要么元素一直放在同一下标，链表转为红黑树且数组元素小于64时就会扩容，要么超过阈值12时才会扩容。依据上面的源码分析，在JDK1.8中put方法的执行的原理图如下问点三：HashMap的扩容机制是怎么样的？JDK7与JDK8有什么不同吗？JDK1.7的扩容条件是数组长度大于阈值且存在哈希冲突，而JDK1.8扩容条件是数组长度大于阈值或链表转为红黑树且数组元素小于64时，源码中的体现如下所示：JDK1.7扩容源码：voidaddEntry(inthash,Kkey,Vvalue,intbucketIndex){//数组长度大于阈值且存在哈希冲突（即当前数组下标有元素），就将数组扩容至2倍if((size&gt;=threshold)&amp;&amp;(null!=table[bucketIndex])){resize(2*table.length);hash=(null!=key)?hash(key):0;bucketIndex=indexFor(hash,table.length);}createEntry(hash,key,value,bucketIndex);}JDK1.8扩容源码：//数组长度大于阈值，就扩容if(++size&gt;threshold)resize();//链表转为红黑树时，若此时数组长度小于64，扩容数组if(tab==null||(n=tab.length)&lt;MIN_TREEIFY_CAPACITY)resize();问点四：HashMap中的键值可以为Null吗？能简单说一下原理吗？JDK两个版本都可以。JDK1.7和1.8本质都是去寻找Hash值为0的那个桶，然后如果key为null，则直接替换值问点五：HashMap中能put两个相同的Key吗？为什么能或为什么不能？在JDK7和JDK8中的做法是一样的，若是存入的key值一样，就会将原来的key所对应的value值直接替换掉问点六：聊一聊JDK7的HashMap中的“死锁”是怎么回事？首先JDK7采用的头插法，会有链表成环的问题，JDK采用的尾插法，不会有循环链表的问题。HashMap是线程不安全的，在HashMap的源码中并未对其操作进行同步执行，所以在并发访问的时候就会出现线程安全的问题。JDK7死锁出现在高并发的时候，此时两个线程都将对数据进行扩容，每次扩容的时候，会让链表翻转。transfer函数源码（transfer函数是resize扩容方法中调用的另一个方法）：voidtransfer(Entry[]newTable,booleanrehash){intnewCapacity=newTable.length;for(Entry&lt;K,V&gt;e:table){while(null!=e){Entry&lt;K,V&gt;next=e.next;---------------------(1)if(rehash){e.hash=null==e.key?0:hash(e.key);}inti=indexFor(e.hash,newCapacity);e.next=newTable[i];newTable[i]=e;e=next;}//while}}假设一个链表，A.next=B,B.next=null：正常情况下，新扩容的数组应该是位null，然后A.next=newTable[i]，则A.next=null，newTable[i]=A，B.next=newTable[i]，则B.next=A，newTable[i]=B如果两个线程同时转换，此时已然会执行A.next=newTable[i],则将A.next=null变成A.next=B，剩下过程一致，出现循环链表问点七：HashMap是线程安全的吗？为什么安全或者不安全？不是线程安全的，比如会在扩容的时候产生循环链表；在put的时候会覆盖别的线程的值问点八：什么HashMap的加载因子是0.75？为什么是超过“8”才用红黑树？因为HashMap底层的数据结构是哈希表，在插入数据的时候会出现hash冲突，而HashMap的解决方式是使用拉链法，即采用额外的空间来解决冲突。而选择加载因子是0.75主要跟数学上泊松分布有关系，选择的参数平均为0.5的泊松分布，计算出来当前加载因子是0.75，这更是空间与时间的一种选择折中。而超过8才使用红黑树，源于该泊松分布计算出来的，一个节点哈希冲突8次的概率极为的小，几乎为不可能时间，这也是一次空间与时间的折中。​//1个节点哈希冲突n次的概率0:0.606530661:0.303265332:0.075816333:0.012636064:0.001579525:0.000157956:0.000013167:0.000000948:0.00000006问点九：HashMap、HashTable、ConcurrentHashMap的区别HashMap是线程不安全的，在jdk1.7高并发的时候，可能会在扩容的时候，产生循环链表，所以在高并发的时候，不去使用。HashTable是一个线程安全的，采用的是synchronize的方式，关键字加在方法上，即对当前HashTable对象加锁，会导致所有的数据加上锁。ConcurrentHashMap在JDK1.7的时候使用的是Segment分段锁的思想，将数据分成段，每个段都有个可重入锁，则多线程的时候不会影响到其他线程访问其他段的数据。ConcurrentHashMap在JDK1.8的时候使用的是CAS+synchronized方式，抛弃了Segment分段锁的思想，CAS是一个乐观锁，则在不加锁情况下实现赋值，在当前节点为空的时候，会采用CAS的方式添加节点；而用synchronized而不用是可重入锁的原因是因为官方对synchronized做了很多优化。HashTable其中使用synchronize来保证线程安全，即当有一个线程拥有锁的时候，其他的线程都会进入阻塞或者轮询状态,这样会使得效率越来越低。而ConcurrentHashMapMap的锁分段技术可以有效的提高并发访问率，HashTable访问效率低下的原因，就是因为所有的线程在竞争同一把锁。如果容器中有多把锁，不同的锁锁定不同的位置，这样线程间就不会存在锁的竞争，这样就可以有效的提高并发访问效率,这就是ConcurrentHashMap所使用的锁分段技术将数据一段一段的存储，为每一段都配一把锁，当一个线程只是占用其中的一个数据段时,其他段的数据也能被其他线程访问。在JDK1.7中currentHashMap采用的是Segment分段锁的思想方式实现：Segment是将数据分成段，默认是16，每个段都有一把锁，则理论最高支持16个线程并发JDK1.8的currentHashMap采用的是**数组+链表+红黑树，抛弃了原有的Segment分段锁，而采用了CAS+synchronized**方式实现：CAS，是一个乐观锁，他主要思想是比较然后再执行操作，比较的是内存的值和预期的原值是否一致，如果不一致，则需要自旋获取新值，但是CAS的最大问题就是可能出现ABA的问题。在nolockwhenaddingtoemptybin，也就是桶为空的时候采用CAS方式添加数据，而不为空的时候采用synchronized的方式问点十：谈谈你理解的HashMap，讲讲其中的get和put过程put方法：考虑是否要初始化根据key计算哈希值，找到hash表对应的索引然后判断是否出现的hash冲突，如果没有则直接插入，查看是否需要扩容JDK1.7出现hash冲突直接插入链表中即可JDK1.8出现hash冲突，需要先判断当前是红黑树还是链表，对于链表可能会有一个树化的过程get方法：思路与上面一致，只是少了一个扩容和树化的过程","link":"https://xzzz2020.github.io/post/hashmap/"},{"title":"【总结】JavaSE基础知识","content":"[TOC]该文章是博主采集于各大博文，用于复习和总结相关知识点，将会持续的收集和更新。一、概述1.JDK版本目前只维护两个JDK版本，一个是8，一个是11（2018年）2.Java语言特性可移植性，跨平台，因为Java有一个JVM虚拟机，虚拟机负责执行字节码文件健壮性，具有GC，有自动垃圾回收机制3.Java的加载与执行过程T.java（源文件）通过javac命令变成字节码文件字节码文件通过类加载器加载到JVM中JVM屏蔽了和操作系统打交道的操作![Java程序运行过程](https://img-1302474103.cos.ap-nanjing.myqcloud.com/img/Java程序运行过程-1.png)4.JVM、JDK和JRE的区别Java虚拟机（JVM）是运行Java字节码的虚拟机。JVM有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。字节码和不同系统的JVM实现是Java语言“一次编译，随处可以运行”的关键所在。JDK是JavaDevelopmentKit，它是功能齐全的JavaSDK。它拥有JRE所拥有的一切，还有编译器（javac）和工具（如javadoc和jdb）。它能够创建和编译程序。JRE是Java运行时环境。它是运行已编译Java程序所需的所有内容的集合，包括Java虚拟机（JVM），Java类库，java命令和其他的一些基础构件。但是，它不能用于创建新程序。5.机器码和字节码的概念与区别？机器码：机器码是电脑CPU直接读取运行的机器指令，运行速度最快，但是非常晦涩难懂，也比较难编写，一般从业人员接触不到。字节码：字节码是一种中间状态（中间码）的二进制代码（文件），需要直译器转译后才能成为机器码。二、Java语言基础1.八种基本类型八种基本数据类型：byte、short、int、long、float、double、boolean、char。一个字节等于8位IEE754标准（32位）：1位是符号位，8位是阶码用移码表示，23位尾数2.字符编码java支持中文，因为其采用的是Unicode编码，使之更趋于国际化类型可以存放一个汉字，java中的char使用utf-16编码编码名称解释ASCII字符编码只支持英文字母、标点符号、数字字符等，ASCII码占用1个字节，所以ASCII码最多可以表示256个字符.小a97大A65,’0’是48ISO-8859-1有称latin-1,是国际化标准或组织ISO制定的，主要为了西欧语言中的字符编码，和ASCII兼容，仍不支持中文GB2312/GBK/GB18030主要是汉字编码，三种编码从容量上看是包含关系简体中文：GBK&lt;GB2312&lt;GB18030繁体中文：Big5【大五码】unicodeUnicode统一了全世界上的所有文字编码，unicode有几种实现：UTF-8,UTF-16,UTF-32java语言采用的是Unicode编码，所以在java中标识符也可以使用中文3.类型转换在java中基本类型可以相互转换，boolean类型比较特殊不可以转换成其他类型转换分为默认转换和强制转换:默认转换：容量小的类型会默认转换为容量大的类型byte--&gt;short--&gt;int--&gt;long--&gt;float--&gt;doublebyte、short、char之间计算不会互相转换，首先先转换成int强制转换：将容量大的类型转换成容量小的类型，需要进行强制转换注意：只要不超出范围可以将整型值直接赋值给byte，short，char在多种类型混合运算过程中，首先先将所有数据转换成容量最大的那种，再运算publicclassDataTypeTest08{publicstaticvoidmain(String[]args){longx=100L;inty=x;//编译不通过longa=2147483648L;intb=(int)a;System.out.println(b);//出现精度丢失问题，大类型--&gt;&gt;小类型会出现问题，输出-2147483648bytea=1000;//出现错误，1000超出了byte的范围longg=10;inth=g/3;//出现错误，多个数值在运算过程中，会转换成容量最大的类型byteh3=(byte)(int)g/3;//考察优先级，将g先转换成int，再强转成byte，再除以3得到int，赋值错误byteh4=(byte)(int)(g/3);//正确的byteh5=(byte)g/3;//考察优先级，先转换成byte，再运算byteh6=(byte)(g/3);//正确shorth7=(short)(g/3);//正确shorti=10;bytej=5;shortk=i+j;//错误的，short和byte运算，首先会转换成int再运算}}4.运算符短路与和逻辑与的区别？短路与比逻辑与智能，短路与效率高。短路或和逻辑或的区别？短路或：左边的算子结果是true，右边的表达式不执行，发生短路a+=3和a=a+3;是一样的吗？结论(重点)：扩展赋值运算符不改变运算结果的类型。初始类型和最终运算结果类型完全相同。publicclassOperatorTest09{publicstaticvoidmain(String[]args){byteb=10;//编译错误//b=b+3;//修改b=(byte)(b+3);System.out.println(b);//13b+=3;System.out.println(b);//16b+=10000;//等同于b=(byte)(b+10000);System.out.println(b);//32}}5.控制语句switch语句switch也称为多重分支，具体格式如下switch(表达式){case值1：语句break;case值2：语句break;default：语句Break;}说明：表达式的值只能为：char、byte、short、int类型（JDK7以后支持String），boolean、long、float、double都是非法的break语句可以省略,但会出现switch穿透default语句也可以省略，一般不建议省略，并且放置在最后需求：假定系统给定学生的考试成绩，考试成绩可以带有小数。假定成绩是合法的[0-100]，请根据学生考试成绩判断该学生成绩等级：[90-100]A[80-90)B[70-80)C[60-70)D[0-60)E以上业务只能使用switch语句完成，不允许使用if语句。publicclassSwitchTest04{publicstaticvoidmain(String[]args){//考试成绩合法doublescore=100;//开始判断intgrade=(int)(score/10);//case条件不能为浮点数switch(grade){case10:System.out.println(&quot;A&quot;);break;case9:System.out.println(&quot;A&quot;);break;case8:System.out.println(&quot;B&quot;);break;case7:System.out.println(&quot;C&quot;);break;case6:System.out.println(&quot;D&quot;);break;default:System.out.println(&quot;E&quot;);}//重点：case是可以合并的switch(grade){case10:case9:System.out.println(&quot;A&quot;);break;case8:System.out.println(&quot;B&quot;);break;case7:System.out.println(&quot;C&quot;);break;case6:System.out.println(&quot;D&quot;);break;default:System.out.println(&quot;E&quot;);}}}for语句for(;false;){//会出现编译错误，因为无法访问System.out.println(&quot;呵呵&quot;);}for(;true;){//死循环System.out.println(&quot;哈哈&quot;);}6.方法方法的返回值问题：publicclassMethodTest07{//缺少返回语句，程序编译时无法判断是否能走到else，无法编译通过publicstaticintm1(){booleanflag=true;if(flag){return1;}}//正确publicstaticintm2(){booleanflag=true;if(flag){return1;}else{return0;}}//编译错误publicstaticintm3(){booleanflag=false;if(flag){//return1;//return后不能接任何语句System.out.println(&quot;??????????&quot;);}System.out.println(&quot;??????????&quot;);return0;System.out.println(&quot;??????????&quot;);}}三、面向对象1.面向过程与面向对象的区别面向过程：面向过程性能比面向对象高。因为类调用时需要实例化，开销比较大，比较消耗资源，所以当性能是最重要的考量因素的时候，比如单片机、嵌入式开发、Linux/Unix等一般采用面向过程开发。但是，面向过程没有面向对象易维护、易复用、易扩展。面向对象：面向对象易维护、易复用、易扩展。因为面向对象有封装、继承、多态性的特性，所以可以设计出低耦合的系统，使系统更加灵活、更加易于维护。但是，面向对象性能比面向过程低这个并不是根本原因，面向过程也需要分配内存，计算内存偏移量，Java性能差的主要原因并不是因为它是面向对象语言，而是Java是半编译语言，最终的执行代码并不是可以直接被CPU执行的二进制机械码。而面向过程语言大多都是直接编译成机械码在电脑上执行，并且其它一些面向过程的脚本语言性能也并不一定比Java好。2.面向对象特征封装封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。继承继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。关于继承如下3点请记住：子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，只是拥有。子类可以拥有自己属性和方法，即子类可以对父类进行扩展。子类可以用自己的方式实现父类的方法。（以后介绍）。多态所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。在Java中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。抽象抽象就是忽略一个主题中与当前目标无关的那些方面，以便更充分地注意与当前目标有关的方面。抽象并不打算了解全部问题，而只是选择其中的一部分，暂时不用部分细节。比如，我们要设计一个学生成绩管理系统，考察学生这个对象时，我们只关心他的班级、学号、成绩等，而不用去关心他的身高、体重这些信息。3.参数传递所有基本数据类型的都是值传递，其他类型的为址传递4.关键字this关键字：this关键字指的是当前调用的对象，只能用在构造函数和实例方法内部，还可以应用在成员变量的声明上，static标识的方法里是不能使用this的。作用：代码复用。super关键字调用父类的构造方法没有显示地调用super();父类的无参构造方法也执行必须将super放到子类的构造函数的第一语句来调用父类的构造方法调用父类的成员方法需要注意：super只能应用在成员方法和构造方法中，不能应用在静态方法中（和this是一样的），如果在构造方法中使用必须放在第一行为什么会有super关键字？因为子类必须要调用父类的构造方法，先把父类构造完成，因为子类依赖于父类，没有父，也就没有子有时需要在子类中显示的调用父类的成员方法那么我们以前为什么没有看到super，而且我们也有继承，如：Student继承了Person？因为子类中我们没有显示的调用父类构造方法，那么他会默认调用父类的无参构造方法，此种情况下如果父类中没有无参构造方法，那么编译时将会失败注意构造方法不存在覆盖的概念，构造方法可以重载static关键字可以用来修饰它可以用来修饰的成员变量和成员方法，被修饰的成员是属于类的，而不是单单是属于某个对象的。也就是说，既然属于类，就可以不靠创建对象来调用了。static方法是否能重写？静态的方法可以被继承，但是不能重写，所以abstract修饰的方法是不可同时是static修饰。语法上子类允许出现和父类只有方法体不一样其他都一模一样的static方法，但是在父类引用指向子类对象时，通过父类引用调用的依然是父类的static方法，而不是子类的static方法。即：语法上static支持重写，但是运行效果上达不到多态目的final关键字final表示不可改变的含义采用final修饰的类不能被继承采用final修饰的方法不能被覆盖采用final修饰的变量不能被修改final修饰的变量必须显示初始化局部变量：一旦赋值不能重新赋值成员变量：不能采用系统默认值，必须手动赋值如果修饰的引用，那么这个引用只能指向一个对象，也就是说这个引用不能再次赋值，但被指向的对象是可以修改的构造方法不能被final修饰会影响JAVA类的初始化final定义的静态常量调用时不会执行static代码块等相关语句，这是由java虚拟机规定的。修饰引用变量：final修饰引用变量，主要修饰的是变量的地址，那么这个引用只能指向一个对象，也就是说这个引用不能再次赋值，但被指向的对象是可以修改的publicclassFinalTest05{publicstaticvoidmain(String[]args){Personp1=newPerson();//可以赋值p1.name=&quot;张三&quot;;System.out.println(p1.name);finalPersonp2=newPerson();p2.name=&quot;李四&quot;;System.out.println(p2.name);//不能编译通过//p2采用final修饰，主要限制了p2指向堆区中的地址不能修改(也就是p2只能指向一个对象)//p2指向的对象的属性是可以修改的p2=newPerson();}}classPerson{Stringname;}final和static联合修饰实例变量==常量（尽量使用一个静态工具类抽取出常量）常量名要求全部大写[规范]常量都是publicstaticfinal的常量在类加载的时候完成初始化，存储在JVM的方法区中常量是值不可改变的变量5.代码块静态属性和静态代码块按照代码顺序执行，实例代码块和成员属性同理静态代码块使用static关键字可以定义静态语句块，静态语句块具有以下特点：静态语句块在类加载时执行，在main方法执行之前就已经执行了。类只加载一次，所以静态语句块也是只执行一次一个类中可以编写多个静态语句块，执行顺序是：自上而下依次执行。静态语句块的使用时机：当程序需要在类加载的时候就做一些事情，可以在静态语句块中来实现实例语句块实例语句块和静态代码块没有关系，实例语句块有以下特点：实例语句块在构造方法执行之前执行，构造函数执行一次，实例语句块对应执行一次。每调用一次构造函数之前就会执行一次实例语句块实例语句块可以编写多个，也是按照自上而下的顺序依次执行。实例语句块使用时机：当程序需要在对象初始化时刻就做一些事情，可以在实例语句块中实现//静态语句块static{System.out.println(1);}//实例语句块{System.out.println(1);}6.类的继承如何实现Java多继承？使用内部类就可以多继承，严格来说，还不是实现多继承，但是这种方法可以实现多继承所需的功能，所以把它称为实现了多继承。定义多个内部类，每个内部类都可以继承一个父类然后定义创建每个内部类的成员变量在方法中调用成员的方法classCall{publicvoidcallSomebody(StringphoneNum){System.out.println(&quot;我在打电话喔，呼叫的号码是：&quot;+phoneNum);}}classSendMessage{publicvoidsendToSomebody(StringphoneNum){System.out.println(&quot;我在发短信喔，发送给：&quot;+phoneNum);}}publicclassPhone{privateclassMyCallextendsCall{}privateclassMySendMessageextendsSendMessage{}privateMyCallcall=newMyCall();privateMySendMessagesend=newMySendMessage();publicvoidphoneCall(StringphoneNum){call.callSomebody(phoneNum);}publicvoidphoneSend(StringphoneNum){send.sendToSomebody(phoneNum);}publicstaticvoidmain(String[]args){Phonephone=newPhone();phone.phoneCall(&quot;110&quot;);phone.phoneSend(&quot;119&quot;);}}继承特征：继承是面向对象的重要概念，软件中的继承和现实中的继承概念是一样的继承是实现软件可重用性的重要手段，如：A继承B，A就拥有了B的所有特性，如现实世界中的儿子继承父亲的财产，儿子不用努力就有了财产，这就是重用性Java中只支持类的单继承，也就是说A只能继承B，A不能同时继承CJava中的继承使用extends关键字，语法格式：[修饰符]class子类extends父类{}方法的重载的条件方法名相同方法的参数类型，个数，顺序至少有一个不同方法的返回类型可以不同（不依靠返回类型来区分重载）方法的修饰符可以不同，因为方法重载和修饰符没有任何关系方法重载只出现在同一个类中方法的覆盖(Override)的条件：必须要有继承关系覆盖只能出现在子类中，如果没有继承关系，不存在覆盖，只存在重载在子类中被覆盖的方法，必须和父类中的方法完全一样，也就是方法名，返回类型、参数列表，完全一样子类方法的访问权限不能小于父类方法的访问权限子类方法不能抛出比父类方法更多的异常，但可以抛出父类方法异常的子异常父类的静态方法不能被子类覆盖父类的私有方法不能覆盖覆盖是针对成员方法，而非属性为什么需要覆盖？就是要改变父类的行为。方法重写之后，“子类对象”执行的一定是重写之后的方法，也体现了就近原则7.static、构造方法和父子类的调用顺序要点：静态的代码块一定比构造方法先执行如果都是静态代码，一个类里面，按照先后顺序执行，父子之间，父类静态代码块先执行静态代码只会执行一次，多次new新的对象，构造方法，非静态代码块会多次执行classParent{static{System.out.println(&quot;父类的静态块&quot;);}privatestaticStringstaticStr=getStaticStr();privateStringstr=getStr();{System.out.println(&quot;父类的实例块&quot;);}publicParent(){System.out.println(&quot;父类的构造方法&quot;);}privatestaticStringgetStaticStr(){System.out.println(&quot;父类的静态属性初始化&quot;);returnnull;}privateStringgetStr(){System.out.println(&quot;父类的实例属性初始化&quot;);returnnull;}}classChildextendsParent{privatestaticStringstaticStr=getStaticStr();static{System.out.println(&quot;子类的静态块&quot;);}{System.out.println(&quot;子类的实例块&quot;);}publicChild(){System.out.println(&quot;子类的构造方法&quot;);}privateStringstr=getStr();privatestaticStringgetStaticStr(){System.out.println(&quot;子类的静态属性初始化&quot;);returnnull;}privateStringgetStr(){System.out.println(&quot;子类的实例属性初始化&quot;);returnnull;}}publicclassTest{publicstaticvoidmain(String[]args){newChild();}}分析：首先先加载类到JVM的方法区中，则先加载静态的内容，比如静态代码块和静态属性，并且先加载父类，且按照代码顺序加载接着加载对象到堆内存中，先加载父类的实例语句块和实例属性，按照父类优先，根据代码顺序加载，最后加载构造方法执行结果：父类的静态块父类的静态属性初始化子类的静态属性初始化子类的静态块父类的实例属性初始化父类的实例块父类的构造方法子类的实例块子类的实例属性初始化子类的构造方法8.抽象类和接口（***）抽象类在java中采用abstract关键字定义的类就是抽象类，采用abstract关键字定义的方法就是抽象方法抽象的方法只需在抽象类中，提供声明，不需要实现如果一个类中含有抽象方法，那么这个类必须定义成抽象类，一个抽象类不一定含有抽象方法如果这个类是抽象的，那么这个类被子类继承，抽象方法必须被重写。如果在子类中不复写该抽象方法，那么必须将此类再次声明为抽象类抽象的类是不能实例化的，就像现实世界中人其实是抽象的，张三、李四才是具体的抽象类不能被final修饰抽象方法不能被final修饰，因为抽象方法就是被子类实现的抽象类中可以包含方法实现，可以将一些公共的代码放到抽象类中，另外在抽象类中可以定义一些抽象的方法，这样就会存在一个约束，而子类必须实现我们定义的方法，如：teacher必须实现printInfo方法，Student也必须实现printInfo方法，方法名称不能修改，必须为printInfo，这样就能实现多态的机制，有了多态的机制，我们在运行期就可以动态的调用子类的方法。所以在运行期可以灵活的互换实现。抽象类和普通类的区别？抽象类普通类不能被实例化，也就是使用new关键字可以被实例化权限限定于Public和Protected，因为需要子类去继承抽象类JDK1.8以前，抽象类的方法默认访问权限为protectedJDK1.8时，抽象类的方法默认访问权限变为default没有权限限制如果一个类继承抽象类，则必须实现抽象类的抽象方法如果没有实现抽象方法，则该类必须定义成抽象类不强制实现父类的方法接口注：JDK1.8以后，接口里可以有静态方法和方法体了。接口我们可以看作是抽象类的一种特殊情况，在接口中只能定义抽象的方法和常量(完全抽象)接口中的方法默认都是publicabstract的(可以省略写)，不能更改接口中的变量默认都是publicstaticfinal的(省略不写)，不能更改，所以必须显示的初始化注意：接口里的所有数据都是public修饰的！如果一个非抽象的类实现了接口，那么接口中所有的方法必须实现一类可以实现多个接口，接口和接口之间支持也是多继承的,但接口之间不能实现在java中接口其实描述了类需要做的事情，类要遵循接口的定义来做事，使用接口到底有什么本质的好处？可以归纳为两点：采用接口明确的声明了它所能提供的服务解决了Java单继承的问题接口和抽象类的区别？接口抽象类不能被实例化不能被实例化需要被子类实现，并实现接口的方法需要被子类继承，并实现抽象方法只能做方法的声明（JDK1.8之后允许方法体）可以做方法的声明，也可以做方法的实现如果子类不能实现接口中的所有方法，则该类只能是抽象类如果子类不能实现抽象类的所有抽象，则该类只能是抽象类属性只能是静态的常量没有限制接口与接口之间可以多继承只能单继承9.类之间的关系泛化关系类与类之间的继承以及接口与接口之间的继承实现关系类对接口的实现关联关系一个类中属性是另个类publicclass学生{private班级班级;//getter/setter}publicclass班级{}聚合关系是关联关系的一种，有着较强的关联关系在java中一个类是整体，使用对象数组包含另个类；另个类属于某个整体publicclass汽车{private轮胎集合轮胎；//getter/setter}publicclass轮胎{private汽车汽车;//getter/setter}依赖关系依赖关系是比关联关系弱的关系，在java语言中体现为返回值，参数，局部变量和静态方法调用publicclassTest{publicstaticvoidmain(String[]args){Personperson=newPerson();}}classPerson{}10.Object类Object类是所有Java类的根基类如果在类的声明中未使用extends关键字指明其基类，则默认基类为Object类equalsequals的源码是这样写的：publicbooleanequals(Objectobj){return(this==obj);}所以，默认情况下比较的是地址值，但是可以让我们覆写该方法，实现对象的比较。如何覆写equals方法？首先为了提高效率，需要用==判断是否是同一个对象，如果是直接返回true接着为了提高健壮性，判断是否对象是否是该类的一个对象，如果是，需要对其向下转型最后是比较的逻辑publicclassObjectDemo{publicstaticvoidmain(Stringargs[]){Studentstudent1=newStudent(&quot;生命壹号&quot;,22,&quot;成都&quot;);Studentstudent2=newStudent(&quot;生命壹号&quot;,22,&quot;成都&quot;);System.out.println(student1==student2);System.out.println(student1.equals(student2));}}classStudent{privateStringname;privateintage;privateStringaddress;publicStudent(Stringname,intage,Stringaddress){this.name=name;this.age=age;this.address=address;}//重写Object类中的equals方法（比较两个对象的值是否相等）publicbooleanequals(Objectobj){//为了提高效率：如果两个内存地址相等，那么一定是指向同一个对内存中的对象，就无需比较两个对象的属性值（自己跟自己比，没啥意义嘛）if(this==obj){returntrue;}//为了提供程序的健壮性//我先判断一下，obj是不是学生的一个对象，如果是，再做向下转型，如果不是，直接返回false。//这个时候，我们要判断的是对象是否是某个类的对象?//记住一个格式：对象名instanceof类名。表示：判断该对象是否是该类的一个对象if(!(objinstanceofStudent)){returnfalse;}//如果是就继续Students=(Student)obj;//强制转换，即向下转型（毕竟Object类型没有具体的对象属性）returnthis.name.equals(s.name)&amp;&amp;this.age==s.age&amp;&amp;this.address.equals(s.address);//判断两个对象的属性值是否相等}}==与equals()区别？==equals()等号比较的是值，特别是比较引用类型，比较的是引用的内存地址的那个值默认源码使用的是==，但是可以通过覆写该方法，实现对象的比较对于基本数据的包装类型（Byte,Short,Character，Integer，Float,Double，Long,Boolean）除了Float和Double之外，其他的六种都是实现了常量池的，因此对于这些数据类型而言，一般我们也可以直接通过==来判断是否相等Byte,Short,Integer,Long,Character,Boolean，前面4种包装类默认创建了数值[-128，127]的相应类型的缓存数据，Character创建了数值在[0,127]范围的缓存数据，Boolean直接返回TrueOrFalse。如果超出对应范围仍然会去创建新的对象。publicclassTest{publicstaticvoidmain(String[]args){Integera=127;Integerb=127;System.out.println(a==b);//trueIntegerc=128;Integerd=128;System.out.println(c==d);//false}}因为Integer在常量池中的存储范围为[-128,127]，127在这范围内，因此是直接存储于常量池的，而128不在这范围内，所以会在堆内存中创建一个新的对象来保存这个值，所以m，n分别指向了两个不同的对象地址，故而导致了不相等。finalize当垃圾收集器将要收集某个垃圾对象时将会调用finalize，建议不要使用此方法，因为此方法的运行时间不确定，如果执行此方法出现错误，程序不会报告，仍然继续运行JVM当看到对象类含有finalize函数，会将该对象交给FinalizerThread处理，但是处理的时间不确定。11.访问控制权限范围由大到小的排序：public&gt;protected&gt;缺省&gt;private对类的修饰只有public和缺省，内部类除外修饰符类的内部同一个包中子类任何地方publicYYYYprotectedYYYN缺省YYNNprivateYNNN总结为一句话：private修饰的只能类的内部调用；缺省的可以在一个包中调用；protected扩展到了子类中，比如继承某个类，则可以使用那个类的属性和方法；public可以在任何地方访问。12内部类分为四种内部类：实例内部类：在类的内部定义的普通类静态内部类：在类的内部定义的静态类局部内部类：在方法中定义的普通类匿名内部类：方法使用中定义的普通类，主要用来实现接口实例内部类特点：创建实例内部类，外部类的实例必须已经创建实例内部类会持有外部类的引用，可以直接访问外部类的属性不允许有静态声明publicclassOuterClass{//静态变量privatestaticStrings1=&quot;静态变量&quot;;//实例变量privateStrings2=&quot;实例变量&quot;;//实例内部类publicclassInnerClass{//编译错误，实例内部类中不允许有静态的声明publicstaticvoidm1(){}//实例方法publicvoidm2(){System.out.println(s1);System.out.println(s2);}}//入口publicstaticvoidmain(String[]args){OuterClassoc=newOuterClass();InnerClassinnerClass=oc.newInnerClass();//??innerClass.m2();}}静态内部类特点：静态内部类不会持有外部的类的引用创建时可以不用创建外部类，在静态内部类中只能直接访问外部类中所有的静态数据。静态内部类等同于静态变量publicclassOuterClass{//静态变量privatestaticStrings1=&quot;静态变量&quot;;//实例变量privateStrings2=&quot;实例变量&quot;;//静态内部类//静态内部类可以使用任何一个访问控制权限修饰符修饰。protectedstaticclassInnerClass{//静态方法publicstaticvoidm1(){System.out.println(s1);//System.out.println(s2);}//实例方法publicvoidm2(){System.out.println(s1);//System.out.println(s2);}}//入口publicstaticvoidmain(String[]args){OuterClass.InnerClass.m1();//外部类.可以省略InnerClassinnerClass=newOuterClass.InnerClass();innerClass.m2();}}局部内部类局部内部类等同于局部变量局部内部类是在方法体中声明的类，该类只能在方法体中使用局部内部类不能使用public、protected、private修饰局部内部类访问本地变量的时候，方法中的参数需要使用final修饰publicclassOuterClass{privateinta=100;//局部变量在内部类中使用必须采用final修饰publicvoidmethod1(finalinttemp){classInner3{inti1=10;//可以访问外部类的成员变量inti2=a;inti3=temp;}//使用内部类Inner3inner3=newInner3();System.out.println(inner3.i1);System.out.println(inner3.i3);}publicstaticvoidmain(String[]args){OuterClassout=newOuterClass();out.method1(300);}}匿名内部类是一种特殊的内部类，该类没有名字通过new关键字创建，并加上方法体主要用于实现接口publicclassTest{publicstaticvoidmain(String[]args){//在方法中实现接口newThread(newRunnable(){@Overridepublicvoidrun(){}}).run();}}四、异常任意的异常都是在运行时发生的！！！1.异常的体系所有的异常都是Throwable的子类Thorwable有两个直接子类Error和ExceptionError:在Java中只要Error发生了就一种结果——退出JVM，例如StackOverErrorException的直接子类：Exception的直接子类叫做编译时异常、受控异常、检查异常。它虽然叫做编译时异常，但是它不是发生在编译阶段的异常，之所以叫做编译时异常是因为编译时异常要求必须在程序编译的阶段就手动的处理，如果不处理这些异常的话，程序无法编译通过。对于编译时异常有两种手段处理，一是trycatch捕获，一是throws抛出RuntimeException的直接子类：RuntimeException的直接子类叫做运行时异常、非受控异常、非检查异常。这种异常不要求在程序编译阶段处理，编译也可以通过比如说除0异常自定义异常：JDK提供的异常不能够满足要求的情况下用户可以自己自定义异常，可以根据实际情况选择继承Exception或者RuntimeException两种形式。2.说出几个常见的异常ErrorStackOverError（堆溢出）OutOfMemoryError（内存溢出）受控异常IOException（IO异常）SQLException（SQL异常）ClassNotFoundException（找不到指定的类异常）不受控异常NullPointerException（空指针异常）ArithmeticException（算术异常）ArrayIndexOutOfBoundsException（数组下表越界异常）ClassCastException（类型强制转换类型）3.异常处理异常的捕获应该从小到大一般有两种方式try...catch...finally....thorws抛给调用者finally在任何情况下都会执行，除非JVM挂掉，通常在finally里关闭资源publicclassExceptionTest12{publicstaticvoidmain(String[]args){intr=method1();//输出为：100？50？System.out.println(r);//输出是50}privatestaticintmethod1(){inta=10;try{a=50;returna;//直接返回值}finally{a=100;//该语句也会执行，只是a已经返回}}}throws和throw的区别？throwsthrowthorws是声明异常thorws是声明异常用在函数上用在函数内部","link":"https://xzzz2020.github.io/post/amjJC-n_8/"},{"title":"秒杀策略（缓存+消息队列）","content":"该项目为仅供个人学习使用！！！个人博客地址：https://blog.csdn.net/qq_43040688个人网站地址：http://www.xzzz2020.cn/一、项目简介二、技术栈三、详细实现3.1分布式Session3.2页面缓存+URL缓存3.3对象级缓存3.4核心接口优化3.5接口安全优化四、项目实践中遇到的问题4.1秒杀成功商品订单数超过预订数值4.2一个用户的多个请求导致秒杀成功秒杀多次4.3使用了缓存依然会大量访问数据库五、接下来的优化思路一、项目简介该项目主要学习常用的高并发优化技术，并发的瓶颈往往在数据库，采用缓存和消息队列对接口进行优化减少对数据优化，掌握面对高并发场景下的设计思路：以SpringBoot为主线的技术栈，使用了Mybatis+Druid，采用前后端分离架构整个项目基于商品的秒杀接口，设计登录、商品展示以及订单展示等一系列的功能接口高并发的优化主要利用Redis实现页面缓存+URL缓存+对象缓存，利用前后端分离实现页面静态化以及整合RabbitMQ实现异步下单的优化。QPS优化至少两倍用户登录信息使用Cookie+Redis实现分布式Session，使用拦截器+自定义参数解析器，获取用户信息。解决了不同服务器之间出现的缓存不一致或者服务器宕机Session消失的问题接口安全实现了秒杀接口地址隐藏+数学公式验证码+利用Redis实现接口防刷。防止机器人对于核心业务的攻击利用Jmeter模拟5000个用户，使用1万个线程，对商品展示接口和秒杀接口进行压测。商品展示接口优化前QPS：584.8，优化后QPS：2085.9；秒杀接口优化前QPS：351.8，优化后QPS：2242.7二、技术栈前端BootstrapAjaxthymeleaf后端SpringBootMybatisDruidJedisfastjson数据库MySQLRedis中间件RabbitMQ测试Jmeter三、详细实现3.1分布式Session常用的有三种分布式Session解决方案：服务器之间Session共享、Session绑定、Cookie+缓存。本项目使用的就是Cookie+缓存的方式。下面将介绍这几种方式：服务器之间Session共享：使用一台作为用户的登录服务器，当用户登录成功之后，会将session写到当前服务器上，我们通过脚本或者守护进程将session同步到其他服务器上，这时当用户跳转到其他服务器，session一致，也就不用再次登录。缺陷：速度慢，同步session有延迟性，可能导致跳转服务器之后，session未同步。而且单向同步时，登录服务器宕机，整个系统都不能正常运行。Session绑定：基于nginx的ip-hash策略，可以对客户端和服务器进行绑定，同一个客户端就只能访问该服务器，无论客户端发送多少次请求都被同一个服务器处理缺陷：容易造成单点故障，如果有一台服务器宕机，那么该台服务器上的session信息将会丢失前端不能有负载均衡，如果有，session绑定将会出问题Cookie+缓存将用户信息保存在Redis上，将键值放在Cookie中传递给浏览器，浏览器再下一次的访问中就会携带该Cookie。此时利用拦截器+自定义参数解析器解析用户的Cookie，从缓存中获取数据传递给方法。部分代码如下：利用Cookie+加缓存保存用户信息/***分布式Session的思路是将数据存放在Redis中*将数据的key放在cookie中发送给用户*用户会携带cookie访问*获取期中的token，从redis中获取*每次访问都会生成一个新的，延长有效期*/privatevoidaddCookie(HttpServletResponseresponse,Stringtoken,MiaoshaUseruser){//生成Cookie//生成一个随机字符串token，去掉&quot;-&quot;//将token+加上Redis通用缓存Key，保存在redis中redisService.set(MiaoshaUserKey.getByToken(),token,user);//生成Cookie，只将token存放在cookie,防止用户获取其他用户信息Cookiecookie=newCookie(COOKIE_NAME_TOKEN,token);//将Cookie的时间和Redis缓存时间一直cookie.setMaxAge(MiaoshaUserKey.getByToken().expireSeconds());//将Cookie存放在根目录cookie.setPath(&quot;/&quot;);////将Cookie返回给浏览器response.addCookie(cookie);}3.2页面缓存+URL缓存页面缓存和URL缓存主要差异在于URL缓存会根据URL的变化，数据会有所不同，如某个商品的详细信息、视频的详细信息等。故只介绍商品列表页面缓存技术：页面缓存当客户的请求到达后端时，先去redis中查询缓存，如果缓存中找不到，则进行数据库逻辑操作，然后渲染，存入缓存并返回给前端如果在缓存中找到了则直接返回给前端。存储在Redis缓存中的页面需要设置超时时间，缓存的时间长度根据页面数据变化频繁程度适当调整。目前大多数页面缓存都是在60~120秒，少数几乎不变化的可以调整到5分钟!部分代码实现：商品列表的Controller层@RequestMapping(value=&quot;/to_list&quot;,produces=&quot;text/html&quot;)@ResponseBodypublicStringtoGoods(Modelmodel,MiaoshaUseruser,finalHttpServletRequestrequest,finalHttpServletResponseresponse){//取缓存Stringhtml;html=redisService.get(GoodsKey.getGoodsList(),&quot;&quot;,String.class);if(html!=null){//如果缓存有这个页面returnhtml;}else{//如果没有这个页面//访问数据库获取商品数据List&lt;GoodsVo&gt;goodsList=goodsService.listGoodsVo();if(user!=null){//如果有用户信息，则保存在Model中model.addAttribute(&quot;user&quot;,user);}//将商品数据保存在Model中model.addAttribute(&quot;goodsList&quot;,goodsList);//手动渲染SpringWebContextspringWebContext=newSpringWebContext(request,response,request.getServletContext(),request.getLocale(),model.asMap(),context);html=viewResolver.getTemplateEngine().process(&quot;goods_list&quot;,springWebContext);if(!StringUtils.isEmpty(html)){//保存到缓存，缓存时间只有60秒，不宜过长redisService.set(GoodsKey.getGoodsList(),&quot;&quot;,html);}//返回到浏览器returnhtml;}}接下来使用Jmeter启动1万个线程进行压测：优化前，可以看的吞吐量达到584.8优化后，可以看的吞吐量达到2085.93.3对象级缓存相比页面缓存是更细粒度缓存。在实际项目中，不会大规模使用页面缓存，因为涉及到分页，一般只缓存前面1-2页。对象缓存就是当用到用户数据的时候，可以从缓存中取出。需要注意两个问题：一旦数据发生更改，一定要将缓存失效Service之间相互调用，切忌不能直接调用DAO，因为可能中间调用了缓存部分代码实现：保存用户信息/***这个是对象级的缓存*从缓存中取出用户信息*&lt;p&gt;*和页面缓存最大的区别是：1.时间是永久的2.当对象发生更新时，需删除或者更新缓存*&lt;p&gt;*从这里可以看出，Service之间相互调用，切忌不能直接调用DAO，因为可能中间调用了缓存*/publicMiaoshaUsergetById(longid){//取缓存MiaoshaUseruser;user=redisService.get(MiaoshaUserKey.getById(),&quot;:&quot;+id,MiaoshaUser.class);if(user!=null){returnuser;}else{//取数据库，加入到缓存中user=miaoshaUserDao.getById(id);redisService.set(MiaoshaUserKey.getById(),&quot;:&quot;+id,user);returnuser;}}3.4核心接口优化核心的业务接口优化主要思路是：使用利用Redis保存商品库存的数量、用户的秒杀成功的订单信息和商品是否秒杀完的标记，这样请求更多的访问缓存，减少对数据库的压力若用户秒杀成功，利用RabbitMQ实现异步下单，服务器控制访问数据库的压力，让用户暂时等待，这样可以优化用户的体验，防止出现服务器宕机等问题部分代码如下所示：秒杀接口Controller@RequestMapping(value=&quot;/{path}/do_miaosha&quot;,method=RequestMethod.POST)@ResponseBodypublicResult&lt;Integer&gt;do_miaosha(MiaoshaUseruser,@RequestParam(&quot;goodsId&quot;)longgoodsId,@PathVariable(&quot;path&quot;)Stringpath){//判断用户是否登录，如果没用登录，则传递提示信息if(user==null){returnResult.error(CodeMsg.SESSION_ERROR);}//隐藏了访问接口，需要验证pathif(StringUtils.isEmpty(path)){returnResult.error(CodeMsg.REQUEST_ILLEGAL);}booleancheck=miaoshaService.checkPath(path,user.getId(),goodsId);if(!check){returnResult.error(CodeMsg.REQUEST_ILLEGAL);}//判断是否秒杀到了MiaoshaOrderorder=orderService.getMiaoshaOrderByUserIdGoodsId(user.getId(),goodsId);//如果能够获取订单，说明该用户已经秒杀到商品if(order!=null){returnResult.error(CodeMsg.REPEATE_MIAO_SHA);}//判断是否秒杀已经结束Booleanover=localOverMap.get(goodsId);if(over){returnResult.error(CodeMsg.MIAO_SHA_OVER);}//预减库存longstock=redisService.decr(GoodsKey.getMiaoGoodsStock(),&quot;:&quot;+goodsId);if(stock&lt;0){//如果发现库存不足，则将秒杀结束的标记置成truelocalOverMap.put(goodsId,true);returnResult.error(CodeMsg.MIAO_SHA_OVER);}//保存信息MiaoshaMessagemiaoshaMessage=newMiaoshaMessage();miaoshaMessage.setGoodsId(goodsId);miaoshaMessage.setUser(user);//入队，实现异步下单mqSender.sendMiaoshaMessage(miaoshaMessage);//返回客户端订单处理中returnResult.success(0);//排队中}消息的发送者publicvoidsendMiaoshaMessage(MiaoshaMessagemiaoshaMessage){//将数据序列化字符串Stringstr=SerializableUtil.beanToString(miaoshaMessage);//发送消息amqpTemplate.convertAndSend(MQConfig.MIAOSHA_QUEUE,str);}消息的接收者@RabbitListener(queues=MQConfig.MIAOSHA_QUEUE)publicvoidmiaoshaReceive(Stringmessage){//将消息反序列化MiaoshaMessagemiaoshaMessage=SerializableUtil.stringToBean(message,MiaoshaMessage.class);//获取用户MiaoshaUseruser=miaoshaMessage.getUser();//获取用户idlonggoodsId=miaoshaMessage.getGoodsId();//再次判断库存是否足够GoodsVogoods=goodsService.getGoodsVoByGoodsId(goodsId);IntegerstockCount=goods.getStockCount();//如果库存不足，则直接返回if(stockCount&lt;=0){return;}//减库存下订单写入订单一个事务中miaoshaService.miaosha(user,goods);}订单的处理@TransactionalpublicOrderInfomiaosha(MiaoshaUseruser,GoodsVogoods){//减库存booleansuccess=goodsService.reduceStock(goods);if(success){//下订单returnorderService.creatOrder(user,goods);}else{//如果库存不足，设置商品已经卖完setGoodsOver(goods.getId());}returnnull;}/***设置商品已经卖完*/privatevoidsetGoodsOver(Longid){redisService.set(MiaoshaKey.getMiaoshaOver(),&quot;:&quot;+id,true);}接下来使用Jmeter启动1万个线程，模拟5000个用户进行压测：优化前，可以看的吞吐量达到351.8优化后，可以看的吞吐量达到2242.73.5接口安全优化接口的安全优化主要的防止恶意用户的访问，以及减少瞬时用户的并发量接口隐藏由于前端的代码在浏览器，所以可以轻易的获取到核心业务的接口解决：地址是在客户端动态生成的，前端需要先获取地址信息，然后在发送给服务器，服务器会对浏览器的地址进行处理并和真实的地址进行比较数学问题验证码验证码主要防止机器人的大量访问，以及将用户的请求分散开，避免集中的下单解决：服务器生成验证码，通过前端输入进行验证接口防刷恶意用户可能会大量的访问服务器，给服务器造成压力解决：利用缓存，保存一定时间的访问数，如果超过一定限制，则直接拒绝访问四、项目实践中遇到的问题4.1秒杀成功商品订单数超过预订数值问题分析：该问题主要因为在高并发下，线程不安全导致的在判断是否秒杀成功时，多个用户通过了判断，然后才减少了库存问题解决：MySQL数据库在更新数据时，会自动加锁在SQL语句中减少库存时，判断库存是否大于0，如果不是则执行失败，订单回滚4.2一个用户的多个请求导致秒杀成功秒杀多次问题分析：由于采用的异步下单，在该用户订单没有完成时，则可能会出现一个用户同时下多个订单问题解决：设计数据库表时，多设计一个秒杀的订单，和普通的订单分离在秒杀订单上，user_id采用唯一索引4.3使用了缓存依然会大量访问数据库问题分析：由于为了简便，在Service上面统统加了@Transactional注解，会导致所有的方法启用事务此时即使使用了缓存，也依然会访问数据库，最终造成数据库压力过大问题解决：只在需要事务的方法上使用@Transactiona注解，提高性能五、接下来的优化思路静态资源优化CDN加速Nginx水平扩展","link":"https://xzzz2020.github.io/post/k_uLsJY6w/"},{"title":"贪心策略","content":"简介贪心的特点实际例子1.硬币支付问题2.小船渡河问题3.区间调度问题（二维数组排序）4.区间选点5.区间覆盖问题6.字典序最小问题7.乘船问题总结简介无论是DFS还是BFS都是遍历解空间动态规划和贪心算法都是一种递推算法，运用局部最优解来推到全局最优解是对遍历解空间的一种优化当问题具有最优子结构的时候，可以用动归，而贪心是动归的特例。贪心的特点只看眼前。根据某种规则，不断的选取当前策略，最终找到最优解主要需要不断的举例，去猜测出一个贪心策略。注意：当前最优的未必是整体最优实际例子1.硬币支付问题硬币问题有1元,5元,10元,50元,100元,500元的硬币各c1,c5,c10,c50,c100,c500枚.现在要用这些硬币来支付A元,最少需要多少枚硬币?假定本题至少存在一种支付方案.0≤ci≤10^90≤A≤10^9输入:第一行有六个数字,分别代表从小到大6种面值的硬币的个数第二行为A,代表需支付的A元样例:输入321302620输出6/***尽量先用大面值,因为不用大面值,将使用更多的小面值硬币,一定得不到最优解*/publicclassMain{staticint[]cin=newint[6];publicstaticvoidmain(String[]args)throwsInterruptedException{Scannerscanner=newScanner(System.in);intmoney;intans=0;for(inti=0;i&lt;6;i++){cin[i]=scanner.nextInt();}int[]coins=newint[]{1,5,10,50,100,500};money=scanner.nextInt();for(inti=5;i&gt;=0;i--){intx=money/coins[i];//金额有多少个coins[i]intt=Math.min(cin[i],x);//当前面值的硬币有cin[i]个ans+=t;money-=t*coins[i];}System.out.println(ans);}}2.小船渡河问题N个人过河，船每次最多只能坐两个人，船载每个人过河的所需时间不同，问最快的过河时间。有N个人要渡河，但是只有一艘船，船上每次最多只能载两个人，渡河的速度由两个人中较慢的那个决定，小船来回载人直到所有人都渡河，求最短的渡河时间。输入的每种情况的第一行包含N，第二行包含N个整数，表示每个人过河的时间。每个案例前面都有一个空行。不会有超过1000人，没有人会花超过100秒的时间穿越。对于每个测试用例，打印一行，其中包含所有N个人过河所需的总秒数。SampleInput1412510SampleOutput17可以发现，4个人以上时，前四轮都是将最慢的两个渡过河。publicclassCase02_POJ_1700{publicstaticvoidmain(String[]args){Scannersc=newScanner(System.in);intT=sc.nextInt();for(inti=0;i&lt;T;i++){intn=sc.nextInt();int[]speed=newint[n];for(intj=0;j&lt;n;j++){speed[j]=sc.nextInt();}//排序Arrays.sort(speed);f(n,speed);}}/***speed已经排序**@paramn*@paramspeed*/privatestaticvoidf(intn,int[]speed){intleft=n;intans=0;while(left&gt;0){if(left==1){//只有1人ans+=speed[0];break;}elseif(left==2){//只有两人ans+=speed[1];break;}elseif(left==3){//有三人ans+=speed[2]+speed[0]+speed[1];break;}else{//通过两种策略来回两趟，渡过最慢的两个人//1，2出发，1返回，最后两名出发，2返回ints1=speed[1]+speed[0]+speed[left-1]+speed[1];//1，3出发，1返回，1，4出发，1返回，1，2过河ints2=speed[left-1]+speed[left-2]+2*speed[0];ans+=Math.min(s1,s2);left-=2;//左侧是渡河的起点，left代表左侧的剩余人数}}System.out.println(ans);}3.区间调度问题（二维数组排序）有n项工作,每项工作分别在si时间开始,在ti时间结束.对于每项工作,你都可以选择参与与否.如果选择了参与,那么自始至终都必须全程参与.此外,参与工作的时间段不能重复(即使是开始的瞬间和结束的瞬间的重叠也是不允许的).你的目标是参与尽可能多的工作,那么最多能参与多少项工作呢?1≤n≤1000001≤si≤ti≤10^9输入:第一行:n第二行:n个整数空格隔开,代表n个工作的开始时间第三行:n个整数空格隔开,代表n个工作的结束时间样例输入:513168352910样例输出:3说明:选取工作1,3,5面向对象的排序思想：将不同的维度，比如说身高、体重、年龄，进行打包。将对象的一些操作打包到一起，操作可以直接影响数据。//贪心策略：选择结束时间最早的publicclassCase03_区间调度问题{publicstaticvoidmain(String[]args){Scannersc=newScanner(System.in);intn=sc.nextInt();int[]s=newint[n];int[]t=newint[n];//建立开始时间和终止时间的打包对象Job[]jobs=newJob[n];for(inti=0;i&lt;n;i++){s[i]=sc.nextInt();}for(inti=0;i&lt;n;i++){t[i]=sc.nextInt();}for(inti=0;i&lt;n;i++){jobs[i]=newJob(s[i],t[i]);}Arrays.sort(jobs);//此时数据按照终止时间和开始时间由小到大排序intres=f(n,jobs);System.out.println(res);}privatestaticintf(intn,Job[]jobs){intcnt=1;inty=jobs[0].t;//先选择最小的终止时间for(inti=0;i&lt;n;i++){//选择下一个终止时间最早的if(jobs[i].s&gt;y){cnt++;y=jobs[i].t;}}returncnt;}/***必须实现排序规则*/privatestaticclassJobimplementsComparable&lt;Job&gt;{ints;intt;publicJob(ints,intt){this.s=s;this.t=t;}//排序规则@OverridepublicintcompareTo(Jobother){intx=this.t-other.t;if(x==0)//如果终止的时间相同，则比较开始时间returnthis.s-other.s;elsereturnx;}}}4.区间选点题意:有n个如下形式的条件:aibici,表示在区间[ai,bi]内至少要选择ci个整数点.（不同区间内含的点可以是同一个）问你满足n个条件的情况下,最少需要选多少个点?SampleInput5373810368113110111SampleOutput6publicclassCase04_区间选点问题{publicstaticvoidmain(String[]args){Scannersc=newScanner(System.in);intn=sc.nextInt();Interval[]intervals=newInterval[n];for(inti=0;i&lt;n;i++){intervals[i]=newInterval(sc.nextInt(),sc.nextInt(),sc.nextInt());}Arrays.sort(intervals);//按区间右端点排序intmax=intervals[n-1].t;//右端最大值int[]axis=newint[max+1];//标记数轴上的点是否已经被选中for(inti=0;i&lt;n;i++){//1.查阅区间中有多少个点ints=intervals[i].s;//起点intt=intervals[i].t;//终点intcnt=sum(axis,s,t);//找到这个区间已经选点的数量，sums[t]-sums[s-1];//效率低//2.如果不够，从区间右端开始标记，遇标记过的就跳过intervals[i].c-=cnt;//需要新增的点的数量while(intervals[i].c&gt;0){if(axis[t]==0){//从区间终点开始选点axis[t]=1;//updateSums(t,sums);//更新前缀和intervals[i].c--;//进一步减少需要新增的点的数量t--;}else{//这个点已经被选过了，不选择重复的点t--;}}}System.out.println(sum(axis,0,max));}/***统计数轴axis上s-t区间已经有多少个点被选中*@paramaxis*@params*@paramt*@return*/privatestaticintsum(int[]axis,ints,intt){intsum=0;for(inti=s;i&lt;=t;i++){sum+=axis[i];}returnsum;}privatestaticclassIntervalimplementsComparable&lt;Interval&gt;{ints;//起点intt;//终点intc;//区间需求publicInterval(ints,intt,intc){this.s=s;this.t=t;this.c=c;}//按照终点由小到大排序@OverridepublicintcompareTo(Intervalother){intx=this.t-other.t;if(x==0)returnthis.s-other.s;elsereturnx;}}}5.区间覆盖问题如果给定一堆线段，给定一个区间，看最少需要几个线段才能完全覆盖这个区间。解决思路：设区间起点为start，终点为end，所需线段数目为ans首先线段中的终点，小于区间的起点，则该线段肯定无法覆盖同理如果区间的终点，大于线段的起点，则也一定无法覆盖接着就需要保存线段终点大于等于区间起点且线段起点小于等于区间终点的线段对上面的线段根据起点的大小排序接着此时的寻找线段起点小于start同时终点最远的线段，并该终点设置为新的start，将ans+1重复上述步骤直到找到终点大于end的题目：给出n条线段，以及最大长度m，问最少需要多少条才能覆盖1-m这个区间，当无法全部覆盖的时候输出-1SampleInput3101736610SampleOutput2publicclassCase05_区间覆盖问题{publicstaticvoidmain(String[]args){Scannersc=newScanner(System.in);intN=sc.nextInt();intT=sc.nextInt();Job[]jobs=newJob[N];for(inti=0;i&lt;N;i++){jobs[i]=newJob(sc.nextInt(),sc.nextInt());}Arrays.sort(jobs);intstart=1;//要覆盖的目标点，end覆盖该点的所有区间中右端点最右intend=1;intans=1;for(inti=0;i&lt;N;i++){ints=jobs[i].s;intt=jobs[i].t;if(i==0&amp;&amp;s&gt;1)break;//第一个起点比区间起点小，则一定无法覆盖if(s&lt;=start){//当前区间有可能覆盖startend=Math.max(t,end);//寻找起点小于start同时终点最远的线段}else{//说明已经没有线段再比start小，开始下一个区间ans++;//上一个目标覆盖已经达成，计数加1start=end+1;//更新起点，设置一个新的覆盖目标if(s&lt;=start){end=Math.max(t,end);}else{//当前的起点如果比end大，则后面的都一定大，无法继续覆盖break;}}if(end&gt;=T){//当前的end超越了线段的右侧，则不需要继续判断了break;}}if(end&lt;T)//如果没有覆盖System.out.println(-1);elseSystem.out.println(ans);}privatestaticclassJobimplementsComparable&lt;Job&gt;{ints;intt;publicJob(ints,intt){this.s=s;this.t=t;}/**按照区间起点排序*/@OverridepublicintcompareTo(Jobother){intx=this.s-other.s;if(x==0)returnthis.t-other.t;elsereturnx;}}}6.字典序最小问题字典序最小问题给一个定长为N的字符串S,构造一个字符串T,长度也为N。起初，T是一个空串，随后反复进行下列任意操作从S的头部删除一个字符，加到T的尾部从S的尾部删除一个字符，加到T的尾部目标是最后生成的字符串T的字典序尽可能小1≤N≤2000字符串S只包含大写英文字母输入：字符串S输出：字符串TpublicclassCase06_字典序最小问题{publicstaticvoidmain(String[]args){Scannersc=newScanner(System.in);intN=sc.nextInt();StringBuilderss=newStringBuilder();//字符输入小技巧for(inti=0;i&lt;N;i++){ss.append(sc.next());}//Strings=sc.nextLine();f(ss.toString());}privatestaticvoidf(Strings){Strings1=newStringBuilder(s).reverse().toString();//字符串翻转，intN=s.length();StringBuilderrs=newStringBuilder();while(rs.length()&lt;N){//这样就可以直接比较两个字符串的头，相当于一个取头一个取尾if(s.compareTo(s1)&lt;=0){//这是个字符串字典比较的小技巧rs.append(s.charAt(0));s=s.substring(1);}else{rs.append(s1.charAt(0));s1=s1.substring(1);}}}7.乘船问题有n个人，第i个人重量为wi。每艘船的最大载重量均为C，且最多只能乘两个人。用最少的船装载所有人。贪心策略：考虑最轻的人i，如果每个人都无法和他一起坐船（重量和超过C），则唯一的方案是每个人坐一艘否则，他应该选择能和他一起坐船的人中最重的一个j求需要船的数量publicclassCase07_乘船问题{publicstaticvoidmain(String[]args){int[]w={1,2,3,4,5,6,7,8,9,10};intn=w.length;intc=10;Arrays.sort(w);intcntOfPerson=n;intcntOfBoat=0;intp1=0;intp2=n-1;while(cntOfPerson&gt;0){if(p1+p2&gt;c){//如果最大的和当前最小的不能在一艘船，则一定需要自己一艘船p2--;cntOfPerson--;cntOfBoat++;}else{p1++;p2--;cntOfPerson-=2;cntOfBoat++;}}System.out.println(cntOfBoat);}}总结本质是一种DFS的剪枝法选择的是当下最优的策略","link":"https://xzzz2020.github.io/post/-Soxdr6Ou/"},{"title":"第七章操作系统接口","content":"命令接口实现系统调用命令接口实现分为下图所示的两个模块实现：终端处理程序，接收键盘的输入，并将命令执行的结果回显在显示器上，功能包括：字符接收字符缓冲回送显示屏幕编辑特殊字符的处理命令解释程序，从.输入缓冲区中取出数据，然后识别命令、执行命令,最后把结果放到输出缓冲区中。系统调用什么是系统调用？系统调用是操作系统提供给应用程序的一-种过程调用，保护操作系统程序不被用户，程序破坏。系统调用是操作系统的程序接口。系统调用与一般的过程调用不同：系统调用处理程序运行在内核态，而一般的过程调用运行在用户态;系统调用需要借助软中断实现，而--般过程调用不需要;系统调用从内核返回时，要进行决策是否运行调度算法，而一般过程调用不需要;系统调用可以嵌套调用，但调用深度有一定的限制，而一般过程调用没有深度限制;","link":"https://xzzz2020.github.io/post/KpZgrFFRY/"},{"title":"第六章文件管理","content":"文件及其逻辑结构顺序文件索引文件索引顺序文件直接文件和哈希文件目录的要求文件的物理结构（***）连续分配链接分配索引分配空闲空间管理空闲表法空闲链表法位视图法（***）成组链表法文件系统软件模型对象及其属性对对象操纵和管理的软件集合文件系统接口文件共享课本习题题目练习文件及其逻辑结构文件概念：由创建者所定义、具有文件名的一组相关元素的集合，可分为结构文件和无结构文件两种。文件逻辑结构概念：文件的逻辑结构是从用户观点出发所观察到的文件组织形式，是用户可以直接处理的数据及其结构，它独立于文件的物理特性，又称为文件组织。顺序文件顺序文件由数据依次排列组成。顺序文件可分为串结构文件和有序结构文件。、串结构文件按记录存入文件的时间先后排列。有序结构按关键字值大小排列。顺序文件又分为定长记录文件和变长记录文件。索引文件若顺序文件是变长记录文件，可按记录号或关键字为每条记录建立一个索引文件，存储记录在顺序文件中的位置信息。索引文件是定长的文件。索引顺序文件索引文件太长会要求更多的I/O次数，直接影响了文件的读/写效率。索引顺序文件先对顺序文件按记录号或关键字排序分组，然后对组的第一个记录索引。直接文件和哈希文件直接文件是一种特殊的哈希文件,记录关键字值决定了记录在顺序文件中的位置。哈希文件则由关键字值通过哈希函数计算获得记录在顺序文件中的位置。目录的要求实现“按名存取”。提高对目录的检索速度。文件共享。允许文件重名。文件的物理结构（***）概念：文件的物理结构指文件的外存分配组织管理方式文件占用的外存空间以块或簇等逻辑单位计量连续分配文件数据连续存储可以提高存取速度，但限制了文件动态增长。链接分配隐式链接，链接指针包含在给文件分配的块中，目录中仅包含文件的起始块和结束块(或长度)。链接指针分散在多个块中，不利于安全措施的实现显示链接：将所有的链接信息提取放到文件分配表中索引分配在链接分配中，文件块链接指针离散存储,造成文件占用块号解析效率不高。索引分配方式就是将块号集中存放。单级索引（一级索引）用一个块来记录文件占用的所有块号,我们称之为索引块二级索引因为一个索引块的大小有限，但是多级索引需要检索多次，会影响性能混合索引(直接地址、-级索引、两级索引、三级索引方式)空闲空间管理空闲表法若干连续的空闲块组合成一个空闲区。空闲表法将所有的空闲区记录在一张表里，包括项号、起始空闲块号、空闲块数等。空闲链表法空闲链表法是以空闲块或空闲区为结点构成一个链表结构。位视图法（***）用一位二进制表示，1代表已分配，0代表空闲。块号从0开始，BitsOfLine是一行有多少位，如char类型为8位block=lineXBitsOfLine+columnline=block/BitsOfLinecolumn=block%BitsOfLine成组链表法用树的结构表示文件系统软件模型对象及其属性文件系统对象超级块对象文件目录索引结点数据块对对象操纵和管理的软件集合对文件的读/写对目录文件的读/写对磁盘空闲空间的管理将文件的逻辑地址转换为物理地址对文件的保护与共享;文件系统接口基于文件名(路径)、文件逻辑地址(相对于文件起始地址的偏移)给用户提供各种操作。常用的文件操作有，创建文件、删除文件、读文件、写文件、设置文件读1写位置、打开文件、关闭文件等。文件共享基于索引结点的共享方式基于符号链的共享方式课本习题11在UNIX中，如果一个盘块的大小为1KB，每个盘块号占4个字节，即每块可放256个地址。请转换下列文件的字节偏移量为物理地址。⑴9999；⑵18000；⑶420000答：首先将逻辑文件的字节偏移量转换为逻辑块号和块内偏移量,就是将[字节偏移量]/[盘块大小]，商为逻辑块号，余数是块内偏移量。在FCB中，第0-9个地址为直接地址，第10个为一次间接地址，第11个地址为二次间接地址，第12个地址为三次间接地址。再将文件的逻辑块号转换为物理块号。使用多重索引结构，在索引节点中根据逻辑块号通过直接索引或间接索引找到对应的物理块号。9999/1024=9余783，则逻辑块号为9，直接索引第9个地址得到物理块号，块内偏移地址为783。18000/1024=17余592，则逻辑块号为10&lt;17&lt;10+256，通过一次间接索引在第10个地址可得到物理块号，块内偏移地址为592。420000/1024=410余160，则逻辑块号为10+256&lt;410，通过二次间接索引在第11个地址可得到一次间址，再由此得到二次间址，再找到物理块号，其块内偏移地址160。某操作系统磁盘文件空间共500块，若用字长为32位的位示图管理磁盘空间，试问：（1）位示图需要多少字？（2）第i字第j位对应的块号是多少？（3）给出申请/归还一块的工作流程。答：（1）位示图需要的字数计算：INT（500/32）=16个字。（2）块号b=(i-1)*32+j（3）申请的过程：顺序扫描位示图、找到空闲块并分配、修改位示图map[i,j]=1。归还的过程：找到回收盘块在位示图中的行和列，修改位示图map[i,j]=0。题目练习","link":"https://xzzz2020.github.io/post/7ZUXXwU1m/"},{"title":"第五章设备管理","content":"设备分类I/O设备控制方式程序查询方式通道控制方式DMA方式（直接存储器访问方式）中断方式I/O系统的软件模型及功能设备独立性软件Spooling缓冲管理四种缓冲策略设备分配磁盘调度算法（会计算***）先来先服务最短寻道时间扫描算法（电梯调度算法）循环扫描算法题目练习设备分类按信息交换单位分类：块设备：数据传送以块为单位，传输速率较高，可寻址;I/O访问常采用DMA方式。字符设备：数据传送以字符为单位，传输速率较低，不可寻址;I/0访问常采用中断方式。按设备的的共享属性分类：独占设备：一段时间内只允许一个进程使用，属于临界资源。共享设备：在一-段时间，允许多个进程同时访问，共享设备必须是可寻址和可随机访问的设备。虚拟设备：将一台独占设备变换为若干个逻辑设备,如虚拟存储器、虚拟终端。I/O设备控制方式程序查询方式不停的检查设备的状态，造成CPU资源的浪费，优点是比较简单通道控制方式通道程序由一系列通道指令构成，包含以下信息：操作码：读、写、控制等;内存地址：读写内存的始址;计数：指令的读写字节数;通道程序示例：通道程序结束位P，1表示通道指令是通道程序的最后一条指令。记录结束位Record,0表示通道指令与下一条通道指令所处理的数据块属于同--个记录，1表示通道指令所处理的数据块是记录的最后一块数据。DMA方式（直接存储器访问方式）DMA方式以块为单位传送数据，仅在数据块传送前和传送结束时,才需要处理机干预。包含四类寄存器：数据寄存器：缓存从设备到内存，或从内存到设备的数据;数据计数寄存器：存储要读/写的字节数;内存地址寄存器：存放内存起始地址;.控制/状态寄存器：接收处理机发来的1/O命令或有关控制信息，以及设备发送的状态信息;中断方式驱动程序向处理机发出启动I/O设备指令后阻塞，处理机转向处理其它工作。设备完成数据传送后，I/O控制器向处理机发送中断请求。处理机收到中断请求信号转向中断处理程序，中断处理程序将数据寄存器中的数据送到指定内存单元，并唤醒阻塞进程。I/O系统的软件模型及功能设备独立性软件设备独立性指应用程序独立于具体使用的物理设备。为了实现设备独立性而引入了逻辑设备和物理设备概念，在应用程序中，使用逻辑设备名来请求使用某类设备，而系统在实际执行时，还必须使用物理设备名称。设备独立性软件的功能：向用户层(或文件层)软件提供统一接口。执行设备的公有操作，如逻辑设备名映射为物理设备名、独立设备的分配与回收、对设备进行保护、缓冲管理、差错控制、提供独立于物理设备的逻辑块。设备独立性实现：构建一个逻辑设备表，实现逻辑设备名到物理设备名的映射Spooling在联机情况下实现的同时输入/输出操作称为Spooling，或称为假脱机操作,即数据的输入、输出不再由外围控制机管理,而改为进程执行。Spooling系统的组成：输入进程SPi和输出进程SPo输入和输出缓冲区输入和输出井Spooling系统应用--共享打印机：将所有打印请求挂在打印机请求队列上。把打印数据放入到输出井上。打印机驱动进程依次完成打印机请求队列上的任务。Spooling系统的特点：提高了I/O速度。将独占设备改造成共享设备。实现了设备的虚拟化。缓冲管理目的：减少低速设备对高速的干扰。四种缓冲策略1.单缓冲由于处理机与I/O设备的并行性，用户进程对一块缓冲区数据的处理时间等价于Max(C，T)+M。需要注意的是传送和计算或输入无法同时计算此时生产者是设备，消费者是用户进程，生产者和消费者都只有一个，不存在互斥2.双缓冲数据被采集到缓冲区和数据从缓冲区传送到用户进程空间再被计算可以并行执行;用户进程对一块缓冲区数据的处理时间等价于Max(C、T);如果C&gt;T,则CPU可以连续地工作;如果C&lt;T,则I/0设备可以连续地工作;双缓冲适用于I/O设备与用户进程速度基本匹配的场合;此时设备输入数据和用户进程取数据可以同时进行3.循环缓冲适用于I/O设备与用户进程速度差异较大的场合循环缓冲的使用：GetBuf过程，从循环缓冲中获取一个满缓冲区或一个空缓冲区;ReleaseBuf过程，向循环缓冲中释放一个空缓冲区或一个满缓冲区;4.缓冲池（***）三种缓冲队列空缓冲队列emq输入缓冲队列inq,装满输入数据输出缓冲队列outq,装满输出数据四种缓冲区收容输入数据缓冲区hin提取输入数据缓冲区sin收容输出数据缓冲区hout提取输出数据缓冲区sout设备分配安全分配：进程发出I/0请求后，便进入阻塞状态,直到I/O操作完成时才被唤醒。摒弃&quot;请求和保持”死锁必要条件之一，缺点是进程进展缓慢。不安全分配：进程发出I/O请求后仍继续运行，需要时又发出第二C个、第三个I/O请求等，效率高，缺点是可能造成死锁。磁盘调度算法（会计算***）注意：每次寻道都会改变当前所在磁道先来先服务按照请求顺序进行寻道最短寻道时间每次寻找离当前磁道最近的请求，会导致饥饿现象，默写请求可能很久都难以调度扫描算法（电梯调度算法）磁头可以朝着增加的方向移动也会朝着减少的方向移动，可以避免饥饿现象的发生先寻找离当前磁头最近的磁道且需要比当前磁道大当不存在比当前磁道更大的时候，磁头需要调转方向，朝着减少的方向移动.循环扫描算法改进：当移动到不存在比当前磁道更大的时候，不再调转方向，从0开始继续寻找题目练习","link":"https://xzzz2020.github.io/post/mxhiqNcFj/"},{"title":"第四章存储器管理","content":"程序的链接与装入程序的装入程序的链接连续存储分配方式单一连续分配固定分区分配方式动态分区分配（***）基本分页存储管理方式页表地址变换机构（***）基本分段存储管理方式段表地址变换机构（***）分页和分段的主要区别虚拟存储器（***）虚拟存储器实现方法的硬件支持分页请求系统分段请求系统页面置换算法（***）最佳置换算法（理想化）先进先出页面置换算法最近最久未使用置换算法（LRU）clock置换算法简单clock置换算法（最近未访问页面置换算法）改进型clock置换算法最近最少未使用（LFU）练习题目程序的链接与装入程序的装入目的：是将代码装入内存准备执行绝对装入方式可重定位装入方式：动态运行时的装入方式：增加一个重定位寄存器，通过硬件完成地址的修正。真实地址等于逻辑地址+重定位寄存器上的地址程序的链接目的：将目标模块相对独立的地址空间合并成一个地址空间。​静态链接方式对相对地址进行修改变换外部调用符号装入时动态链接运行时动态链接连续存储分配方式目的：给每一个程序分配一片连续的存储空间，容量为程序运行时所需的最大空间。指标：碎片率，越小越好。单一连续分配内存分为系统区和用户区用户区一次只能装入一个程序运行系统区装入操作系统固定分区分配方式将内存划分成固定数目的区域，如图所示：为了实现内存的管理，需要建立固定分区表（数组实现）：程序的大小和分区大小不能完全匹配，所以需要分配大于等于程序大小的内存，分区中浪费的空间称为内碎片动态分区分配（***）操作系统不预设固定数目分区，按照程序内存需求为其划分，内存中分区数目动态变化。数据结构：分配算法：首次适应算法：空闲分区以地址递增的顺序排列，每次从链首开始顺序查找，直到找到一个大小能满足要求的空闲分区为止。然后再按照程序的要求大小，从该空闲分区中划分出一块内存空间给请求者，余下的空闲部分仍留在空闲链表中。特点是低端或高端地址空间被频繁使用。循环首次适应算法：在首次适应算法的基础上，每次查找时从上次找到空闲分区的下一个空闲分区开始查找。特点是空闲分区使用均匀，但是会缺乏大的空闲分区。最佳适应算法：能满足要求、又是最小的空闲分区分配给作业，避免&quot;大材小用”。特点:分区按照大小顺序排列。最差适应算法：每次从空闲分区中选择最大的空闲分区分配给程序，以便切割剩余的空闲分区空间更大。切割操作会产生一些空间过小，总是不会分配给程序，这些空间被称作外碎片。###可重定位分区分配紧凑：通过移动程序，将外碎片合并一个大的空闲分区基本分页存储管理方式离散分配的基本单位是页页表解决了逻辑地址到物理地址的转换的问题：将程序逻辑地址空间划分成固定大小的页面;内存划分成等大小的页框;页表实现页面到页框的索引;页表项个数由程序的逻辑地址空间决定，页表项位数由页框起始物理地址位数决定。记录了页面和页框号（每个页框的起始地址）的对应关系，如下图所示：页表存储了页框的起始物理地址，需要一个连续的存储空间实现随机访问，对于逻辑地址相当于页号+页内偏移。地址变换机构（***）先让页号与页表基址相加得到页框号再让页框号与页内偏移相加得到物理地址基本分段存储管理方式离散分配的基本单位是端采用二维逻辑地址结构，由段号加段内偏移构成段表地址变换机构（***）分页和分段的主要区别页是信息的物理单位；段是信息的逻辑单位。页大小固定；段大小不固定。分页采用一维线性逻辑地址，分段采用二维逻辑地址。虚拟存储器（***）概念：虚拟存储器是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器，其逻辑容量由内存容量和外存容量之和决定，运行速度接近于内存速度,每位成本接近外存。虚拟存储器实现方法的硬件支持分页请求系统请求分页的页表机制缺页中断机构地址变换机构分段请求系统请求分段的端表机制缺段中断机构地址变换机构页面置换算法（***）页面中断：发生页面的置换最佳置换算法（理想化）置换以后永不使用或者最长时间不使用的页面发生3次缺页中断和页面中断先进先出页面置换算法淘汰最先进入的页面，即选择在内存中驻留时间最久的页面予以淘汰。最近最久未使用置换算法（LRU）选择最近最久未使用的页面予以淘汰，即当前使用次数最少的页面。实现方式：利用栈保存当前使用的各个页面的页面号,每当进程访问某页面时，便将该页面的页面号从栈中弹出，并将它压入栈顶。因此，栈底是最近最久未使用的页面。使用寄存器，每一次访问都会在寄存器加一，每次置换选择寄存器中次数最少的页面clock置换算法简单clock置换算法（最近未访问页面置换算法）将所有的页面组成一个循环链表,并为每个页面添加一个访问位A。当一个页面被访问时，将其A位设置为1。置换过程是从pointer开始，若该页面的A位为1,将其设置为0,并使pointer指向下一个页面，直到找到A位为0的页面;若该页面的A位为0，则将其置换出内存，并用换入的页面占用换出页面的页框，使pointer指向下一个页面。如果第一轮没有找到，则执行第二轮，由于第一轮将所有页面的A都设置为0，则一定能在第二轮找到改进型clock置换算法增加一个修改为M，页面状态可以分为四类：1类(A=0，M=0)，未访问未修改;2类(A=0，M=1)，未访问.已修改;3类(A=1，M=0)，已访问未修改;4类(A=1,M=1)，已访问已修改;置换过程：从pointer开始寻找1类页面，直到找到1类页面结束，或者扫描完一遍进入第II步。从pointer开始寻找2类页面，直到找到2类页面结束，或者扫描完一遍进入第I步。在本步每扫描完一个页面，须将页面的访问位修改为0。重复l和II。(一定可以找到置换的页。)最近最少未使用（LFU）在最近时期内选择使用次数最少的页面作为淘汰页练习题目","link":"https://xzzz2020.github.io/post/HB2L7VswF/"},{"title":"第三章进程同步与死锁","content":"进程同步信号量整型信号量记录性信号量（***）AND型信号量信号量的应用（***）利用信号量实现互斥利用信号量实现前驱关系资源的分配同步的问题进程间通信死锁的相关概念处理死锁的基本方法预防死锁避免死锁（***）银行家算法（***）检测死锁解除死锁练习题目进程同步临界资源：对一些硬件而言，打印机就是一个临界资源，即多个程序共同需要抢占的资源临界区：每个进程中访问临界资源的代码实现互斥的结构：硬件实现：关中断：让处理机始终执行一个程序，不进行程序的切换指令同步应该遵循的规则：空闲让进：当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。忙则等待：当有进程进入临界区时，表明临界资源正在被访问，因而其他试图进入临界区的进程必须等待，以保证对临界资源的互斥访问。有限等待：对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区，以免陷入“死等”状态。让权等待：当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等&quot;前驱图：若想执行S2，则需要先执行S1。信号量整型信号量记录性信号量（***）AND型信号量信号量的应用（***）利用信号量实现互斥实现算法：符合：空闲让进，忙则等待和有限等待利用信号量实现前驱关系资源的分配申请资源时需要执行P操作，释放资源时执行V操作同步的问题生产者-消费者问题哲学家进餐问题读者-写者问题进程间通信低级通信：信号量机制高级通讯：共享存储器系统、消息传递系统、管道通信。死锁的相关概念可抢占资源：某进程在获得该资源后，该资源可以再被其他进程或系统抢占。不可抢占的资源：一旦系统将某资源分配给该进程后，就不能将它强行收回，只能在进程用完后自行释放。死锁的定义：如果一组进程中的每个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程就是死锁。产生死锁的原因：竞争不可抢占资源引发死锁。竞争可消耗资源引发死锁。进程推进顺序不当引发死锁。处理死锁的基本方法预防死锁破坏“请求和保持条件”破坏“不可抢占条件”破坏“循环等待条件”：进程统一按照某种线性规则申请资源。例如,输入机资源序号为1,打印机序号为2，磁带机资源序号为3,磁盘资源序号为4，进程在申请资源时，必须按照从1到4或者从4到1的顺序申请。避免死锁（***）安全状态：安全状态，是指系统能按某种顺序(P1,P2,Pn)(称此序列为安全序列)，来为每个进程Pi分配其所需的资源,直到满足每个进程对资源的最大需求，使每个进程都可以顺利地完成。不安全状态：如果系统无法找到这样一个安全序列，称系统处于不安全状态。要避免死锁，需要使系统处于安全状态；系统处于不安全状态，并不一定处于死锁状态根据上述定义，当给P1分配2个资源时，则此时P1、P2和P3都无法满足最大需求，处于不安全状态银行家算法（***）先假设分配可以满足，做一次安全检测，如果仍能处于安全状态，则允许分配。寻找安全序列的方式只有两种：每次都从最上面开始；按照从上到下顺序循环应用：如果单向顺序，查找安全序列的流程为：判断P0，返现剩余资源不能满足。判断P1，发现满足，则释放P1分配的资源，此时资源是：5，3，2。继续判断P0，返现剩余资源不能满足。P1结束，则直接跳过。判断P2，返现剩余资源不能满足。判断P3，发现满足，则释放P3分配的资源，此时资源是：7，4，3。继续判断P0，发现满足，则释放P0分配的资源，此时资源是：7，5，3。P0、P1结束，直接跳过。判断P2，发现满足，则释放P2分配的资源，此时资源是：10，5，5.。P0、P1、P2、P3结束，直接跳过。判断P4，发现满足，则释放P4分配的资源。最终的安全序列为：P1、P3、P0、P2、P4。确认分配。此时找不到安全序列，拒绝分配。检测死锁解除死锁练习题目","link":"https://xzzz2020.github.io/post/vUwZiOAP9/"},{"title":"第二章处理机管理","content":"程序的执行方式顺序方式（*）并发执行（***）并行执行进程进程的特征进程的状态进程控制块（PCB）进程控制进程的四个操作进程的创建进程的终止进程的阻塞和进程的唤醒进程调度概念进程调度的方式衡量调度算法指标进程调度算法（计算***）先来先服务调度算法（***）短作业优先调度算法（***）高优先权调度算法（***）高响应比优先调度算法时间片轮转调度算法（***）多级队列调度算法多级反馈队列调度算法线程题目练习程序的执行方式顺序方式（*）内存中只能驻留一个程序，前一个程序结束，后一个程序才能进来，并且有着严格的先后次序顺序执行的特点：顺序性：程序执行有着明确的先后顺序封闭性：程序运行时独占所有资源可再现性：初始条件相同，若程序执行顺序不变，则每次得到的结果一定相同问题：无法满足高性能并发执行（***）并发指一段时间内执行多个程序。多个程序同时进入内存，轮流交替执行。并发执行的特点：间断性：交替执行就是走走停停失去了封闭性：程序不再独占系统资源不可再现性：程序执行有多种结果。并行执行同一时刻有多个程序执行，只能在多处理机上实现进程进程是研究并发方式下，程序的执行。进程的概念：进程是进程实体的运行过程，是系统进行资源分配和调度的一一个独立单位。进程实体：由程序段、相关数据段和PCB组成进程的特征并发性，多个进程在一段时间内同存于内存中同时运行动态性，进程由创建而产生，由调度而执行，由撤消而消亡。独立性，进程是能独立运行、资源分配、调度的基本单位。结构性，进程映像由程序、数据、栈和进程控制块(PCB)构成。异步性，进程按各自独立、不可预知的速度向前推进。进程的状态有三个状态：就绪状态：指程序已经处于准备好运行的状态。执行状态：指程序已经获得CPU，正在执行。阻塞状态：指程序的执行因为某些原因无法继续执行。进程控制块（PCB）用来描述进程的基本情况和活动过程，进而控制和管理进程。（类似于学籍、户口等）进程创建时会建立一个PCB，结束时会收回PCB进程控制块中的信息：进程标识符：包括内部标识符和外部标识符。处理机状态：处理机状态包括通用寄存器、程序计数寄存器、程序状态寄存器、栈寄存器信息。进程控制信息：程序栈和数据地址，同步和通信机制，资源清单,链接指针。进程调度信息进程控制块中的组织方式线性方式链接方式索引方式进程控制进程控制用于创建、终止、阻塞和唤醒进程。进程控制由操作系统内核原语来实现。原语是由若干条指令组成，用于完成一定功能的一个过程，所有的指令要么全做，要么全不做。（一个函数）用户态：具有较低特权的执行状态，进行执行规定的指令，访问特定的寄存器和存储区。系统态（内核态）：具有较高特权，能执行全部的指令，访问所有的寄存器和存储区。进程的四个操作进程的创建引起进程创建的事件：用户执行应用程序。用户登录。启动服务。程序创建进程。进程创建的过程（必须要求是原语）：申请空白PCB为新进程分配资源，如内存空间等初始化PCB将进程插入就绪队列进程的终止引起进程终止的事件：正常结束。异常结束。外界干预。进程的终止过程：检查进程状态。有无子孙需要终止。归还进程全部资源。将PCB从进程中移除。进程的阻塞和进程的唤醒进程调度概念处理机调度的层次：高级调度低级调度中级调度引起进程调度的事件：进程终止。进程创建。进程阻塞。进程唤醒。外部设备中断。进程切换时需要保存和恢复现场。进程调度的方式抢占式调度：允许调度程序根据某种原则，暂停某个占用处理机的进程，抢占已经分配出去的处理机。抢占的原则有优先权原则、短作业优先原则和时间片原则。非抢占式调度：进程一旦获得处理机，只有在该进程任务完成或因某事件而阻塞时，才让出处理机，决不允许某进程抢占已经分配出去的处理机。（只有时间片用完才能调度）衡量调度算法指标面向用户（***）：平均周转时间：所有周转时间求平均。带权周转时间：一个程序的周转时间除以服务的时间。（&gt;=1）平均带权周转时间：对带权周转时间求平均。周转时间：从作业被提交给系统开始，到作业完成为止的这段时间间隔。面向系统：吞吐量：在单位时间内系统所完成的作业数。处理机利用率：在过去一段时间内CPU被占用的时间总和。各类资源的平衡利用率：保证系统所有的资源被合理利用。进程调度算法（计算***）先来先服务调度算法（***）先来的进程先抢到CPU，有利于长作业，不利于短作业短作业优先调度算法（***）在分配时，优先分配给服务时间最短的，降低了系统的平均周转时间，对长作业不利。只有在抢占的时候，进程的创建才会导致需要重新分配CPU，非抢占式在进程终止的时候分配。非抢占方式：抢占式：高优先权调度算法（***）按照优先权重分配CPU，优先数越小，优先权越大高响应比优先调度算法按照响应比去分配CPU资源，既考虑的作业的先后顺序，又优先照顾短作业，同时不会使长作业等太久响应比=等待时间/服务时间时间片轮转调度算法（***）按照先来先服务的将作业放入一个调度队列中，每隔一定的时间片，发生一次调度，一般为10ms到100ms。假设时间片为2。多级队列调度算法优先调度优先级高的多级反馈队列调度算法解决了低优先级队列长时间无法调度的问题线程为什么提出线程？进程是资源的拥有者，在并发时，对进程的切换需要有较大时空的开销。一个进程内全部线程都是在同一个地址空间进行，在并发时可以减少系统的开销。线程概念：线程是进程的一个实体，是被系统独立调度的基本单位，只拥有少量的资源(如CPU寄存器资源)。如下图所示，每个线程都会有个栈，一共有三个线程：线程的特点：一个线程拥有少量的资源，记录在线程控制块中。轻型实体，线程基本上不拥有资源，或者是有较少的资源;一个进程的所有线程共享进程所拥有的全部资源。线程是处理机调度的基本单位，多个线程可以并发执行。线程与进程的比较：线程的实现方式：内核级线程：所有创建、切换等都需要内核的支持，开销较大（适合多处理器系统）用户级线程：可以不需要进入内核态创建，但是切换进程需要进入内核（开销小）组合方式：建立内核级线程与用户级线程的关系。题目练习","link":"https://xzzz2020.github.io/post/IyZhCzd1C/"},{"title":"第一章操作系统引论","content":"操作系统发展操作系统的功能处理机管理存储器管理（内存）设备管理（高效使用IO设备）文件管理操作系统接口操作系统的基本特征操作系统的作用设计目标操作系统结构练习题目操作系统发展无操作系统单道批处理系统多道批处理系统：多个程序交替使用CPU，目的是提高CPU的利用率分时系统：使用户以交互的方式共享计算机，用户感觉到自己在享用到计算机资源，本质还是利用了时分复用技术实时系统：在规定的时间开始事件的处理或者在规定时间内完成对事件的处理，对时间要求苛刻操作系统的功能处理机管理进程控制进程调度进程同步进程通信死锁存储器管理（内存）内存分配内存共享内存扩充内存保护设备管理（高效使用IO设备）设备处理缓冲管理设备分配设备的独立性设备的虚拟性文件管理文件读/写目录管理存储空间管理文件共享、存储性能优化、存储可靠性和数据一致性操作系统接口图形接口系统调用命令调用​操作系统的基本特征并发性：多个程序在同一时间间隔执行共享性：多个并发的程序共同使用计算机资源，提高计算机资源的利用率虚拟性：有时分复用和空分复用两种技术异步性：表现为多任务执行的无序性，主要应对阻塞操作系统的作用操作系统(OperatingSystem,OS)是一组控制和管理计算机硬件和软件资源，合理地对各类作业进行调度，以及方便用户使用的程序集合。是用户和计算机系统之间的接口是系统资源的管理者扩充计算机的功能，实现对计算机的抽象设计目标方便性有效性扩充性开放性操作系统结构无操作系统结构模块化结构层次结构微内核结构练习题目","link":"https://xzzz2020.github.io/post/ZBrN48x_g/"},{"title":"2020最新-Java学习目录","content":"学习的知识体系图片太大，直接奉上链接，可以自己保存到电脑上：https://blog.csdn.net/qq_43040688/article/details/105819866这些全部都是博主学习时记录的一些笔记，手上也有学习时使用的相关的网课资源或者是课本资源，感觉讲的都很不错，资料也很全。一.数据库1.1关系型数据库MySQL(已更新)推荐书目：《MySQL必知必会》、《MySQL技术内幕》、《高性能MySQL》对于MySQL语法优先学习SQL的语句增删改查等，然后在LeetCode练习一下数据库的题目，可能会手写SQL语句SQL语句学习链接基础部分https://blog.csdn.net/qq_43040688/article/details/105346357重点部分https://blog.csdn.net/qq_43040688/article/details/105348610扩展部分https://blog.csdn.net/qq_43040688/article/details/105381801接着需要重点学习索引、锁、事务、SQL优化以及MySQL的架构SQL高级部分链接MySQL体系结构和存储引擎介绍https://blog.csdn.net/qq_43040688/article/details/105393816InnoDB存储引擎https://blog.csdn.net/qq_43040688/article/details/105415093MySQL索引https://blog.csdn.net/qq_43040688/article/details/105419053MySQL创建高性能的索引https://blog.csdn.net/qq_43040688/article/details/105454477MySQL查询性能优化https://blog.csdn.net/qq_43040688/article/details/105456790MySQL锁https://blog.csdn.net/qq_43040688/article/details/105440448MySQL事务https://blog.csdn.net/qq_43040688/article/details/105441274MySQL备份https://blog.csdn.net/qq_43040688/article/details/105441944MySQL架构https://blog.csdn.net/qq_43040688/article/details/105450005MySQL高级特性https://blog.csdn.net/qq_43040688/article/details/105465192分库分表的高频面试题https://blog.csdn.net/qq_43040688/article/details/1055946531.2非关系型数据库Redis二、Java基础2.1Java虚拟机（已更新）虛拟机推荐《深入理解Java虚拟机》这本书，重点学习一下内存、垃圾回收、类加载机制这几部分内容。JVM内存结构链接JVM简介https://blog.csdn.net/qq_43040688/article/details/104964070程序计数器和虚拟机栈https://blog.csdn.net/qq_43040688/article/details/104970081本地方法栈和堆https://blog.csdn.net/qq_43040688/article/details/104972811方法区https://blog.csdn.net/qq_43040688/article/details/104982648直接内存https://blog.csdn.net/qq_43040688/article/details/1049960322.2Java并发（已更新）Java并发主要看了汪文君的并发三个阶段，内容比较丰富，看了很久Java并发基础学习Java并发，需要先掌握线程的一些基础知识这些基础知识的组合构成了后面的设计模式首先应该了解如何启动一个多线程，即使用Runnable、Callable、Thread；还需要了解线程启动后的生命周期，了解了不用实现方式的差别，最重要的研读Thread的源码，详情参考：Java多线程起步，Thread构造函数源码分析需要学习Thread常用API以及三种关闭线程的方式，详情参考：Thread的API需要了解this锁和class锁，详情参考：Java多线程之认识“锁”需要了解线程间的通讯，最基本的就是消费者和生产者模型，需要深入了解了wait、sleep、notify、nitifyAll的机制和差异，对于waitset要有个清晰的认识，详情参考：Java多线程之线程间的通讯需要尝试自定义了一个Boolean锁，了解了加锁和释放锁的过程，实现了获取正在阻塞的线程；需要了解线程运行时出现异常的处理方式，详情参考：自定义Boolean锁&amp;捕获线程中的异常需要学习了线程组的概念以及常用API，如interrupt，setDaemon，activeCount，enumerate，详情参考：线程组需要自定义了一个线程池，对线程池的处理机制有了较深的理解，详情参考：自定义线程池Java并发基础链接Java多线程起步https://blog.csdn.net/qq_43040688/article/details/103979628Thread构造函数源码分析https://blog.csdn.net/qq_43040688/article/details/105543926Thread的APIhttps://blog.csdn.net/qq_43040688/article/details/105747547Java多线程之认识“锁”https://blog.csdn.net/qq_43040688/article/details/105752943Java多线程之线程间的通讯https://blog.csdn.net/qq_43040688/article/details/105754406自定义Boolean锁&amp;捕获线程中的异常https://blog.csdn.net/qq_43040688/article/details/105771445线程组https://blog.csdn.net/qq_43040688/article/details/105774614自定义线程池https://blog.csdn.net/qq_43040688/article/details/105786243多线程的设计模式Java在并发的场景中，设计模式就像个套路，开发者可以自由的组合以满足应用需求下面有十四个多线程的设计模式，帮助理解后面的JUC包。第一个设计模式是：观察者模式。需要定义一个主题，一个观察者。主题在多线程情况下，可以实现Runnable接口，传递给线程；线程在执行的过程中，可能会修改主题的状态；主题状态发生变化，会通知观察者，执行观察者的onChange方法。详情参考：观察者模式第二个设计模式是：单例模式。解决方式有三种：第一种是doublecheck方式，但是可能会引起空指针异常；第二种是holder方式，利用内部static类实现；第三种是利用enum类实现。详情参考：单例模式第三个设计模式是单线程执行模式。就是在同一时刻只能有一个对共享资源进行操作。详情参考：单线程执行设计模式第四个设计模式不可变对象设计模式。是一种无锁的设计模式，其思想是如果共享资源是不可以修改的，则线程一定安全。详情参考：不可变对象设计模式第五个设计模式确保挂起设计模式。当线程在工作时，如果来了其他任务，将任务放入到队列中等待。详情参考：确保挂起设计模式第六个设计模式Balking设计模式。当工作已经执行过了，就直接return，防止重复的工作，提高效率。详情参考：Balking设计模式第七个设计模式生产者-消费者设计模式。如果生产一个产品，放到吧台上，通知消费者；如果吧台上有产品，消费者就会立即执行。详情参考：生产者-消费者设计模式第七个设计模式读写锁的设计模式。读取操作与读取操作之间不存在线程安全的问题，所以在此情况下，避免加锁，影响性能。详情参考：读写锁的设计模式第八个设计模式Thread-Per-Message。每一个请求都创建一个线程服务，为了提高性能，可以使用线程池。详情参考：Thread-Per-Message第九个设计模式Worker设计模式。需要一个Master，负责创建worker、启动worker、监控worker以及接受任务。详情参考：Worker设计模式第十个设计模式Future设计模式。通过返回一个票据，避免陷入阻塞；当任务完成后，可以调用票据的get方法获取结果。详情参考：Future设计模式第十一个设计模式两阶段终止设计模式。当线程关闭时，不会立马关闭，而是先执行第二阶段的资源释放任务。利用的try...finally...。详情参考：两阶段终止设计模式第十二个设计模式线程保险箱设计模式。利用Map，线程是key，数据是value。可以保证线程间的数据是安全的。需要注意：线程池下，需要清空原来的数据。详情参考：线程保险箱设计模式和上下文设计模式第十三个设计模式ActiveObjects设计模式。接受异步调用的主动方法。可以主动异步的执行一些任务。详情参考：ActiveObjects设计模式第十四个设计模式CountDown设计模式。多个子任务执行，主任务等待子任务全部执行完，再执行详情参考：CountDown设计模式多线程的设计模式链接观察者模式https://blog.csdn.net/qq_43040688/article/details/105835544单例模式https://blog.csdn.net/qq_43040688/article/details/105798423单线程执行设计模式https://blog.csdn.net/qq_43040688/article/details/105856901不可变对象设计模式https://blog.csdn.net/qq_43040688/article/details/105865371确保挂起设计模式https://blog.csdn.net/qq_43040688/article/details/105886681Balking设计模式https://blog.csdn.net/qq_43040688/article/details/105890674生产者-消费者设计模式https://blog.csdn.net/qq_43040688/article/details/105891561读写锁的设计模式https://blog.csdn.net/qq_43040688/article/details/105857920Thread-Per-Messagehttps://blog.csdn.net/qq_43040688/article/details/105892219Worker设计模式https://blog.csdn.net/qq_43040688/article/details/105894685Future设计模式https://blog.csdn.net/qq_43040688/article/details/105868293两阶段终止设计模式https://blog.csdn.net/qq_43040688/article/details/105892777线程保险箱设计模式https://blog.csdn.net/qq_43040688/article/details/105887378上下文设计模式https://blog.csdn.net/qq_43040688/article/details/105888242ActiveObjects设计模式https://blog.csdn.net/qq_43040688/article/details/105895280CountDown设计模式https://blog.csdn.net/qq_43040688/article/details/105892054Java高并发与JVM的关系主要是学习waitset、JMM模型JMM模型中有四个内容，主要参看博客：Java多线程之内存模型三大特性。如果想学习更多，请学习JVM的部分。解决高速缓存中数据不一致性的问题——总线锁（效率低）、高速缓存一致性协议，英特尔高并发的三个要求——原子性、可见性、有序性happens-before指令重排序Java多线程之内存模型三大特性：https://blog.csdn.net/qq_43040688/article/details/105823532原子包CAS：乐观锁，CompareAndSwap。优点是：保证变量的原子性；避免从用户态到内核态，可以提高性能确定。缺点：在竞争激烈的情况下，浪费CUP资源。还有一个问题是ABA问题，解决方法是：加一个版本号。详情参考：CASUnSafe类内部有很多native方法，是执行的是C++的代码，给了Java操作内存的方式获取Unsafe需要通过反射Unsafe类的属性常用的功能：CAS、加载类（可以不运行构造方法）、能直接操作内存、内置锁的实现详情参考：UnSafe类AtomicInteger和AtomicBoolean：是保证原子性的对象。利用的CAS详情参考：AtomicInteger和AtomicBooleanAtomicReference是一个利用CAS帮助对象保证原子性的但是存在ABA问题，解决该问题的是：AtomicStampedReference，详情参考：CAS详情参考：AtomicReference文章名称链接CAShttps://blog.csdn.net/qq_43040688/article/details/105914717AtomicIntegerhttps://blog.csdn.net/qq_43040688/article/details/105908835AtomicBooleanhttps://blog.csdn.net/qq_43040688/article/details/105917939AtomicReferencehttps://blog.csdn.net/qq_43040688/article/details/105918329UnSafe类https://blog.csdn.net/qq_43040688/article/details/105923421JUC工具包CountDownLatch通过一个计数器实现，计数器初始值就是线程的数量每当一个线程完成任务，就会使计数减一可以在多线程环境使用，使多个线程阻塞，等待上一阶段任务的全部完成详情见：CountDownLatchCyclicBarrier跟CountDownLatch的区别是：完成任务后需要等待其他线程完成任务，同时是一个可重用点详情见：CyclicBarrierPhaserJDK1.7之后引用的，具有CyclicBarrier和CountDownLatch同时它的注册数是支持动态增加或减少（可以用于线程出现异常）当它在一个阶段所有任务完成时，会进入下一阶段，同时计数器重新恢复详情见：PhaserExchanger用于线程间交换数据需要注意一点：交换的数据对象是一个引用，而不是拷贝，需要考虑线程安全问题详情见：ExchangerSemaphore是一个对共享资源管理的设施，通过对信号量的控制，可以让资源被多个线程访问详情见：SemaphoreReentrantLock支持公平锁，即尽可能的保证线程之间获取时间片的次数的相同的支持tryLock机制，尝试获取锁，如果没有获取到，不会阻塞需要手动的释放锁，try...finally...相较内置锁而言，是基于AQS实现的，不需要一个从用户态到内核态的过程，性能更高是一个Java类，具有更多的功能，同时可以自由的扩展详情请见：ReentrantLock读写锁将读和写分为两个锁，可以有效解决读-读之间的冲突问题，大幅提高性能是悲观锁，可能读的线程太多，写的线程迟迟难以执行详情请见：读写锁StampedLock解决读写锁中，写的线程迟迟难以执行的过程，是一个乐观锁思路是：获得一个乐观的读锁，先读取数据；在返回数据时，检测数据是否有被写入，如果有，则获取一个悲观读锁，重新读取数据详情请见：StampedLock三种锁的比较synchronizedStampedLockLock是JVM的的内置锁，每个JDK版本都会优化是一个Java类，可以更好的扩展是一个Java类，可以更好的扩展都是悲观锁提供了写的乐观锁都是悲观锁，但是提供了自旋锁，或者不阻塞的获取锁性能一般，因为有一个从用户态到内核态的过程性能最好，可以代替读写锁性能十分不稳定，在复杂的读写环境下，性能十分差详情请见：三种锁的比较ForkJoin基本思想是：如果当前线程执行任务速度比较慢，则将此任务拆分，交给子线程执行分为Fork和Join两个阶段，充分利用CPU资源详情请见：ForkJoin文章名称链接CountDownLatchhttps://blog.csdn.net/qq_43040688/article/details/105935307CyclicBarrierhttps://blog.csdn.net/qq_43040688/article/details/105937169Phaserhttps://blog.csdn.net/qq_43040688/article/details/106033183Exchangerhttps://blog.csdn.net/qq_43040688/article/details/105955788Semaphorehttps://blog.csdn.net/qq_43040688/article/details/105956731ReentrantLockhttps://blog.csdn.net/qq_43040688/article/details/105958719读写锁https://blog.csdn.net/qq_43040688/article/details/105975257StampedLockhttps://blog.csdn.net/qq_43040688/article/details/106026847三种锁的比较https://blog.csdn.net/qq_43040688/article/details/106032189ForkJoinhttps://blog.csdn.net/qq_43040688/article/details/106032309Exectors框架首先需要学习线程池的构造方法中参数的意义，如果可以尽量不要使用工厂方法创建线程池。ThreadPoolExecutor创建线程池有七大参数，特别重要有四种拒绝策略四种阻塞队列一些调试的API关闭线程池的注意事项详情请见：ThreadPoolExecutorExecutors用来创建线程池，可以创建5种线程池，需要对这些线程池特性很熟悉：newCachedThreadPoolnewFixedThreadPoolnewScheduledThreadPoolnewSingleThreadExecutornewWorkStealingPool详情请见：ExecutorsCompletionService用来增强线程池，主要思想是：执行一批任务，先执行的，先获取结果实现的子类是：ExecutorCompletionService详情请见：CompletionServiceCompleableFuture可以进行串联的操作，即利用上一个任务的结果，执行下一个任务进行并联的操作，即多个线程执行不同任务，最先执行完成的任务结果将作为这一批任务的结果可以不需要调用者主动获取结果，而进行回调执行一批任务时，获取的Future是按照任务完成的顺序创建CompleableFuture有多种方式，最多的是runAsync和supplyAsyncAPI分为组合方法、中转方法和终结方法详情请见：CompleableFuture文章名称链接ThreadPoolExecutorhttps://blog.csdn.net/qq_43040688/article/details/106041236Executorshttps://blog.csdn.net/qq_43040688/article/details/106046629CompletionServicehttps://blog.csdn.net/qq_43040688/article/details/106058225CompleableFuturehttps://blog.csdn.net/qq_43040688/article/details/106061776","link":"https://xzzz2020.github.io/post/2020-zui-xin-java-mian-shi/"},{"title":"RocketMQ监控平台（附网盘链接）","content":"RocketMQ有一个对其扩展的开源项目incubator-rocketmq-externals，这个项目中有一个子模块叫rocketmq-console，这个便是管理控制台项目了，先将incubator-rocketmq-externals拉到本地，因为我们需要自己对rocketmq-console进行编译打包运行。在linux环境下，使用nohubjava-jarxxxx&amp;启动，为了防止端口冲突，已经修改其端口为9999链接：https://pan.baidu.com/s/1_z8UOFyPwOQKIa_VAl5nTA提取码：jpg03.5.2下载并编译打包gitclonehttps://github.com/apache/rocketmq-externalscdrocketmq-consolemvncleanpackage-Dmaven.test.skip=true注意：打包前在rocketmq-console中配置namesrv集群地址：rocketmq.config.namesrvAddr=192.168.25.135:9876;192.168.25.138:9876启动rocketmq-console：java-jarrocketmq-console-ng-1.0.0.jar启动成功后，我们就可以通过浏览器访问http://localhost:8080进入控制台界面了，如下图：","link":"https://xzzz2020.github.io/post/rocketmq-jian-kong-ping-tai-fu-wang-pan-lian-jie/"},{"title":"⚡️Build a blog platform","content":"在学习技术的过程中，博客是一个总结的过程，十分重要。该文章主要介绍如何搭建一个属于自己的个人博客，点击查看博主博客关于本博客Gridea主题评论评论管理系统博客撰写关于本博客本博客基于github和gitee的静态页，国内用户推荐使用gitee，访问速度更快。如果在学习过程中，出现了什么问题，可以在下方评论，博主会收到的。技术概要如下：博客框架采用的是Gridea主题基于bitcron-pro评论系统使用的Valine评论管理系统使用的Valine-Admin博客使用Typora编写图片上传采用的是PicGO+腾讯COSGrideaGridea是一个博客管理软件，支持Windos和Mac，十分好用，页面也比较好看，但是目前不支持gitee，所以需要写一段代码自己提交。页面如下：下载地址：https://gridea.dev/由于下载速度的原因，提供百度网盘下载0.9.2版本：链接：https://pan.baidu.com/s/1lgQGgiCrVRpvdeeCkaHqSg提取码：73ne下载完成后，先使用github搭建，如果同步成功即可完成。学习文档：https://www.jianshu.com/p/6ddc767b1569想要在gitee快速搭建，首先需要在gitee搭建一个仓库，参考：https://blog.csdn.net/qq_36667170/article/details/79318578下面步骤需要会Git！！！！每次推送到github的博客都是在这个目录下C:\\Users\\正好\\Documents\\Gridea\\output，只需要将这个目下的文件，除了.git文件下外所用的文件覆盖到你本地gitee的仓库。然后需要对这些文件递归调用将其中github的地址替换成gitee，博主使用Java写了一个工具，需要将里面的目录地址修改即可，百度网盘下载地址：链接：https://pan.baidu.com/s/1lg770AMzhgSG_U4SQ5kWRA提取码：n2n7将下图的代码变成你gitee的文件夹即可，逻辑就是遍历文件夹，读取每个文件替换语句。但是我把图片、CSS、JS的文件夹屏蔽了，防止造成影响。接着就是Git提交到gitee仓库，然后重新部署gitee的pages的服务。进入提示的网站地址，刷新一下浏览器就出来了。主题博主对其中的搜索算法以及随机色彩算法进行了改进，如果需要可以联系博主目前使用的主题基于这个项目：https://github.com/qyxtim/bitcron-progit下来后，将bitcron-pro文件夹，放到Gridea的主题目录，如C:\\Users\\正好\\Documents\\Gridea\\themes但是该主题不支持Valine评论，所以对其需要进行一些修改，在下面会有介绍。评论评论是基于Valine的，这有一篇博客可以学习：https://ioliu.cn/2017/add-valine-comments-to-your-blog/由于bitcron-pro不支持该评论Valine但是支持Gitalk，可以通过修改代码实现。需要修改的文件目录，博主本机上是：C:\\Users\\正好\\Documents\\Gridea\\themes\\bitcron-pro\\templates\\_blocks下面的gitalk.ejs将里面所有内容删除，添加下面一段：&lt;!--评论显示区，请插入合适的位置--&gt;&lt;divid=&quot;comment&quot;&gt;&lt;/div&gt;&lt;!--Leancloud操作库:--&gt;&lt;scriptsrc=&quot;//cdn1.lncld.net/static/js/3.6.1/av-min.js&quot;&gt;&lt;/script&gt;&lt;!--Valine的核心代码库--&gt;&lt;scriptsrc=&quot;//cdn.jsdelivr.net/npm/valine@1.4.4/dist/Valine.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;newValine({el:'#comment',appId:'??????????',appKey:'?????????',placeholder:'ヾﾉ≧∀≦)o快来评论一下吧!',avatar:''});&lt;/script&gt;appId和appKey需要在LeanCloud管理页面查看：配置完成记得在Gridea的Gitalk页面单击一下保存，就会应用到博客上。评论管理系统Valine自带一个Valine-Admain的开源项目，会在评论时，给博主予以提醒，需要基于LeanCloud实现。目前LeanCloud不再提供免费的二级域名，所以最好在阿里云或者腾讯云买一个，在各个地方都用的到需要参考的文章：https://blog.csdn.net/u012208219/article/details/106883083后台页面如下所示：邮件提醒页面：当前LeanCloud定时唤醒任务执行时会提示：因流控原因，通过定时任务唤醒体验版实例失败，建议升级至标准版云引擎实例避免休眠参考这篇文章建立监控：https://blog.csdn.net/Lott0419/article/details/106819895博客撰写博主使用的Typora，但是使用这个写博客图片是保存到本地的，所以就需要利用PicGo+图床上传到网络中Typora0.9.86百度网盘下载：链接：https://pan.baidu.com/s/1aO3jyACQYvBubAjq2QhpGg提取码：920iPicGo2.3.0百度网盘下载：链接：https://pan.baidu.com/s/1wqfzmSt-s9yoa4jstOYnUw提取码：rnu8然后就是需要配置PicGo，如果想要使用腾讯COS当图床，参考这篇文章：https://zhuanlan.zhihu.com/p/119250383，当然还可以使用gitee仓库，不过对象存储真心不贵。Gridea可以提供背景图库，我这边有几个网站推荐，都是免费的图片下载网站：http://www.polayoutu.com/collectionshttps://www.hippopx.com/zhhttps://unsplash.com/","link":"https://xzzz2020.github.io/post/Build_blog/"}]}